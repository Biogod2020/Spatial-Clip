{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3668ee",
   "metadata": {},
   "source": [
    "# Cell 1: å¯¼å…¥ (Imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d41fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# (Review #1) å¯¼å…¥ PIL å¹¶è®¾ç½®ä»¥å¤„ç†æˆªæ–­å›¾åƒ\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# (Review #3) å¯¼å…¥ pyarrow ç”¨äºæ›´ç¨³å¥çš„ Parquet å†™å…¥\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# ç¡®ä¿ open_clip åœ¨ Python è·¯å¾„ä¸­\n",
    "# sys.path.append('/path/to/your/open_clip/src')\n",
    "import open_clip\n",
    "\n",
    "# é…ç½®æ—¥å¿—è®°å½•\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b59619",
   "metadata": {},
   "source": [
    "# Cell 2: é…ç½® (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "482d3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 11:30:13,981 - INFO - è®¾å¤‡: cuda:2\n",
      "2025-09-03 11:30:13,981 - INFO - é¢„æ¼”æ¨¡å¼ (DRYRUN): False\n"
     ]
    }
   ],
   "source": [
    "# --- æ ¸å¿ƒé…ç½® ---\n",
    "# ğŸ›¡ï¸ å®‰å…¨ç¬¬ä¸€: é»˜è®¤åœ¨é¢„æ¼”æ¨¡å¼ä¸‹è¿è¡Œ\n",
    "DRYRUN = False\n",
    "\n",
    "# (Review #12) è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§\n",
    "def set_seed(seed=2025):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(2025)\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "BASE_DIR = Path(\"/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/\")\n",
    "TRAIN_MANIFEST = BASE_DIR / \"train_manifest.csv\"\n",
    "VALID_MANIFEST = BASE_DIR / \"validation_manifest.csv\"\n",
    "MODEL_CHECKPOINT = BASE_DIR / \"omiclip_epoch_50.pt\"\n",
    "\n",
    "# (Review #8) æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "for p in [TRAIN_MANIFEST, VALID_MANIFEST, MODEL_CHECKPOINT]:\n",
    "    assert p.exists(), f\"å…³é”®æ–‡ä»¶ç¼ºå¤±: {p}\"\n",
    "\n",
    "# (Review #4) å®šä¹‰æ›´é²æ£’çš„æ­£åˆ™è¡¨è¾¾å¼\n",
    "FILENAME_REGEX = re.compile(r'(.+?)_(-?\\d+)_(-?\\d+)\\.(png|jpg|jpeg|tif|tiff)$', re.IGNORECASE)\n",
    "\n",
    "# æ¨¡å‹é…ç½®\n",
    "MODEL_NAME = \"ViT-B-32\"\n",
    "\n",
    "# é‚»åŸŸè®¡ç®—é…ç½®\n",
    "K_NEIGHBORS = 6\n",
    "\n",
    "# æ‰¹å¤„ç†å’Œè®¾å¤‡é…ç½®\n",
    "BATCH_SIZE = 128  # (Review #9) é™ä½é»˜è®¤æ‰¹æ¬¡å¤§å°ä»¥æé«˜å…¼å®¹æ€§\n",
    "\n",
    "# (Review #2) ç¨³å¥çš„è®¾å¤‡é€‰æ‹©é€»è¾‘\n",
    "def pick_device(prefer_cuda_index: int = 2) -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        n = torch.cuda.device_count()\n",
    "        idx = prefer_cuda_index if prefer_cuda_index < n else 0\n",
    "        return f\"cuda:{idx}\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "DEVICE = pick_device(prefer_cuda_index=2)\n",
    "\n",
    "# è¾“å‡ºé…ç½®\n",
    "ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
    "OUTPUT_NODES_PATH = ARTIFACTS_DIR / \"nodes.parquet\"\n",
    "OUTPUT_EDGES_PATH = ARTIFACTS_DIR / \"edges.parquet\"\n",
    "OUTPUT_IMG_EMBED_PATH = ARTIFACTS_DIR / \"image_embeds.npy\"\n",
    "OUTPUT_TXT_EMBED_PATH = ARTIFACTS_DIR / \"text_embeds.npy\"\n",
    "\n",
    "# (Review #13) æ˜¾å¼åˆ›å»ºç›®å½•\n",
    "if not DRYRUN:\n",
    "    ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "    (ARTIFACTS_DIR / \"clip_cache\").mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "logging.info(f\"è®¾å¤‡: {DEVICE}\")\n",
    "logging.info(f\"é¢„æ¼”æ¨¡å¼ (DRYRUN): {DRYRUN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d89259",
   "metadata": {},
   "source": [
    "# Cell 3: æ ¸å¿ƒé€»è¾‘ - æ•°æ®åŠ è½½ä¸å¤„ç† (Core Logic - Data Loading & Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa3df7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "# (Review #1) å¯¼å…¥ PIL å¹¶è®¾ç½®ä»¥å¤„ç†æˆªæ–­å›¾åƒ\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# --- æ–°å¢ï¼šå¥å£®çš„å›¾åƒéªŒè¯å‡½æ•° ---\n",
    "def is_image_valid(filepath: str) -> bool:\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥å•ä¸ªå›¾åƒæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚\n",
    "    è¿”å› True å¦‚æœæ–‡ä»¶å­˜åœ¨ã€å¤§å°ä¸ä¸ºé›¶ä¸”å¯ä»¥è¢«PILè¯†åˆ«ã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p = Path(filepath)\n",
    "        # 1. å¿«é€Ÿæ£€æŸ¥ï¼šæ˜¯å¦å­˜åœ¨å’Œå¤§å°æ˜¯å¦ä¸º0\n",
    "        if not p.exists() or p.stat().st_size == 0:\n",
    "            return False\n",
    "        # 2. æ·±åº¦æ£€æŸ¥ï¼šPILèƒ½å¦æ‰“å¼€å¹¶éªŒè¯\n",
    "        with Image.open(p) as img:\n",
    "            img.verify()  # å¿«é€Ÿæ£€æŸ¥æ–‡ä»¶å¤´å’Œå…ƒæ•°æ®\n",
    "        return True\n",
    "    except Exception:\n",
    "        # æ•è·æ‰€æœ‰å¼‚å¸¸ (FileNotFoundError, PIL.UnidentifiedImageError, etc.)\n",
    "        return False\n",
    "# ------------------------------------\n",
    "\n",
    "def parse_path(path_str: str) -> Tuple[str, int, int]:\n",
    "    \"\"\"ä»å›¾åƒè·¯å¾„ä¸­è§£æ sample_id, x, y åæ ‡ã€‚\"\"\"\n",
    "    m = FILENAME_REGEX.search(Path(path_str).name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"æ— æ³•è§£æè·¯å¾„æ ¼å¼: {path_str}\")\n",
    "    sample_id, x, y, _ = m.groups()\n",
    "    return sample_id, int(x), int(y)\n",
    "\n",
    "def find_malformed_paths(paths: pd.Series) -> List[str]:\n",
    "    \"\"\"å¿«é€ŸæŸ¥æ‰¾æ‰€æœ‰ä¸ç¬¦åˆé¢„æœŸæ ¼å¼çš„è·¯å¾„ã€‚\"\"\"\n",
    "    return [p for p in paths if not FILENAME_REGEX.search(Path(p).name)]\n",
    "\n",
    "def load_and_prepare_data(manifest_paths: List[Path]) -> pd.DataFrame:\n",
    "    \"\"\"åŠ è½½ã€åˆå¹¶ã€éªŒè¯ã€è§£æå¹¶ç´¢å¼•æ¸…å•æ–‡ä»¶ã€‚\"\"\"\n",
    "    logging.info(f\"ä» {manifest_paths} åŠ è½½æ¸…å•...\")\n",
    "    df = pd.concat([pd.read_csv(p) for p in manifest_paths], ignore_index=True)\n",
    "\n",
    "    required_cols = {\"image_path\", \"gene_sentence\"}\n",
    "    assert required_cols.issubset(df.columns), f\"æ¸…å•ç¼ºå°‘åˆ—: {required_cols - set(df.columns)}\"\n",
    "\n",
    "    # --- BUG FIX & ROBUSTNESS ---\n",
    "    # åœ¨åŠ è½½ä»»ä½•æ•°æ®å‰ï¼Œå¹¶è¡ŒéªŒè¯æ‰€æœ‰å›¾åƒæ–‡ä»¶çš„æœ‰æ•ˆæ€§\n",
    "    logging.info(f\"å¼€å§‹å¹¶è¡ŒéªŒè¯ {len(df)} ä¸ªå›¾åƒæ–‡ä»¶...\")\n",
    "    image_paths = df['image_path'].tolist()\n",
    "    # ä½¿ç”¨ process_map å¹¶è¡Œå¤„ç†ï¼Œå¹¶æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    # max_workers=None ä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ\n",
    "    is_valid_mask = process_map(is_image_valid, image_paths, max_workers=None, chunksize=100)\n",
    "    \n",
    "    num_original = len(df)\n",
    "    df_valid = df[is_valid_mask].copy() # ä½¿ç”¨ .copy() é¿å… SettingWithCopyWarning\n",
    "    num_valid = len(df_valid)\n",
    "    num_removed = num_original - num_valid\n",
    "    \n",
    "    if num_removed > 0:\n",
    "        logging.warning(f\"éªŒè¯å®Œæˆã€‚ç§»é™¤äº† {num_removed} ä¸ªæ— æ•ˆæˆ–æŸåçš„å›¾åƒæ¡ç›®ã€‚\")\n",
    "    else:\n",
    "        logging.info(\"éªŒè¯å®Œæˆã€‚æ‰€æœ‰å›¾åƒæ–‡ä»¶å‡æœ‰æ•ˆã€‚\")\n",
    "    # ----------------------------\n",
    "\n",
    "    logging.info(\"é¢„æ£€æŸ¥æ‰€æœ‰è·¯å¾„æ ¼å¼...\")\n",
    "    malformed = find_malformed_paths(df_valid['image_path'])\n",
    "    if malformed:\n",
    "        logging.error(f\"å‘ç° {len(malformed)} ä¸ªæ ¼å¼é”™è¯¯çš„è·¯å¾„ã€‚ç¤ºä¾‹: {malformed[:5]}\")\n",
    "    else:\n",
    "        logging.info(\"æ‰€æœ‰è·¯å¾„æ ¼å¼å‡æœ‰æ•ˆã€‚\")\n",
    "\n",
    "    logging.info(\"è§£ææ–‡ä»¶åä»¥æå–åæ ‡å’Œæ ·æœ¬ID...\")\n",
    "    path_data = df_valid['image_path'].apply(parse_path)\n",
    "    \n",
    "    parsed_info_df = pd.DataFrame(path_data.tolist(), columns=['sample_id', 'x', 'y'], index=df_valid.index)\n",
    "    df_final = df_valid.join(parsed_info_df)\n",
    "    df_final = df_final.astype({'sample_id': 'object', 'x': 'int32', 'y': 'int32'})\n",
    "    \n",
    "    df_final.reset_index(drop=True, inplace=True) # ä½¿ç”¨ drop=True é¿å…æ—§ç´¢å¼•æˆä¸ºæ–°åˆ—\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final.rename(columns={'index': 'tile_id'}, inplace=True)\n",
    "    df_final['tile_id'] = df_final['tile_id'].astype('int64')\n",
    "    \n",
    "    logging.info(f\"æ•°æ®åŠ è½½å®Œæˆã€‚æœ‰æ•ˆå›¾å—æ€»æ•° {len(df_final)}ï¼Œåˆ†å¸ƒåœ¨ {df_final['sample_id'].nunique()} ä¸ªæ ·æœ¬ä¸­ã€‚\")\n",
    "    return df_final\n",
    "\n",
    "def compute_neighborhoods(df: pd.DataFrame, k: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"æŒ‰æ ·æœ¬åˆ†ç»„è®¡ç®—k-æœ€è¿‘é‚»ï¼Œè¿”å›èŠ‚ç‚¹å’Œè¾¹DataFrameã€‚\"\"\"\n",
    "    logging.info(f\"å¼€å§‹è®¡ç®— k={k} çš„æœ€è¿‘é‚»...\")\n",
    "    \n",
    "    edges = []\n",
    "    \n",
    "    for sample_id, group in tqdm(df.groupby('sample_id'), desc=\"å¤„ç†æ ·æœ¬\"):\n",
    "        coords = group[['x', 'y']].values\n",
    "        n_neighbors = min(k + 1, len(coords))\n",
    "        if n_neighbors <= 1:\n",
    "            continue\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(coords)\n",
    "        distances, indices = nbrs.kneighbors(coords)\n",
    "        \n",
    "        distances, indices = distances[:, 1:], indices[:, 1:]\n",
    "        \n",
    "        non_zero_distances = distances[distances > 0]\n",
    "        sigma = np.percentile(non_zero_distances, 50) if non_zero_distances.size > 0 else 1.0\n",
    "        sigma = max(sigma, 1e-6)\n",
    "\n",
    "        weights = np.exp(- (distances ** 2) / (2 * sigma ** 2))\n",
    "        \n",
    "        sum_w = weights.sum(axis=1, keepdims=True)\n",
    "        alpha = np.divide(weights, np.maximum(sum_w, 1e-8))\n",
    "\n",
    "        src_tile_ids = group['tile_id'].values\n",
    "        neighbor_tile_ids = src_tile_ids[indices]\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            src_id = src_tile_ids[i]\n",
    "            for j in range(indices.shape[1]):\n",
    "                edges.append((\n",
    "                    src_id,\n",
    "                    neighbor_tile_ids[i, j],\n",
    "                    distances[i, j],\n",
    "                    weights[i, j],\n",
    "                    alpha[i, j]\n",
    "                ))\n",
    "\n",
    "    logging.info(\"é‚»åŸŸè®¡ç®—å®Œæˆã€‚\")\n",
    "    edges_df = pd.DataFrame(edges, columns=[\n",
    "        \"src_tile_id\", \"nbr_tile_id\", \"distance\", \"weight\", \"alpha\"\n",
    "    ]).astype({\n",
    "        \"src_tile_id\": \"int64\", \"nbr_tile_id\": \"int64\",\n",
    "        \"distance\": \"float32\", \"weight\": \"float32\", \"alpha\": \"float32\"\n",
    "    })\n",
    "\n",
    "    nodes_df = df[['tile_id', 'sample_id', 'x', 'y', 'image_path', 'gene_sentence']].copy()\n",
    "    return nodes_df, edges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757c67e",
   "metadata": {},
   "source": [
    "# Cell 4: æ ¸å¿ƒé€»è¾‘ - åµŒå…¥ç¼“å­˜ (Core Logic - Embedding Caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78b37bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipDataset(Dataset):\n",
    "    \"\"\"ç”¨äºæ‰¹é‡æå–ç‰¹å¾çš„ PyTorch Datasetã€‚\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, preprocess_fn, tokenizer):\n",
    "        self.df = df\n",
    "        self.preprocess = preprocess_fn\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = self.preprocess(Image.open(row['image_path']).convert(\"RGB\"))\n",
    "        # (Review #5) ç¡®ä¿å§‹ç»ˆä¼ é€’åˆ—è¡¨ç»™ tokenizer\n",
    "        text = self.tokenizer([row['gene_sentence']])[0]\n",
    "        return image, text\n",
    "\n",
    "def cache_embeddings(df: pd.DataFrame, model_name: str, checkpoint_path: Path, device: str, batch_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"ä¸ºæ‰€æœ‰å›¾å—ç”Ÿæˆå›¾åƒå’Œæ–‡æœ¬åµŒå…¥ã€‚\"\"\"\n",
    "    logging.info(f\"åŠ è½½æ¨¡å‹ {model_name} ä»æ£€æŸ¥ç‚¹ {checkpoint_path}...\")\n",
    "    \n",
    "    model, _, preprocess_val = open_clip.create_model_and_transforms(\n",
    "        model_name, pretrained=None, cache_dir=str(ARTIFACTS_DIR / \"clip_cache\")\n",
    "    )\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    if all(key.startswith('module.') for key in state_dict.keys()):\n",
    "        state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = open_clip.get_tokenizer(model_name)\n",
    "    dataset = ClipDataset(df, preprocess_val, tokenizer)\n",
    "    \n",
    "    # (Review #9) ä¼˜åŒ– DataLoader\n",
    "    pin_memory = device.startswith(\"cuda\")\n",
    "    num_workers = 16\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, persistent_workers=(num_workers > 0)\n",
    "    )\n",
    "    \n",
    "    image_embeds, text_embeds = [], []\n",
    "    # (Review #9) ä½¿ç”¨ torch.inference_mode()\n",
    "    with torch.inference_mode():\n",
    "        for images, texts in tqdm(dataloader, desc=\"æå–åµŒå…¥\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            texts = texts.to(device, non_blocking=True)\n",
    "            \n",
    "            image_features = model.encode_image(images)\n",
    "            text_features = model.encode_text(texts)\n",
    "            \n",
    "            image_features = F.normalize(image_features, p=2, dim=-1)\n",
    "            text_features = F.normalize(text_features, p=2, dim=-1)\n",
    "            \n",
    "            image_embeds.append(image_features.cpu().numpy())\n",
    "            text_embeds.append(text_features.cpu().numpy())\n",
    "\n",
    "    img_emb_array = np.vstack(image_embeds).astype(\"float32\")\n",
    "    txt_emb_array = np.vstack(text_embeds).astype(\"float32\")\n",
    "    \n",
    "    logging.info(\"åµŒå…¥æå–å®Œæˆã€‚\")\n",
    "    return img_emb_array, txt_emb_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f573a",
   "metadata": {},
   "source": [
    "# Cell 5: ä¸»æµç¨‹ä¸äº¤ä»˜ (Main Orchestration & Delivery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a6ffc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 11:04:54,416 - INFO - ä» [PosixPath('/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/train_manifest.csv'), PosixPath('/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/validation_manifest.csv')] åŠ è½½æ¸…å•...\n",
      "2025-09-03 11:04:58,560 - INFO - å¼€å§‹å¹¶è¡ŒéªŒè¯ 952909 ä¸ªå›¾åƒæ–‡ä»¶...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97848cff4a420ea60499bfb58346d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/952909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 11:10:18,086 - WARNING - éªŒè¯å®Œæˆã€‚ç§»é™¤äº† 1 ä¸ªæ— æ•ˆæˆ–æŸåçš„å›¾åƒæ¡ç›®ã€‚\n",
      "2025-09-03 11:10:18,088 - INFO - é¢„æ£€æŸ¥æ‰€æœ‰è·¯å¾„æ ¼å¼...\n",
      "2025-09-03 11:10:22,158 - INFO - æ‰€æœ‰è·¯å¾„æ ¼å¼å‡æœ‰æ•ˆã€‚\n",
      "2025-09-03 11:10:22,160 - INFO - è§£ææ–‡ä»¶åä»¥æå–åæ ‡å’Œæ ·æœ¬ID...\n",
      "2025-09-03 11:10:27,192 - INFO - æ•°æ®åŠ è½½å®Œæˆã€‚æœ‰æ•ˆå›¾å—æ€»æ•° 952908ï¼Œåˆ†å¸ƒåœ¨ 475 ä¸ªæ ·æœ¬ä¸­ã€‚\n",
      "2025-09-03 11:10:27,318 - INFO - å¼€å§‹è®¡ç®— k=6 çš„æœ€è¿‘é‚»...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de25137983e04cd9a53adda15c57ccd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "å¤„ç†æ ·æœ¬:   0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 11:10:34,339 - INFO - é‚»åŸŸè®¡ç®—å®Œæˆã€‚\n",
      "2025-09-03 11:10:41,038 - INFO - åŠ è½½æ¨¡å‹ ViT-B-32 ä»æ£€æŸ¥ç‚¹ /cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt...\n",
      "2025-09-03 11:10:41,041 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
      "2025-09-03 11:10:41,042 - INFO - Loaded built-in ViT-B-32 model config.\n",
      "2025-09-03 11:10:41,042 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
      "2025-09-03 11:10:41,043 - INFO - Instantiating model architecture: CLIP\n",
      "2025-09-03 11:10:42,253 - WARNING - Model ViT-B-32 initialized partially.\n",
      "2025-09-03 11:10:42,254 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
      "2025-09-03 11:10:42,254 - INFO - Model ViT-B-32 creation process complete.\n",
      "2025-09-03 11:10:43,467 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
      "2025-09-03 11:10:43,468 - INFO - Attempting to load config from built-in: ViT-B-32\n",
      "2025-09-03 11:10:43,469 - INFO - Using default SimpleTokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3047d2a2870447188f4c41ecdb8eab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "æå–åµŒå…¥:   0%|          | 0/7445 [00:03<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 11:21:17,215 - INFO - åµŒå…¥æå–å®Œæˆã€‚\n",
      "2025-09-03 11:21:17,259 - INFO - å¼€å§‹å°†æ•°æ®å†™å…¥ç£ç›˜...\n",
      "2025-09-03 11:21:22,628 - INFO - åµŒå…¥å·²ä¿å­˜åˆ° .npy æ–‡ä»¶: artifacts/image_embeds.npy, artifacts/text_embeds.npy\n",
      "2025-09-03 11:21:25,490 - INFO - èŠ‚ç‚¹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: artifacts/nodes.parquet\n",
      "2025-09-03 11:21:26,659 - INFO - è¾¹(é‚»åŸŸ)æ•°æ®å·²ä¿å­˜åˆ°: artifacts/edges.parquet\n",
      "2025-09-03 11:21:26,663 - INFO - æ‰€æœ‰æ–‡ä»¶ä¿å­˜æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "def run_step0_preprocessing():\n",
    "    \"\"\"æ‰§è¡ŒStep 0çš„å®Œæ•´æµç¨‹ã€‚\"\"\"\n",
    "    # 1. åŠ è½½å’Œå‡†å¤‡æ•°æ®\n",
    "    base_df = load_and_prepare_data([TRAIN_MANIFEST, VALID_MANIFEST])\n",
    "    \n",
    "    # 2. è®¡ç®—é‚»åŸŸï¼Œå¾—åˆ°èŠ‚ç‚¹å’Œè¾¹è¡¨\n",
    "    nodes_df, edges_df = compute_neighborhoods(base_df, k=K_NEIGHBORS)\n",
    "    \n",
    "    # 3. ç¼“å­˜åµŒå…¥\n",
    "    img_embeds, txt_embeds = cache_embeddings(\n",
    "        nodes_df, # ä»…éœ€èŠ‚ç‚¹ä¿¡æ¯æ¥æå–åµŒå…¥\n",
    "        model_name=MODEL_NAME,\n",
    "        checkpoint_path=MODEL_CHECKPOINT,\n",
    "        device=DEVICE,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # 4. (Review #3, #10) æ‹†åˆ†å­˜å‚¨åˆ° Parquet å’Œ Numpy æ–‡ä»¶\n",
    "    if not DRYRUN:\n",
    "        logging.info(\"å¼€å§‹å°†æ•°æ®å†™å…¥ç£ç›˜...\")\n",
    "        \n",
    "        # ä¿å­˜åµŒå…¥\n",
    "        np.save(OUTPUT_IMG_EMBED_PATH, img_embeds)\n",
    "        np.save(OUTPUT_TXT_EMBED_PATH, txt_embeds)\n",
    "        logging.info(f\"åµŒå…¥å·²ä¿å­˜åˆ° .npy æ–‡ä»¶: {OUTPUT_IMG_EMBED_PATH}, {OUTPUT_TXT_EMBED_PATH}\")\n",
    "        \n",
    "        # ä½¿ç”¨ PyArrow ä¿å­˜ Parquet æ–‡ä»¶ï¼Œæ›´ç¨³å¥\n",
    "        pq.write_table(pa.Table.from_pandas(nodes_df, preserve_index=False), OUTPUT_NODES_PATH)\n",
    "        logging.info(f\"èŠ‚ç‚¹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_NODES_PATH}\")\n",
    "        \n",
    "        pq.write_table(pa.Table.from_pandas(edges_df, preserve_index=False), OUTPUT_EDGES_PATH)\n",
    "        logging.info(f\"è¾¹(é‚»åŸŸ)æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_EDGES_PATH}\")\n",
    "        \n",
    "        logging.info(\"æ‰€æœ‰æ–‡ä»¶ä¿å­˜æˆåŠŸï¼\")\n",
    "    else:\n",
    "        logging.warning(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œæ–‡ä»¶æœªè¢«å†™å…¥ã€‚\")\n",
    "        logging.info(\"èŠ‚ç‚¹è¡¨é¢„è§ˆ:\\n\" + str(nodes_df.head()))\n",
    "        logging.info(\"è¾¹è¡¨é¢„è§ˆ:\\n\" + str(edges_df.head()))\n",
    "        logging.info(f\"å›¾åƒåµŒå…¥æ•°ç»„å½¢çŠ¶: {img_embeds.shape}\")\n",
    "        logging.info(f\"æ–‡æœ¬åµŒå…¥æ•°ç»„å½¢çŠ¶: {txt_embeds.shape}\")\n",
    "\n",
    "    return nodes_df, edges_df, img_embeds, txt_embeds\n",
    "\n",
    "# æ‰§è¡Œä¸»æµç¨‹\n",
    "nodes_df, edges_df, img_embeds, txt_embeds = run_step0_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b482c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 11:30:35,497 - INFO - å¼€å§‹éªŒè¯æ‹†åˆ†åçš„æ–‡ä»¶...\n",
      "2025-09-03 11:30:35,500 - INFO - æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²æ‰¾åˆ°ã€‚\n",
      "2025-09-03 11:30:38,200 - INFO - âœ… èŠ‚ç‚¹è¡¨åŸºæœ¬ç»“æ„æ­£ç¡®ã€‚\n",
      "2025-09-03 11:30:38,699 - INFO - âœ… è¾¹è¡¨åŸºæœ¬ç»“æ„å’Œå¼•ç”¨å®Œæ•´æ€§æ­£ç¡®ã€‚\n",
      "2025-09-03 11:30:39,842 - INFO - âœ… åµŒå…¥æ•°ç»„å½¢çŠ¶å’Œç»´åº¦æ­£ç¡®ã€‚\n",
      "2025-09-03 11:30:39,843 - INFO - ğŸ‰ å…¨éƒ¨éªŒè¯æˆåŠŸï¼æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€æ­¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "def validate_output_revised():\n",
    "    \"\"\"åŠ è½½å¹¶éªŒè¯æ–°ç”Ÿæˆçš„æ‰€æœ‰æ–‡ä»¶ã€‚\"\"\"\n",
    "    logging.info(\"å¼€å§‹éªŒè¯æ‹†åˆ†åçš„æ–‡ä»¶...\")\n",
    "    \n",
    "    paths_to_check = [\n",
    "        OUTPUT_NODES_PATH, OUTPUT_EDGES_PATH, \n",
    "        OUTPUT_IMG_EMBED_PATH, OUTPUT_TXT_EMBED_PATH\n",
    "    ]\n",
    "    \n",
    "    for p in paths_to_check:\n",
    "        if not p.exists():\n",
    "            logging.error(f\"éªŒè¯å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ï¼{p}ã€‚è¯·ç¡®ä¿ DRYRUN=False å¹¶é‡æ–°è¿è¡Œã€‚\")\n",
    "            return\n",
    "    logging.info(\"æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²æ‰¾åˆ°ã€‚\")\n",
    "\n",
    "    # 1. éªŒè¯èŠ‚ç‚¹è¡¨ (nodes.parquet)\n",
    "    nodes = pd.read_parquet(OUTPUT_NODES_PATH)\n",
    "    assert not nodes.empty, \"èŠ‚ç‚¹è¡¨ä¸åº”ä¸ºç©º\"\n",
    "    assert nodes['tile_id'].is_unique, \"èŠ‚ç‚¹è¡¨ä¸­çš„ tile_id åº”å”¯ä¸€\"\n",
    "    assert nodes['tile_id'].dtype == 'int64'\n",
    "    assert nodes['x'].dtype == 'int32'\n",
    "    logging.info(\"âœ… èŠ‚ç‚¹è¡¨åŸºæœ¬ç»“æ„æ­£ç¡®ã€‚\")\n",
    "\n",
    "    # 2. éªŒè¯è¾¹è¡¨ (edges.parquet)\n",
    "    edges = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
    "    assert not edges.empty, \"è¾¹è¡¨ä¸åº”ä¸ºç©º\"\n",
    "    assert 'src_tile_id' in edges.columns and 'nbr_tile_id' in edges.columns\n",
    "    assert edges['src_tile_id'].isin(nodes['tile_id']).all(), \"è¾¹è¡¨ä¸­çš„æºIDåº”åœ¨èŠ‚ç‚¹è¡¨ä¸­\"\n",
    "    assert edges['nbr_tile_id'].isin(nodes['tile_id']).all(), \"è¾¹è¡¨ä¸­çš„é‚»å±…IDåº”åœ¨èŠ‚ç‚¹è¡¨ä¸­\"\n",
    "    assert edges['alpha'].dtype == 'float32'\n",
    "    max_neighbors = edges.groupby('src_tile_id').size().max()\n",
    "    assert max_neighbors <= K_NEIGHBORS, f\"å•ä¸ªèŠ‚ç‚¹çš„æœ€å¤§é‚»å±…æ•° ({max_neighbors}) è¶…è¿‡ k={K_NEIGHBORS}\"\n",
    "    logging.info(\"âœ… è¾¹è¡¨åŸºæœ¬ç»“æ„å’Œå¼•ç”¨å®Œæ•´æ€§æ­£ç¡®ã€‚\")\n",
    "\n",
    "    # 3. éªŒè¯åµŒå…¥æ•°ç»„ (.npy)\n",
    "    img_e = np.load(OUTPUT_IMG_EMBED_PATH)\n",
    "    txt_e = np.load(OUTPUT_TXT_EMBED_PATH)\n",
    "    assert img_e.shape[0] == len(nodes), \"å›¾åƒåµŒå…¥æ•°é‡åº”ä¸èŠ‚ç‚¹æ•°é‡åŒ¹é…\"\n",
    "    assert txt_e.shape[0] == len(nodes), \"æ–‡æœ¬åµŒå…¥æ•°é‡åº”ä¸èŠ‚ç‚¹æ•°é‡åŒ¹é…\"\n",
    "    \n",
    "    # å‡è®¾ ViT-B-32 çš„åµŒå…¥ç»´åº¦æ˜¯ 512\n",
    "    embed_dim = 512\n",
    "    assert img_e.shape[1] == embed_dim, f\"å›¾åƒåµŒå…¥ç»´åº¦é”™è¯¯ (åº”ä¸º {embed_dim})\"\n",
    "    assert txt_e.shape[1] == embed_dim, f\"æ–‡æœ¬åµŒå…¥ç»´åº¦é”™è¯¯ (åº”ä¸º {embed_dim})\"\n",
    "    logging.info(\"âœ… åµŒå…¥æ•°ç»„å½¢çŠ¶å’Œç»´åº¦æ­£ç¡®ã€‚\")\n",
    "\n",
    "    logging.info(\"ğŸ‰ å…¨éƒ¨éªŒè¯æˆåŠŸï¼æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€æ­¥ã€‚\")\n",
    "\n",
    "# è¿è¡ŒéªŒè¯\n",
    "if not DRYRUN:\n",
    "    validate_output_revised()\n",
    "else:\n",
    "    logging.info(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡éªŒè¯ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632eab82",
   "metadata": {},
   "source": [
    "# Cell 6 Visualization Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d34feace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_neighborhood(nodes_df: pd.DataFrame, edges_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Randomly select a tile and visualize its position and neighbors in the sample space.\n",
    "    \"\"\"\n",
    "    # Ensure data is loaded\n",
    "    if 'nodes_df' not in locals() or 'edges_df' not in locals():\n",
    "        logging.info(\"Loading data from disk for visualization...\")\n",
    "        nodes_df = pd.read_parquet(OUTPUT_NODES_PATH)\n",
    "        edges_df = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
    "\n",
    "    # 1. Random sampling\n",
    "    # Randomly select a sample ID\n",
    "    sample_ids_with_neighbors = edges_df['src_tile_id'].map(nodes_df.set_index('tile_id')['sample_id']).unique()\n",
    "    if len(sample_ids_with_neighbors) == 0:\n",
    "        logging.warning(\"No samples found in edge table, cannot perform visualization.\")\n",
    "        return\n",
    "        \n",
    "    random_sample_id = random.choice(sample_ids_with_neighbors)\n",
    "    \n",
    "    # Get all tiles from this sample\n",
    "    sample_nodes = nodes_df[nodes_df['sample_id'] == random_sample_id]\n",
    "    \n",
    "    # Randomly select an anchor tile from this sample\n",
    "    anchor_tile = sample_nodes.sample(1).iloc[0]\n",
    "    anchor_id = anchor_tile['tile_id']\n",
    "    \n",
    "    logging.info(f\"Visualizing anchor tile ID: {anchor_id} from sample '{random_sample_id}'\")\n",
    "\n",
    "    # 2. Data preparation\n",
    "    # Get neighbor information for the anchor\n",
    "    anchor_edges = edges_df[edges_df['src_tile_id'] == anchor_id]\n",
    "    neighbor_ids = anchor_edges['nbr_tile_id'].tolist()\n",
    "    \n",
    "    # Get neighbor coordinates and weights\n",
    "    neighbor_nodes = nodes_df[nodes_df['tile_id'].isin(neighbor_ids)].merge(\n",
    "        anchor_edges[['nbr_tile_id', 'alpha']],\n",
    "        left_on='tile_id',\n",
    "        right_on='nbr_tile_id'\n",
    "    )\n",
    "\n",
    "    # 3. Visualization\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Draw background: all other points in this sample\n",
    "    ax.scatter(\n",
    "        sample_nodes['x'], sample_nodes['y'],\n",
    "        s=5, c='lightgray', alpha=0.5, label='Background (same sample)'\n",
    "    )\n",
    "    \n",
    "    # Draw neighbors\n",
    "    ax.scatter(\n",
    "        neighbor_nodes['x'], neighbor_nodes['y'],\n",
    "        s=50, c='royalblue', alpha=0.8, label=f'Neighbors (k={len(neighbor_nodes)})'\n",
    "    )\n",
    "    \n",
    "    # Draw anchor point\n",
    "    ax.scatter(\n",
    "        anchor_tile['x'], anchor_tile['y'],\n",
    "        s=200, c='red', marker='*', edgecolors='black', label='Anchor'\n",
    "    )\n",
    "    \n",
    "    # Draw connection lines, transparency determined by alpha\n",
    "    for _, neighbor in neighbor_nodes.iterrows():\n",
    "        ax.plot(\n",
    "            [anchor_tile['x'], neighbor['x']],\n",
    "            [anchor_tile['y'], neighbor['y']],\n",
    "            color='salmon',\n",
    "            linewidth=1.5,\n",
    "            alpha=neighbor['alpha'] * 0.8 + 0.2  # Ensure weakest lines are still visible\n",
    "        )\n",
    "        \n",
    "    # 4. Chart styling\n",
    "    ax.set_title(f\"Neighborhood Visualization (Sample: {random_sample_id}, Anchor ID: {anchor_id})\", fontsize=16)\n",
    "    ax.set_xlabel(\"X Coordinate\", fontsize=12)\n",
    "    ax.set_ylabel(\"Y Coordinate\", fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_aspect('equal', adjustable='box') # Ensure equal x, y axis ratios\n",
    "    plt.gca().invert_yaxis() # Image coordinate system Y-axis usually points down\n",
    "    plt.show()\n",
    "\n",
    "# --- Run visualization ---\n",
    "# Assume nodes_df and edges_df are already in memory\n",
    "if not DRYRUN:\n",
    "    try:\n",
    "        visualize_neighborhood(nodes_df, edges_df)\n",
    "    except NameError:\n",
    "        # If variables are not in memory, load from files\n",
    "        nodes_df_viz = pd.read_parquet(OUTPUT_NODES_PATH)\n",
    "        edges_df_viz = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
    "        visualize_neighborhood(nodes_df_viz, edges_df_viz)\n",
    "else:\n",
    "    logging.info(\"In dry run mode, skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb1493",
   "metadata": {},
   "source": [
    "# Cell 6.1 Visualization Validation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5edc1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_from_path(path_str: str) -> Image.Image:\n",
    "    \"\"\"Safely loads an image from a path.\"\"\"\n",
    "    try:\n",
    "        return Image.open(path_str).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load image at {path_str}: {e}\")\n",
    "        # Return a placeholder image on failure\n",
    "        return Image.new('RGB', (224, 224), color = 'red')\n",
    "\n",
    "def visualize_retrieval(nodes_df: pd.DataFrame = None, edges_df: pd.DataFrame = None):\n",
    "    \"\"\"\n",
    "    Randomly selects an anchor tile, retrieves its raw data (image, text), \n",
    "    finds its neighbors, retrieves their raw data, and displays them all.\n",
    "    \"\"\"\n",
    "    # 1. åŠ è½½æ•°æ® (å¦‚æœå°šæœªåŠ è½½)\n",
    "    if nodes_df is None or edges_df is None:\n",
    "        logging.info(\"Visualizer is loading data from disk...\")\n",
    "        if not OUTPUT_NODES_PATH.exists() or not OUTPUT_EDGES_PATH.exists():\n",
    "            logging.error(\"Parquet files not found. Please run the main pipeline first.\")\n",
    "            return\n",
    "        nodes_df = pd.read_parquet(OUTPUT_NODES_PATH)\n",
    "        edges_df = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
    "\n",
    "    # 2. éšæœºæŠ½æ ·ä¸€ä¸ªæœ‰æ„ä¹‰çš„é”šç‚¹\n",
    "    sample_ids_with_neighbors = edges_df['src_tile_id'].map(nodes_df.set_index('tile_id')['sample_id']).unique()\n",
    "    if len(sample_ids_with_neighbors) == 0:\n",
    "        logging.warning(\"No edges found in the dataset. Cannot visualize a neighborhood.\")\n",
    "        return\n",
    "        \n",
    "    random_sample_id = random.choice(sample_ids_with_neighbors)\n",
    "    \n",
    "    possible_anchors = nodes_df[\n",
    "        (nodes_df['sample_id'] == random_sample_id) &\n",
    "        (nodes_df['tile_id'].isin(edges_df['src_tile_id']))\n",
    "    ]\n",
    "    if possible_anchors.empty:\n",
    "        logging.warning(f\"Could not find an anchor with neighbors in sample '{random_sample_id}'. Retrying might help.\")\n",
    "        return\n",
    "        \n",
    "    anchor_tile_series = possible_anchors.sample(1).iloc[0]\n",
    "    anchor_id = anchor_tile_series['tile_id']\n",
    "    \n",
    "    # 3. æ£€ç´¢æ•°æ®\n",
    "    anchor_image = load_image_from_path(anchor_tile_series['image_path'])\n",
    "    anchor_text = anchor_tile_series['gene_sentence']\n",
    "    \n",
    "    anchor_edges = edges_df[edges_df['src_tile_id'] == anchor_id].sort_values('distance')\n",
    "    neighbor_ids = anchor_edges['nbr_tile_id'].tolist()\n",
    "    \n",
    "    # --- BUG FIX ---\n",
    "    # é”™è¯¯åŸå› ï¼šä¹‹å‰çš„ merge æ“ä½œé—æ¼äº† 'distance' åˆ—ã€‚\n",
    "    # ä¿®å¤æ–¹æ¡ˆï¼šåœ¨ merge çš„åˆ—é€‰æ‹©ä¸­åŠ å…¥ 'distance'ã€‚\n",
    "    neighbor_nodes_df = nodes_df[nodes_df['tile_id'].isin(neighbor_ids)].merge(\n",
    "        anchor_edges[['nbr_tile_id', 'distance', 'alpha']], # <-- æ ¸å¿ƒä¿®å¤ç‚¹\n",
    "        left_on='tile_id',\n",
    "        right_on='nbr_tile_id'\n",
    "    ).set_index('tile_id').loc[neighbor_ids].reset_index() # ä¿æŒæ’åº\n",
    "    # --- END FIX ---\n",
    "\n",
    "    neighbor_images = [load_image_from_path(p) for p in neighbor_nodes_df['image_path']]\n",
    "    neighbor_texts = neighbor_nodes_df['gene_sentence'].tolist()\n",
    "    \n",
    "    logging.info(f\"Visualizing anchor tile {anchor_id} and its {len(neighbor_ids)} neighbors from sample '{random_sample_id}'.\")\n",
    "\n",
    "    # 4. å¯è§†åŒ–\n",
    "    num_plots = 1 + len(neighbor_ids)\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(num_plots * 4, 4.5))\n",
    "    \n",
    "    def wrap_text(text, width=40):\n",
    "        return textwrap.fill(text, width)\n",
    "\n",
    "    axes[0].imshow(anchor_image)\n",
    "    axes[0].set_title(f\"Anchor Tile: {anchor_id}\\n\\n{wrap_text(anchor_text)}\", fontsize=10)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i, row in enumerate(neighbor_nodes_df.itertuples(index=False)):\n",
    "        ax_neighbor = axes[i + 1]\n",
    "        ax_neighbor.imshow(neighbor_images[i])\n",
    "        title = (\n",
    "            f\"Neighbor {i+1} (ID: {row.tile_id})\\n\"\n",
    "            f\"Dist: {row.distance:.2f}, Alpha: {row.alpha:.2f}\\n\\n\" # ç°åœ¨å¯ä»¥å®‰å…¨è®¿é—® row.distance\n",
    "            f\"{wrap_text(row.gene_sentence)}\"\n",
    "        )\n",
    "        ax_neighbor.set_title(title, fontsize=10)\n",
    "        ax_neighbor.axis('off')\n",
    "        \n",
    "    plt.suptitle(f\"Data Retrieval for Sample '{random_sample_id}'\", fontsize=16, y=1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- è¿è¡Œå¯è§†åŒ– ---\n",
    "if not DRYRUN:\n",
    "    try:\n",
    "        # å‡è®¾ nodes_df å’Œ edges_df å¯èƒ½å·²åœ¨å†…å­˜ä¸­\n",
    "        visualize_retrieval(nodes_df, edges_df)\n",
    "    except NameError:\n",
    "        # å¦‚æœå˜é‡ä¸åœ¨å†…å­˜ä¸­ï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½\n",
    "        visualize_retrieval()\n",
    "else:\n",
    "    logging.info(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡å¯è§†åŒ–ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4387ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb2b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gigapath)",
   "language": "python",
   "name": "gigapath"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
