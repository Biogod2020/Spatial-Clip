===== ./notebooks/d1_dataset_construct_cw.ipynb =====
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a3668ee",
      "metadata": {},
      "source": [
        "# Cell 1: å¯¼å…¥ (Imports)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "85d41fbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import re\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# (Review #1) å¯¼å…¥ PIL å¹¶è®¾ç½®ä»¥å¤„ç†æˆªæ–­å›¾åƒ\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# (Review #3) å¯¼å…¥ pyarrow ç”¨äºæ›´ç¨³å¥çš„ Parquet å†™å…¥\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# ç¡®ä¿ open_clip åœ¨ Python è·¯å¾„ä¸­\n",
        "# sys.path.append('/path/to/your/open_clip/src')\n",
        "import open_clip\n",
        "\n",
        "# é…ç½®æ—¥å¿—è®°å½•\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    stream=sys.stdout\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b59619",
      "metadata": {},
      "source": [
        "# Cell 2: é…ç½® (Configuration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "482d3545",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-03 11:30:13,981 - INFO - è®¾å¤‡: cuda:2\n",
            "2025-09-03 11:30:13,981 - INFO - é¢„æ¼”æ¨¡å¼ (DRYRUN): False\n"
          ]
        }
      ],
      "source": [
        "# --- æ ¸å¿ƒé…ç½® ---\n",
        "# ğŸ›¡ï¸ å®‰å…¨ç¬¬ä¸€: é»˜è®¤åœ¨é¢„æ¼”æ¨¡å¼ä¸‹è¿è¡Œ\n",
        "DRYRUN = False\n",
        "\n",
        "# (Review #12) è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§\n",
        "def set_seed(seed=2025):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(2025)\n",
        "\n",
        "# è·¯å¾„é…ç½®\n",
        "BASE_DIR = Path(\"/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/\")\n",
        "TRAIN_MANIFEST = BASE_DIR / \"train_manifest.csv\"\n",
        "VALID_MANIFEST = BASE_DIR / \"validation_manifest.csv\"\n",
        "MODEL_CHECKPOINT = BASE_DIR / \"omiclip_epoch_50.pt\"\n",
        "\n",
        "# (Review #8) æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "for p in [TRAIN_MANIFEST, VALID_MANIFEST, MODEL_CHECKPOINT]:\n",
        "    assert p.exists(), f\"å…³é”®æ–‡ä»¶ç¼ºå¤±: {p}\"\n",
        "\n",
        "# (Review #4) å®šä¹‰æ›´é²æ£’çš„æ­£åˆ™è¡¨è¾¾å¼\n",
        "FILENAME_REGEX = re.compile(r'(.+?)_(-?\\d+)_(-?\\d+)\\.(png|jpg|jpeg|tif|tiff)$', re.IGNORECASE)\n",
        "\n",
        "# æ¨¡å‹é…ç½®\n",
        "MODEL_NAME = \"ViT-B-32\"\n",
        "\n",
        "# é‚»åŸŸè®¡ç®—é…ç½®\n",
        "K_NEIGHBORS = 6\n",
        "\n",
        "# æ‰¹å¤„ç†å’Œè®¾å¤‡é…ç½®\n",
        "BATCH_SIZE = 128  # (Review #9) é™ä½é»˜è®¤æ‰¹æ¬¡å¤§å°ä»¥æé«˜å…¼å®¹æ€§\n",
        "\n",
        "# (Review #2) ç¨³å¥çš„è®¾å¤‡é€‰æ‹©é€»è¾‘\n",
        "def pick_device(prefer_cuda_index: int = 2) -> str:\n",
        "    if torch.cuda.is_available():\n",
        "        n = torch.cuda.device_count()\n",
        "        idx = prefer_cuda_index if prefer_cuda_index < n else 0\n",
        "        return f\"cuda:{idx}\"\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    return \"cpu\"\n",
        "DEVICE = pick_device(prefer_cuda_index=2)\n",
        "\n",
        "# è¾“å‡ºé…ç½®\n",
        "ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
        "OUTPUT_NODES_PATH = ARTIFACTS_DIR / \"nodes.parquet\"\n",
        "OUTPUT_EDGES_PATH = ARTIFACTS_DIR / \"edges.parquet\"\n",
        "OUTPUT_IMG_EMBED_PATH = ARTIFACTS_DIR / \"image_embeds.npy\"\n",
        "OUTPUT_TXT_EMBED_PATH = ARTIFACTS_DIR / \"text_embeds.npy\"\n",
        "\n",
        "# (Review #13) æ˜¾å¼åˆ›å»ºç›®å½•\n",
        "if not DRYRUN:\n",
        "    ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "    (ARTIFACTS_DIR / \"clip_cache\").mkdir(exist_ok=True, parents=True)\n",
        "    \n",
        "logging.info(f\"è®¾å¤‡: {DEVICE}\")\n",
        "logging.info(f\"é¢„æ¼”æ¨¡å¼ (DRYRUN): {DRYRUN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d89259",
      "metadata": {},
      "source": [
        "# Cell 3: æ ¸å¿ƒé€»è¾‘ - æ•°æ®åŠ è½½ä¸å¤„ç† (Core Logic - Data Loading & Processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "aa3df7d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm.contrib.concurrent import process_map\n",
        "\n",
        "# (Review #1) å¯¼å…¥ PIL å¹¶è®¾ç½®ä»¥å¤„ç†æˆªæ–­å›¾åƒ\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# --- æ–°å¢ï¼šå¥å£®çš„å›¾åƒéªŒè¯å‡½æ•° ---\n",
        "def is_image_valid(filepath: str) -> bool:\n",
        "    \"\"\"\n",
        "    æ£€æŸ¥å•ä¸ªå›¾åƒæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚\n",
        "    è¿”å› True å¦‚æœæ–‡ä»¶å­˜åœ¨ã€å¤§å°ä¸ä¸ºé›¶ä¸”å¯ä»¥è¢«PILè¯†åˆ«ã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        p = Path(filepath)\n",
        "        # 1. å¿«é€Ÿæ£€æŸ¥ï¼šæ˜¯å¦å­˜åœ¨å’Œå¤§å°æ˜¯å¦ä¸º0\n",
        "        if not p.exists() or p.stat().st_size == 0:\n",
        "            return False\n",
        "        # 2. æ·±åº¦æ£€æŸ¥ï¼šPILèƒ½å¦æ‰“å¼€å¹¶éªŒè¯\n",
        "        with Image.open(p) as img:\n",
        "            img.verify()  # å¿«é€Ÿæ£€æŸ¥æ–‡ä»¶å¤´å’Œå…ƒæ•°æ®\n",
        "        return True\n",
        "    except Exception:\n",
        "        # æ•è·æ‰€æœ‰å¼‚å¸¸ (FileNotFoundError, PIL.UnidentifiedImageError, etc.)\n",
        "        return False\n",
        "# ------------------------------------\n",
        "\n",
        "def parse_path(path_str: str) -> Tuple[str, int, int]:\n",
        "    \"\"\"ä»å›¾åƒè·¯å¾„ä¸­è§£æ sample_id, x, y åæ ‡ã€‚\"\"\"\n",
        "    m = FILENAME_REGEX.search(Path(path_str).name)\n",
        "    if not m:\n",
        "        raise ValueError(f\"æ— æ³•è§£æè·¯å¾„æ ¼å¼: {path_str}\")\n",
        "    sample_id, x, y, _ = m.groups()\n",
        "    return sample_id, int(x), int(y)\n",
        "\n",
        "def find_malformed_paths(paths: pd.Series) -> List[str]:\n",
        "    \"\"\"å¿«é€ŸæŸ¥æ‰¾æ‰€æœ‰ä¸ç¬¦åˆé¢„æœŸæ ¼å¼çš„è·¯å¾„ã€‚\"\"\"\n",
        "    return [p for p in paths if not FILENAME_REGEX.search(Path(p).name)]\n",
        "\n",
        "def load_and_prepare_data(manifest_paths: List[Path]) -> pd.DataFrame:\n",
        "    \"\"\"åŠ è½½ã€åˆå¹¶ã€éªŒè¯ã€è§£æå¹¶ç´¢å¼•æ¸…å•æ–‡ä»¶ã€‚\"\"\"\n",
        "    logging.info(f\"ä» {manifest_paths} åŠ è½½æ¸…å•...\")\n",
        "    df = pd.concat([pd.read_csv(p) for p in manifest_paths], ignore_index=True)\n",
        "\n",
        "    required_cols = {\"image_path\", \"gene_sentence\"}\n",
        "    assert required_cols.issubset(df.columns), f\"æ¸…å•ç¼ºå°‘åˆ—: {required_cols - set(df.columns)}\"\n",
        "\n",
        "    # --- BUG FIX & ROBUSTNESS ---\n",
        "    # åœ¨åŠ è½½ä»»ä½•æ•°æ®å‰ï¼Œå¹¶è¡ŒéªŒè¯æ‰€æœ‰å›¾åƒæ–‡ä»¶çš„æœ‰æ•ˆæ€§\n",
        "    logging.info(f\"å¼€å§‹å¹¶è¡ŒéªŒè¯ {len(df)} ä¸ªå›¾åƒæ–‡ä»¶...\")\n",
        "    image_paths = df['image_path'].tolist()\n",
        "    # ä½¿ç”¨ process_map å¹¶è¡Œå¤„ç†ï¼Œå¹¶æ˜¾ç¤ºè¿›åº¦æ¡\n",
        "    # max_workers=None ä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ\n",
        "    is_valid_mask = process_map(is_image_valid, image_paths, max_workers=None, chunksize=100)\n",
        "    \n",
        "    num_original = len(df)\n",
        "    df_valid = df[is_valid_mask].copy() # ä½¿ç”¨ .copy() é¿å… SettingWithCopyWarning\n",
        "    num_valid = len(df_valid)\n",
        "    num_removed = num_original - num_valid\n",
        "    \n",
        "    if num_removed > 0:\n",
        "        logging.warning(f\"éªŒè¯å®Œæˆã€‚ç§»é™¤äº† {num_removed} ä¸ªæ— æ•ˆæˆ–æŸåçš„å›¾åƒæ¡ç›®ã€‚\")\n",
        "    else:\n",
        "        logging.info(\"éªŒè¯å®Œæˆã€‚æ‰€æœ‰å›¾åƒæ–‡ä»¶å‡æœ‰æ•ˆã€‚\")\n",
        "    # ----------------------------\n",
        "\n",
        "    logging.info(\"é¢„æ£€æŸ¥æ‰€æœ‰è·¯å¾„æ ¼å¼...\")\n",
        "    malformed = find_malformed_paths(df_valid['image_path'])\n",
        "    if malformed:\n",
        "        logging.error(f\"å‘ç° {len(malformed)} ä¸ªæ ¼å¼é”™è¯¯çš„è·¯å¾„ã€‚ç¤ºä¾‹: {malformed[:5]}\")\n",
        "    else:\n",
        "        logging.info(\"æ‰€æœ‰è·¯å¾„æ ¼å¼å‡æœ‰æ•ˆã€‚\")\n",
        "\n",
        "    logging.info(\"è§£ææ–‡ä»¶åä»¥æå–åæ ‡å’Œæ ·æœ¬ID...\")\n",
        "    path_data = df_valid['image_path'].apply(parse_path)\n",
        "    \n",
        "    parsed_info_df = pd.DataFrame(path_data.tolist(), columns=['sample_id', 'x', 'y'], index=df_valid.index)\n",
        "    df_final = df_valid.join(parsed_info_df)\n",
        "    df_final = df_final.astype({'sample_id': 'object', 'x': 'int32', 'y': 'int32'})\n",
        "    \n",
        "    df_final.reset_index(drop=True, inplace=True) # ä½¿ç”¨ drop=True é¿å…æ—§ç´¢å¼•æˆä¸ºæ–°åˆ—\n",
        "    df_final.reset_index(inplace=True)\n",
        "    df_final.rename(columns={'index': 'tile_id'}, inplace=True)\n",
        "    df_final['tile_id'] = df_final['tile_id'].astype('int64')\n",
        "    \n",
        "    logging.info(f\"æ•°æ®åŠ è½½å®Œæˆã€‚æœ‰æ•ˆå›¾å—æ€»æ•° {len(df_final)}ï¼Œåˆ†å¸ƒåœ¨ {df_final['sample_id'].nunique()} ä¸ªæ ·æœ¬ä¸­ã€‚\")\n",
        "    return df_final\n",
        "\n",
        "def compute_neighborhoods(df: pd.DataFrame, k: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"æŒ‰æ ·æœ¬åˆ†ç»„è®¡ç®—k-æœ€è¿‘é‚»ï¼Œè¿”å›èŠ‚ç‚¹å’Œè¾¹DataFrameã€‚\"\"\"\n",
        "    logging.info(f\"å¼€å§‹è®¡ç®— k={k} çš„æœ€è¿‘é‚»...\")\n",
        "    \n",
        "    edges = []\n",
        "    \n",
        "    for sample_id, group in tqdm(df.groupby('sample_id'), desc=\"å¤„ç†æ ·æœ¬\"):\n",
        "        coords = group[['x', 'y']].values\n",
        "        n_neighbors = min(k + 1, len(coords))\n",
        "        if n_neighbors <= 1:\n",
        "            continue\n",
        "\n",
        "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(coords)\n",
        "        distances, indices = nbrs.kneighbors(coords)\n",
        "        \n",
        "        distances, indices = distances[:, 1:], indices[:, 1:]\n",
        "        \n",
        "        non_zero_distances = distances[distances > 0]\n",
        "        sigma = np.percentile(non_zero_distances, 50) if non_zero_distances.size > 0 else 1.0\n",
        "        sigma = max(sigma, 1e-6)\n",
        "\n",
        "        weights = np.exp(- (distances ** 2) / (2 * sigma ** 2))\n",
        "        \n",
        "        sum_w = weights.sum(axis=1, keepdims=True)\n",
        "        alpha = np.divide(weights, np.maximum(sum_w, 1e-8))\n",
        "\n",
        "        src_tile_ids = group['tile_id'].values\n",
        "        neighbor_tile_ids = src_tile_ids[indices]\n",
        "\n",
        "        for i in range(len(group)):\n",
        "            src_id = src_tile_ids[i]\n",
        "            for j in range(indices.shape[1]):\n",
        "                edges.append((\n",
        "                    src_id,\n",
        "                    neighbor_tile_ids[i, j],\n",
        "                    distances[i, j],\n",
        "                    weights[i, j],\n",
        "                    alpha[i, j]\n",
        "                ))\n",
        "\n",
        "    logging.info(\"é‚»åŸŸè®¡ç®—å®Œæˆã€‚\")\n",
        "    edges_df = pd.DataFrame(edges, columns=[\n",
        "        \"src_tile_id\", \"nbr_tile_id\", \"distance\", \"weight\", \"alpha\"\n",
        "    ]).astype({\n",
        "        \"src_tile_id\": \"int64\", \"nbr_tile_id\": \"int64\",\n",
        "        \"distance\": \"float32\", \"weight\": \"float32\", \"alpha\": \"float32\"\n",
        "    })\n",
        "\n",
        "    nodes_df = df[['tile_id', 'sample_id', 'x', 'y', 'image_path', 'gene_sentence']].copy()\n",
        "    return nodes_df, edges_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6757c67e",
      "metadata": {},
      "source": [
        "# Cell 4: æ ¸å¿ƒé€»è¾‘ - åµŒå…¥ç¼“å­˜ (Core Logic - Embedding Caching)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "78b37bcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClipDataset(Dataset):\n",
        "    \"\"\"ç”¨äºæ‰¹é‡æå–ç‰¹å¾çš„ PyTorch Datasetã€‚\"\"\"\n",
        "    def __init__(self, df: pd.DataFrame, preprocess_fn, tokenizer):\n",
        "        self.df = df\n",
        "        self.preprocess = preprocess_fn\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = self.preprocess(Image.open(row['image_path']).convert(\"RGB\"))\n",
        "        # (Review #5) ç¡®ä¿å§‹ç»ˆä¼ é€’åˆ—è¡¨ç»™ tokenizer\n",
        "        text = self.tokenizer([row['gene_sentence']])[0]\n",
        "        return image, text\n",
        "\n",
        "def cache_embeddings(df: pd.DataFrame, model_name: str, checkpoint_path: Path, device: str, batch_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"ä¸ºæ‰€æœ‰å›¾å—ç”Ÿæˆå›¾åƒå’Œæ–‡æœ¬åµŒå…¥ã€‚\"\"\"\n",
        "    logging.info(f\"åŠ è½½æ¨¡å‹ {model_name} ä»æ£€æŸ¥ç‚¹ {checkpoint_path}...\")\n",
        "    \n",
        "    model, _, preprocess_val = open_clip.create_model_and_transforms(\n",
        "        model_name, pretrained=None, cache_dir=str(ARTIFACTS_DIR / \"clip_cache\")\n",
        "    )\n",
        "    \n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
        "    if all(key.startswith('module.') for key in state_dict.keys()):\n",
        "        state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
        "    model.load_state_dict(state_dict)\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    tokenizer = open_clip.get_tokenizer(model_name)\n",
        "    dataset = ClipDataset(df, preprocess_val, tokenizer)\n",
        "    \n",
        "    # (Review #9) ä¼˜åŒ– DataLoader\n",
        "    pin_memory = device.startswith(\"cuda\")\n",
        "    num_workers = 16\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=pin_memory, persistent_workers=(num_workers > 0)\n",
        "    )\n",
        "    \n",
        "    image_embeds, text_embeds = [], []\n",
        "    # (Review #9) ä½¿ç”¨ torch.inference_mode()\n",
        "    with torch.inference_mode():\n",
        "        for images, texts in tqdm(dataloader, desc=\"æå–åµŒå…¥\"):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            texts = texts.to(device, non_blocking=True)\n",
        "            \n",
        "            image_features = model.encode_image(images)\n",
        "            text_features = model.encode_text(texts)\n",
        "            \n",
        "            image_features = F.normalize(image_features, p=2, dim=-1)\n",
        "            text_features = F.normalize(text_features, p=2, dim=-1)\n",
        "            \n",
        "            image_embeds.append(image_features.cpu().numpy())\n",
        "            text_embeds.append(text_features.cpu().numpy())\n",
        "\n",
        "    img_emb_array = np.vstack(image_embeds).astype(\"float32\")\n",
        "    txt_emb_array = np.vstack(text_embeds).astype(\"float32\")\n",
        "    \n",
        "    logging.info(\"åµŒå…¥æå–å®Œæˆã€‚\")\n",
        "    return img_emb_array, txt_emb_array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa0f573a",
      "metadata": {},
      "source": [
        "# Cell 5: ä¸»æµç¨‹ä¸äº¤ä»˜ (Main Orchestration & Delivery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "4a6ffc6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-03 11:04:54,416 - INFO - ä» [PosixPath('/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/train_manifest.csv'), PosixPath('/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/validation_manifest.csv')] åŠ è½½æ¸…å•...\n",
            "2025-09-03 11:04:58,560 - INFO - å¼€å§‹å¹¶è¡ŒéªŒè¯ 952909 ä¸ªå›¾åƒæ–‡ä»¶...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad97848cff4a420ea60499bfb58346d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/952909 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-03 11:10:18,086 - WARNING - éªŒè¯å®Œæˆã€‚ç§»é™¤äº† 1 ä¸ªæ— æ•ˆæˆ–æŸåçš„å›¾åƒæ¡ç›®ã€‚\n",
            "2025-09-03 11:10:18,088 - INFO - é¢„æ£€æŸ¥æ‰€æœ‰è·¯å¾„æ ¼å¼...\n",
            "2025-09-03 11:10:22,158 - INFO - æ‰€æœ‰è·¯å¾„æ ¼å¼å‡æœ‰æ•ˆã€‚\n",
            "2025-09-03 11:10:22,160 - INFO - è§£ææ–‡ä»¶åä»¥æå–åæ ‡å’Œæ ·æœ¬ID...\n",
            "2025-09-03 11:10:27,192 - INFO - æ•°æ®åŠ è½½å®Œæˆã€‚æœ‰æ•ˆå›¾å—æ€»æ•° 952908ï¼Œåˆ†å¸ƒåœ¨ 475 ä¸ªæ ·æœ¬ä¸­ã€‚\n",
            "2025-09-03 11:10:27,318 - INFO - å¼€å§‹è®¡ç®— k=6 çš„æœ€è¿‘é‚»...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de25137983e04cd9a53adda15c57ccd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "å¤„ç†æ ·æœ¬:   0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-03 11:10:34,339 - INFO - é‚»åŸŸè®¡ç®—å®Œæˆã€‚\n",
            "2025-09-03 11:10:41,038 - INFO - åŠ è½½æ¨¡å‹ ViT-B-32 ä»æ£€æŸ¥ç‚¹ /cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt...\n",
            "2025-09-03 11:10:41,041 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-03 11:10:41,042 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-03 11:10:41,042 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-03 11:10:41,043 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-03 11:10:42,253 - WARNING - Model ViT-B-32 initialized partially.\n",
            "2025-09-03 11:10:42,254 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-03 11:10:42,254 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-03 11:10:43,467 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-03 11:10:43,468 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-03 11:10:43,469 - INFO - Using default SimpleTokenizer.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3047d2a2870447188f4c41ecdb8eab9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "æå–åµŒå…¥:   0%|          | 0/7445 [00:03<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-03 11:21:17,215 - INFO - åµŒå…¥æå–å®Œæˆã€‚\n",
            "2025-09-03 11:21:17,259 - INFO - å¼€å§‹å°†æ•°æ®å†™å…¥ç£ç›˜...\n",
            "2025-09-03 11:21:22,628 - INFO - åµŒå…¥å·²ä¿å­˜åˆ° .npy æ–‡ä»¶: artifacts/image_embeds.npy, artifacts/text_embeds.npy\n",
            "2025-09-03 11:21:25,490 - INFO - èŠ‚ç‚¹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: artifacts/nodes.parquet\n",
            "2025-09-03 11:21:26,659 - INFO - è¾¹(é‚»åŸŸ)æ•°æ®å·²ä¿å­˜åˆ°: artifacts/edges.parquet\n",
            "2025-09-03 11:21:26,663 - INFO - æ‰€æœ‰æ–‡ä»¶ä¿å­˜æˆåŠŸï¼\n"
          ]
        }
      ],
      "source": [
        "def run_step0_preprocessing():\n",
        "    \"\"\"æ‰§è¡ŒStep 0çš„å®Œæ•´æµç¨‹ã€‚\"\"\"\n",
        "    # 1. åŠ è½½å’Œå‡†å¤‡æ•°æ®\n",
        "    base_df = load_and_prepare_data([TRAIN_MANIFEST, VALID_MANIFEST])\n",
        "    \n",
        "    # 2. è®¡ç®—é‚»åŸŸï¼Œå¾—åˆ°èŠ‚ç‚¹å’Œè¾¹è¡¨\n",
        "    nodes_df, edges_df = compute_neighborhoods(base_df, k=K_NEIGHBORS)\n",
        "    \n",
        "    # 3. ç¼“å­˜åµŒå…¥\n",
        "    img_embeds, txt_embeds = cache_embeddings(\n",
        "        nodes_df, # ä»…éœ€èŠ‚ç‚¹ä¿¡æ¯æ¥æå–åµŒå…¥\n",
        "        model_name=MODEL_NAME,\n",
        "        checkpoint_path=MODEL_CHECKPOINT,\n",
        "        device=DEVICE,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "    \n",
        "    # 4. (Review #3, #10) æ‹†åˆ†å­˜å‚¨åˆ° Parquet å’Œ Numpy æ–‡ä»¶\n",
        "    if not DRYRUN:\n",
        "        logging.info(\"å¼€å§‹å°†æ•°æ®å†™å…¥ç£ç›˜...\")\n",
        "        \n",
        "        # ä¿å­˜åµŒå…¥\n",
        "        np.save(OUTPUT_IMG_EMBED_PATH, img_embeds)\n",
        "        np.save(OUTPUT_TXT_EMBED_PATH, txt_embeds)\n",
        "        logging.info(f\"åµŒå…¥å·²ä¿å­˜åˆ° .npy æ–‡ä»¶: {OUTPUT_IMG_EMBED_PATH}, {OUTPUT_TXT_EMBED_PATH}\")\n",
        "        \n",
        "        # ä½¿ç”¨ PyArrow ä¿å­˜ Parquet æ–‡ä»¶ï¼Œæ›´ç¨³å¥\n",
        "        pq.write_table(pa.Table.from_pandas(nodes_df, preserve_index=False), OUTPUT_NODES_PATH)\n",
        "        logging.info(f\"èŠ‚ç‚¹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_NODES_PATH}\")\n",
        "        \n",
        "        pq.write_table(pa.Table.from_pandas(edges_df, preserve_index=False), OUTPUT_EDGES_PATH)\n",
        "        logging.info(f\"è¾¹(é‚»åŸŸ)æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_EDGES_PATH}\")\n",
        "        \n",
        "        logging.info(\"æ‰€æœ‰æ–‡ä»¶ä¿å­˜æˆåŠŸï¼\")\n",
        "    else:\n",
        "        logging.warning(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œæ–‡ä»¶æœªè¢«å†™å…¥ã€‚\")\n",
        "        logging.info(\"èŠ‚ç‚¹è¡¨é¢„è§ˆ:\\n\" + str(nodes_df.head()))\n",
        "        logging.info(\"è¾¹è¡¨é¢„è§ˆ:\\n\" + str(edges_df.head()))\n",
        "        logging.info(f\"å›¾åƒåµŒå…¥æ•°ç»„å½¢çŠ¶: {img_embeds.shape}\")\n",
        "        logging.info(f\"æ–‡æœ¬åµŒå…¥æ•°ç»„å½¢çŠ¶: {txt_embeds.shape}\")\n",
        "\n",
        "    return nodes_df, edges_df, img_embeds, txt_embeds\n",
        "\n",
        "# æ‰§è¡Œä¸»æµç¨‹\n",
        "nodes_df, edges_df, img_embeds, txt_embeds = run_step0_preprocessing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b482c4f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-03 11:30:35,497 - INFO - å¼€å§‹éªŒè¯æ‹†åˆ†åçš„æ–‡ä»¶...\n",
            "2025-09-03 11:30:35,500 - INFO - æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²æ‰¾åˆ°ã€‚\n",
            "2025-09-03 11:30:38,200 - INFO - âœ… èŠ‚ç‚¹è¡¨åŸºæœ¬ç»“æ„æ­£ç¡®ã€‚\n",
            "2025-09-03 11:30:38,699 - INFO - âœ… è¾¹è¡¨åŸºæœ¬ç»“æ„å’Œå¼•ç”¨å®Œæ•´æ€§æ­£ç¡®ã€‚\n",
            "2025-09-03 11:30:39,842 - INFO - âœ… åµŒå…¥æ•°ç»„å½¢çŠ¶å’Œç»´åº¦æ­£ç¡®ã€‚\n",
            "2025-09-03 11:30:39,843 - INFO - ğŸ‰ å…¨éƒ¨éªŒè¯æˆåŠŸï¼æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€æ­¥ã€‚\n"
          ]
        }
      ],
      "source": [
        "def validate_output_revised():\n",
        "    \"\"\"åŠ è½½å¹¶éªŒè¯æ–°ç”Ÿæˆçš„æ‰€æœ‰æ–‡ä»¶ã€‚\"\"\"\n",
        "    logging.info(\"å¼€å§‹éªŒè¯æ‹†åˆ†åçš„æ–‡ä»¶...\")\n",
        "    \n",
        "    paths_to_check = [\n",
        "        OUTPUT_NODES_PATH, OUTPUT_EDGES_PATH, \n",
        "        OUTPUT_IMG_EMBED_PATH, OUTPUT_TXT_EMBED_PATH\n",
        "    ]\n",
        "    \n",
        "    for p in paths_to_check:\n",
        "        if not p.exists():\n",
        "            logging.error(f\"éªŒè¯å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ï¼{p}ã€‚è¯·ç¡®ä¿ DRYRUN=False å¹¶é‡æ–°è¿è¡Œã€‚\")\n",
        "            return\n",
        "    logging.info(\"æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²æ‰¾åˆ°ã€‚\")\n",
        "\n",
        "    # 1. éªŒè¯èŠ‚ç‚¹è¡¨ (nodes.parquet)\n",
        "    nodes = pd.read_parquet(OUTPUT_NODES_PATH)\n",
        "    assert not nodes.empty, \"èŠ‚ç‚¹è¡¨ä¸åº”ä¸ºç©º\"\n",
        "    assert nodes['tile_id'].is_unique, \"èŠ‚ç‚¹è¡¨ä¸­çš„ tile_id åº”å”¯ä¸€\"\n",
        "    assert nodes['tile_id'].dtype == 'int64'\n",
        "    assert nodes['x'].dtype == 'int32'\n",
        "    logging.info(\"âœ… èŠ‚ç‚¹è¡¨åŸºæœ¬ç»“æ„æ­£ç¡®ã€‚\")\n",
        "\n",
        "    # 2. éªŒè¯è¾¹è¡¨ (edges.parquet)\n",
        "    edges = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
        "    assert not edges.empty, \"è¾¹è¡¨ä¸åº”ä¸ºç©º\"\n",
        "    assert 'src_tile_id' in edges.columns and 'nbr_tile_id' in edges.columns\n",
        "    assert edges['src_tile_id'].isin(nodes['tile_id']).all(), \"è¾¹è¡¨ä¸­çš„æºIDåº”åœ¨èŠ‚ç‚¹è¡¨ä¸­\"\n",
        "    assert edges['nbr_tile_id'].isin(nodes['tile_id']).all(), \"è¾¹è¡¨ä¸­çš„é‚»å±…IDåº”åœ¨èŠ‚ç‚¹è¡¨ä¸­\"\n",
        "    assert edges['alpha'].dtype == 'float32'\n",
        "    max_neighbors = edges.groupby('src_tile_id').size().max()\n",
        "    assert max_neighbors <= K_NEIGHBORS, f\"å•ä¸ªèŠ‚ç‚¹çš„æœ€å¤§é‚»å±…æ•° ({max_neighbors}) è¶…è¿‡ k={K_NEIGHBORS}\"\n",
        "    logging.info(\"âœ… è¾¹è¡¨åŸºæœ¬ç»“æ„å’Œå¼•ç”¨å®Œæ•´æ€§æ­£ç¡®ã€‚\")\n",
        "\n",
        "    # 3. éªŒè¯åµŒå…¥æ•°ç»„ (.npy)\n",
        "    img_e = np.load(OUTPUT_IMG_EMBED_PATH)\n",
        "    txt_e = np.load(OUTPUT_TXT_EMBED_PATH)\n",
        "    assert img_e.shape[0] == len(nodes), \"å›¾åƒåµŒå…¥æ•°é‡åº”ä¸èŠ‚ç‚¹æ•°é‡åŒ¹é…\"\n",
        "    assert txt_e.shape[0] == len(nodes), \"æ–‡æœ¬åµŒå…¥æ•°é‡åº”ä¸èŠ‚ç‚¹æ•°é‡åŒ¹é…\"\n",
        "    \n",
        "    # å‡è®¾ ViT-B-32 çš„åµŒå…¥ç»´åº¦æ˜¯ 512\n",
        "    embed_dim = 512\n",
        "    assert img_e.shape[1] == embed_dim, f\"å›¾åƒåµŒå…¥ç»´åº¦é”™è¯¯ (åº”ä¸º {embed_dim})\"\n",
        "    assert txt_e.shape[1] == embed_dim, f\"æ–‡æœ¬åµŒå…¥ç»´åº¦é”™è¯¯ (åº”ä¸º {embed_dim})\"\n",
        "    logging.info(\"âœ… åµŒå…¥æ•°ç»„å½¢çŠ¶å’Œç»´åº¦æ­£ç¡®ã€‚\")\n",
        "\n",
        "    logging.info(\"ğŸ‰ å…¨éƒ¨éªŒè¯æˆåŠŸï¼æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€æ­¥ã€‚\")\n",
        "\n",
        "# è¿è¡ŒéªŒè¯\n",
        "if not DRYRUN:\n",
        "    validate_output_revised()\n",
        "else:\n",
        "    logging.info(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡éªŒè¯ã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632eab82",
      "metadata": {},
      "source": [
        "# Cell 6 Visualization Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "d34feace",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_neighborhood(nodes_df: pd.DataFrame, edges_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Randomly select a tile and visualize its position and neighbors in the sample space.\n",
        "    \"\"\"\n",
        "    # Ensure data is loaded\n",
        "    if 'nodes_df' not in locals() or 'edges_df' not in locals():\n",
        "        logging.info(\"Loading data from disk for visualization...\")\n",
        "        nodes_df = pd.read_parquet(OUTPUT_NODES_PATH)\n",
        "        edges_df = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
        "\n",
        "    # 1. Random sampling\n",
        "    # Randomly select a sample ID\n",
        "    sample_ids_with_neighbors = edges_df['src_tile_id'].map(nodes_df.set_index('tile_id')['sample_id']).unique()\n",
        "    if len(sample_ids_with_neighbors) == 0:\n",
        "        logging.warning(\"No samples found in edge table, cannot perform visualization.\")\n",
        "        return\n",
        "        \n",
        "    random_sample_id = random.choice(sample_ids_with_neighbors)\n",
        "    \n",
        "    # Get all tiles from this sample\n",
        "    sample_nodes = nodes_df[nodes_df['sample_id'] == random_sample_id]\n",
        "    \n",
        "    # Randomly select an anchor tile from this sample\n",
        "    anchor_tile = sample_nodes.sample(1).iloc[0]\n",
        "    anchor_id = anchor_tile['tile_id']\n",
        "    \n",
        "    logging.info(f\"Visualizing anchor tile ID: {anchor_id} from sample '{random_sample_id}'\")\n",
        "\n",
        "    # 2. Data preparation\n",
        "    # Get neighbor information for the anchor\n",
        "    anchor_edges = edges_df[edges_df['src_tile_id'] == anchor_id]\n",
        "    neighbor_ids = anchor_edges['nbr_tile_id'].tolist()\n",
        "    \n",
        "    # Get neighbor coordinates and weights\n",
        "    neighbor_nodes = nodes_df[nodes_df['tile_id'].isin(neighbor_ids)].merge(\n",
        "        anchor_edges[['nbr_tile_id', 'alpha']],\n",
        "        left_on='tile_id',\n",
        "        right_on='nbr_tile_id'\n",
        "    )\n",
        "\n",
        "    # 3. Visualization\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    \n",
        "    # Draw background: all other points in this sample\n",
        "    ax.scatter(\n",
        "        sample_nodes['x'], sample_nodes['y'],\n",
        "        s=5, c='lightgray', alpha=0.5, label='Background (same sample)'\n",
        "    )\n",
        "    \n",
        "    # Draw neighbors\n",
        "    ax.scatter(\n",
        "        neighbor_nodes['x'], neighbor_nodes['y'],\n",
        "        s=50, c='royalblue', alpha=0.8, label=f'Neighbors (k={len(neighbor_nodes)})'\n",
        "    )\n",
        "    \n",
        "    # Draw anchor point\n",
        "    ax.scatter(\n",
        "        anchor_tile['x'], anchor_tile['y'],\n",
        "        s=200, c='red', marker='*', edgecolors='black', label='Anchor'\n",
        "    )\n",
        "    \n",
        "    # Draw connection lines, transparency determined by alpha\n",
        "    for _, neighbor in neighbor_nodes.iterrows():\n",
        "        ax.plot(\n",
        "            [anchor_tile['x'], neighbor['x']],\n",
        "            [anchor_tile['y'], neighbor['y']],\n",
        "            color='salmon',\n",
        "            linewidth=1.5,\n",
        "            alpha=neighbor['alpha'] * 0.8 + 0.2  # Ensure weakest lines are still visible\n",
        "        )\n",
        "        \n",
        "    # 4. Chart styling\n",
        "    ax.set_title(f\"Neighborhood Visualization (Sample: {random_sample_id}, Anchor ID: {anchor_id})\", fontsize=16)\n",
        "    ax.set_xlabel(\"X Coordinate\", fontsize=12)\n",
        "    ax.set_ylabel(\"Y Coordinate\", fontsize=12)\n",
        "    ax.legend(loc='best')\n",
        "    ax.set_aspect('equal', adjustable='box') # Ensure equal x, y axis ratios\n",
        "    plt.gca().invert_yaxis() # Image coordinate system Y-axis usually points down\n",
        "    plt.show()\n",
        "\n",
        "# --- Run visualization ---\n",
        "# Assume nodes_df and edges_df are already in memory\n",
        "if not DRYRUN:\n",
        "    try:\n",
        "        visualize_neighborhood(nodes_df, edges_df)\n",
        "    except NameError:\n",
        "        # If variables are not in memory, load from files\n",
        "        nodes_df_viz = pd.read_parquet(OUTPUT_NODES_PATH)\n",
        "        edges_df_viz = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
        "        visualize_neighborhood(nodes_df_viz, edges_df_viz)\n",
        "else:\n",
        "    logging.info(\"In dry run mode, skipping visualization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78cb1493",
      "metadata": {},
      "source": [
        "# Cell 6.1 Visualization Validation 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5edc1860",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import textwrap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "def load_image_from_path(path_str: str) -> Image.Image:\n",
        "    \"\"\"Safely loads an image from a path.\"\"\"\n",
        "    try:\n",
        "        return Image.open(path_str).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to load image at {path_str}: {e}\")\n",
        "        # Return a placeholder image on failure\n",
        "        return Image.new('RGB', (224, 224), color = 'red')\n",
        "\n",
        "def visualize_retrieval(nodes_df: pd.DataFrame = None, edges_df: pd.DataFrame = None):\n",
        "    \"\"\"\n",
        "    Randomly selects an anchor tile, retrieves its raw data (image, text), \n",
        "    finds its neighbors, retrieves their raw data, and displays them all.\n",
        "    \"\"\"\n",
        "    # 1. åŠ è½½æ•°æ® (å¦‚æœå°šæœªåŠ è½½)\n",
        "    if nodes_df is None or edges_df is None:\n",
        "        logging.info(\"Visualizer is loading data from disk...\")\n",
        "        if not OUTPUT_NODES_PATH.exists() or not OUTPUT_EDGES_PATH.exists():\n",
        "            logging.error(\"Parquet files not found. Please run the main pipeline first.\")\n",
        "            return\n",
        "        nodes_df = pd.read_parquet(OUTPUT_NODES_PATH)\n",
        "        edges_df = pd.read_parquet(OUTPUT_EDGES_PATH)\n",
        "\n",
        "    # 2. éšæœºæŠ½æ ·ä¸€ä¸ªæœ‰æ„ä¹‰çš„é”šç‚¹\n",
        "    sample_ids_with_neighbors = edges_df['src_tile_id'].map(nodes_df.set_index('tile_id')['sample_id']).unique()\n",
        "    if len(sample_ids_with_neighbors) == 0:\n",
        "        logging.warning(\"No edges found in the dataset. Cannot visualize a neighborhood.\")\n",
        "        return\n",
        "        \n",
        "    random_sample_id = random.choice(sample_ids_with_neighbors)\n",
        "    \n",
        "    possible_anchors = nodes_df[\n",
        "        (nodes_df['sample_id'] == random_sample_id) &\n",
        "        (nodes_df['tile_id'].isin(edges_df['src_tile_id']))\n",
        "    ]\n",
        "    if possible_anchors.empty:\n",
        "        logging.warning(f\"Could not find an anchor with neighbors in sample '{random_sample_id}'. Retrying might help.\")\n",
        "        return\n",
        "        \n",
        "    anchor_tile_series = possible_anchors.sample(1).iloc[0]\n",
        "    anchor_id = anchor_tile_series['tile_id']\n",
        "    \n",
        "    # 3. æ£€ç´¢æ•°æ®\n",
        "    anchor_image = load_image_from_path(anchor_tile_series['image_path'])\n",
        "    anchor_text = anchor_tile_series['gene_sentence']\n",
        "    \n",
        "    anchor_edges = edges_df[edges_df['src_tile_id'] == anchor_id].sort_values('distance')\n",
        "    neighbor_ids = anchor_edges['nbr_tile_id'].tolist()\n",
        "    \n",
        "    # --- BUG FIX ---\n",
        "    # é”™è¯¯åŸå› ï¼šä¹‹å‰çš„ merge æ“ä½œé—æ¼äº† 'distance' åˆ—ã€‚\n",
        "    # ä¿®å¤æ–¹æ¡ˆï¼šåœ¨ merge çš„åˆ—é€‰æ‹©ä¸­åŠ å…¥ 'distance'ã€‚\n",
        "    neighbor_nodes_df = nodes_df[nodes_df['tile_id'].isin(neighbor_ids)].merge(\n",
        "        anchor_edges[['nbr_tile_id', 'distance', 'alpha']], # <-- æ ¸å¿ƒä¿®å¤ç‚¹\n",
        "        left_on='tile_id',\n",
        "        right_on='nbr_tile_id'\n",
        "    ).set_index('tile_id').loc[neighbor_ids].reset_index() # ä¿æŒæ’åº\n",
        "    # --- END FIX ---\n",
        "\n",
        "    neighbor_images = [load_image_from_path(p) for p in neighbor_nodes_df['image_path']]\n",
        "    neighbor_texts = neighbor_nodes_df['gene_sentence'].tolist()\n",
        "    \n",
        "    logging.info(f\"Visualizing anchor tile {anchor_id} and its {len(neighbor_ids)} neighbors from sample '{random_sample_id}'.\")\n",
        "\n",
        "    # 4. å¯è§†åŒ–\n",
        "    num_plots = 1 + len(neighbor_ids)\n",
        "    fig, axes = plt.subplots(1, num_plots, figsize=(num_plots * 4, 4.5))\n",
        "    \n",
        "    def wrap_text(text, width=40):\n",
        "        return textwrap.fill(text, width)\n",
        "\n",
        "    axes[0].imshow(anchor_image)\n",
        "    axes[0].set_title(f\"Anchor Tile: {anchor_id}\\n\\n{wrap_text(anchor_text)}\", fontsize=10)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    for i, row in enumerate(neighbor_nodes_df.itertuples(index=False)):\n",
        "        ax_neighbor = axes[i + 1]\n",
        "        ax_neighbor.imshow(neighbor_images[i])\n",
        "        title = (\n",
        "            f\"Neighbor {i+1} (ID: {row.tile_id})\\n\"\n",
        "            f\"Dist: {row.distance:.2f}, Alpha: {row.alpha:.2f}\\n\\n\" # ç°åœ¨å¯ä»¥å®‰å…¨è®¿é—® row.distance\n",
        "            f\"{wrap_text(row.gene_sentence)}\"\n",
        "        )\n",
        "        ax_neighbor.set_title(title, fontsize=10)\n",
        "        ax_neighbor.axis('off')\n",
        "        \n",
        "    plt.suptitle(f\"Data Retrieval for Sample '{random_sample_id}'\", fontsize=16, y=1.1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- è¿è¡Œå¯è§†åŒ– ---\n",
        "if not DRYRUN:\n",
        "    try:\n",
        "        # å‡è®¾ nodes_df å’Œ edges_df å¯èƒ½å·²åœ¨å†…å­˜ä¸­\n",
        "        visualize_retrieval(nodes_df, edges_df)\n",
        "    except NameError:\n",
        "        # å¦‚æœå˜é‡ä¸åœ¨å†…å­˜ä¸­ï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½\n",
        "        visualize_retrieval()\n",
        "else:\n",
        "    logging.info(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡å¯è§†åŒ–ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4387ce2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffb2b05",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (gigapath)",
      "language": "python",
      "name": "gigapath"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
===== ./notebooks/d2_true_train_val_split.ipynb =====
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ebb022bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Set\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# --- æ ¸å¿ƒé…ç½® ---\n",
        "# ğŸ›¡ï¸ å®‰å…¨ç¬¬ä¸€: è®¾ä¸º False ä»¥å®é™…æ‰§è¡Œæ–‡ä»¶å†™å…¥\n",
        "DRYRUN = False\n",
        "\n",
        "# --- è·¯å¾„é…ç½® ---\n",
        "# è¾“å…¥: åŒ…å«é¢„å¤„ç†åæ•°æ®çš„ç›®å½•\n",
        "INPUT_ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
        "# è¾“å‡º: å°†å­˜æ”¾ train/ å’Œ val/ å­ç›®å½•çš„åŸºå‡†ç›®å½•\n",
        "OUTPUT_SPLIT_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/dataset_split\")\n",
        "\n",
        "# å®šä¹‰åŸå§‹æ¸…å•æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè·å– sample_id\n",
        "ORIGINAL_MANIFEST_FILE = Path(\"/cwStorage/nodecw_group/jijh/hest_1k/HEST_v1_1_0.csv\") \n",
        "\n",
        "# æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "assert INPUT_ARTIFACTS_DIR.exists(), f\"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_ARTIFACTS_DIR}\"\n",
        "assert ORIGINAL_MANIFEST_FILE.exists(), f\"åŸå§‹æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨: {ORIGINAL_MANIFEST_FILE}\"\n",
        "for filename in [\"nodes.parquet\", \"edges.parquet\", \"image_embeds.npy\", \"text_embeds.npy\"]:\n",
        "    assert (INPUT_ARTIFACTS_DIR / filename).exists(), f\"è¾“å…¥æ–‡ä»¶ç¼ºå¤±: {filename}\"\n",
        "\n",
        "# --- æ—¥å¿—é…ç½® ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    stream=sys.stdout\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a686927b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_validation_sample_ids(manifest_path: Path) -> Set[str]:\n",
        "    \"\"\"\n",
        "    æ ¹æ®é¢„å®šä¹‰çš„ç ”ç©¶é¡¹ç›®æ ‡é¢˜ï¼Œä»åŸå§‹æ¸…å•ä¸­è·å–éªŒè¯é›†çš„ sample_id åˆ—è¡¨ã€‚\n",
        "    \"\"\"\n",
        "    df_manifest = pd.read_csv(manifest_path)\n",
        "    \n",
        "    VALIDATION_TITLES = [\n",
        "        \"Spatial deconvolution of HER2-positive breast cancer delineates tumor-associated cell type interactions\",\n",
        "        \"Characterization of immune cell populations in the tumor microenvironment of colorectal cancer using high definition spatial profiling\"\n",
        "    ]\n",
        "    \n",
        "    validation_ids = df_manifest[df_manifest['dataset_title'].isin(VALIDATION_TITLES)]['id'].unique()\n",
        "    \n",
        "    logging.info(f\"ä»æ¸…å•ä¸­ç¡®å®šäº† {len(validation_ids)} ä¸ªç”¨äºéªŒè¯çš„ç‹¬ç«‹æ ·æœ¬ IDã€‚\")\n",
        "    return set(validation_ids)\n",
        "\n",
        "def split_and_save_dataset(\n",
        "    input_dir: Path, \n",
        "    output_dir: Path, \n",
        "    validation_sample_ids: Set[str]\n",
        "):\n",
        "    \"\"\"\n",
        "    åŠ è½½é¢„å¤„ç†çš„æ•°æ®ï¼ŒæŒ‰ sample_id æ‹†åˆ†ä¸ºè®­ç»ƒ/éªŒè¯é›†ï¼Œå¹¶ä¿å­˜åˆ°æ–°ç›®å½•ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(f\"å¼€å§‹ä» '{input_dir}' åŠ è½½æ•°æ®...\")\n",
        "    nodes_df = pd.read_parquet(input_dir / \"nodes.parquet\")\n",
        "    edges_df = pd.read_parquet(input_dir / \"edges.parquet\")\n",
        "    all_img_embeds = np.load(input_dir / \"image_embeds.npy\")\n",
        "    all_txt_embeds = np.load(input_dir / \"text_embeds.npy\")\n",
        "    logging.info(\"æ‰€æœ‰è¾“å…¥æ–‡ä»¶åŠ è½½å®Œæ¯•ã€‚\")\n",
        "\n",
        "    # 1. æ‹†åˆ† Nodes å’Œ Embeddings\n",
        "    val_nodes_mask = nodes_df['sample_id'].isin(validation_sample_ids)\n",
        "    \n",
        "    train_nodes_df = nodes_df[~val_nodes_mask].copy()\n",
        "    val_nodes_df = nodes_df[val_nodes_mask].copy()\n",
        "    \n",
        "    # ä½¿ç”¨åŸå§‹ç´¢å¼•æ¥åˆ‡ç‰‡ numpy æ•°ç»„\n",
        "    train_indices = train_nodes_df.index.to_numpy()\n",
        "    val_indices = val_nodes_df.index.to_numpy()\n",
        "    \n",
        "    train_img_embeds = all_img_embeds[train_indices]\n",
        "    val_img_embeds = all_img_embeds[val_indices]\n",
        "    \n",
        "    train_txt_embeds = all_txt_embeds[train_indices]\n",
        "    val_txt_embeds = all_txt_embeds[val_indices]\n",
        "    \n",
        "    # 2. æ‹†åˆ† Edges\n",
        "    train_tile_ids = set(train_nodes_df['tile_id'])\n",
        "    val_tile_ids = set(val_nodes_df['tile_id'])\n",
        "    \n",
        "    train_edges_mask = edges_df['src_tile_id'].isin(train_tile_ids) & edges_df['nbr_tile_id'].isin(train_tile_ids)\n",
        "    val_edges_mask = edges_df['src_tile_id'].isin(val_tile_ids) & edges_df['nbr_tile_id'].isin(val_tile_ids)\n",
        "    \n",
        "    train_edges_df = edges_df[train_edges_mask].copy()\n",
        "    val_edges_df = edges_df[val_edges_mask].copy()\n",
        "\n",
        "    # 3. æŠ¥å‘Šç»Ÿè®¡æ•°æ®\n",
        "    logging.info(\"--- æ‹†åˆ†ç»Ÿè®¡ ---\")\n",
        "    logging.info(f\"è®­ç»ƒé›†: {len(train_nodes_df)} tiles, {len(train_edges_df)} edges\")\n",
        "    logging.info(f\"éªŒè¯é›†: {len(val_nodes_df)} tiles, {len(val_edges_df)} edges\")\n",
        "    logging.info(\"--------------------\")\n",
        "\n",
        "    # 4. å®‰å…¨å†™å…¥æ–‡ä»¶\n",
        "    if not DRYRUN:\n",
        "        train_dir = output_dir / \"train\"\n",
        "        val_dir = output_dir / \"val\"\n",
        "        train_dir.mkdir(parents=True, exist_ok=True)\n",
        "        val_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        logging.info(f\"æ­£åœ¨å‘ '{train_dir}' å†™å…¥è®­ç»ƒé›†æ–‡ä»¶...\")\n",
        "        pq.write_table(pa.Table.from_pandas(train_nodes_df, preserve_index=False), train_dir / \"nodes.parquet\")\n",
        "        pq.write_table(pa.Table.from_pandas(train_edges_df, preserve_index=False), train_dir / \"edges.parquet\")\n",
        "        np.save(train_dir / \"image_embeds.npy\", train_img_embeds)\n",
        "        np.save(train_dir / \"text_embeds.npy\", train_txt_embeds)\n",
        "        \n",
        "        logging.info(f\"æ­£åœ¨å‘ '{val_dir}' å†™å…¥éªŒè¯é›†æ–‡ä»¶...\")\n",
        "        pq.write_table(pa.Table.from_pandas(val_nodes_df, preserve_index=False), val_dir / \"nodes.parquet\")\n",
        "        pq.write_table(pa.Table.from_pandas(val_edges_df, preserve_index=False), val_dir / \"edges.parquet\")\n",
        "        np.save(val_dir / \"image_embeds.npy\", val_img_embeds)\n",
        "        np.save(val_dir / \"text_embeds.npy\", val_txt_embeds)\n",
        "        \n",
        "        logging.info(\"æ‰€æœ‰æ–‡ä»¶å·²æˆåŠŸå†™å…¥ç£ç›˜ã€‚\")\n",
        "    else:\n",
        "        logging.warning(\"å½“å‰ä¸ºé¢„æ¼”æ¨¡å¼ (DRYRUN=True)ï¼Œæœªæ‰§è¡Œä»»ä½•å†™ç›˜æ“ä½œã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "54be59bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_split(output_dir: Path):\n",
        "    \"\"\"\n",
        "    åŠ è½½æ‹†åˆ†åçš„æ•°æ®å¹¶æ‰§è¡Œä¸€ç³»åˆ—æ£€æŸ¥ä»¥ç¡®ä¿å…¶å®Œæ•´æ€§å’Œæ­£ç¡®æ€§ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(\"--- å¼€å§‹éªŒè¯æ‹†åˆ†åçš„æ•°æ®é›† ---\")\n",
        "    train_dir = output_dir / \"train\"\n",
        "    val_dir = output_dir / \"val\"\n",
        "    \n",
        "    if not train_dir.exists() or not val_dir.exists():\n",
        "        logging.error(\"éªŒè¯å¤±è´¥: è¾“å‡ºç›®å½• train/ æˆ– val/ ä¸å­˜åœ¨ã€‚\")\n",
        "        return\n",
        "\n",
        "    # åŠ è½½æ•°æ®\n",
        "    train_nodes = pd.read_parquet(train_dir / \"nodes.parquet\")\n",
        "    val_nodes = pd.read_parquet(val_dir / \"nodes.parquet\")\n",
        "    train_edges = pd.read_parquet(train_dir / \"edges.parquet\")\n",
        "    val_edges = pd.read_parquet(val_dir / \"edges.parquet\")\n",
        "    train_img_embeds = np.load(train_dir / \"image_embeds.npy\")\n",
        "    val_img_embeds = np.load(val_dir / \"image_embeds.npy\")\n",
        "\n",
        "    # æ£€æŸ¥ 1: æ•°æ®æ³„éœ² (æœ€é‡è¦ï¼)\n",
        "    train_samples = set(train_nodes['sample_id'].unique())\n",
        "    val_samples = set(val_nodes['sample_id'].unique())\n",
        "    common_samples = train_samples.intersection(val_samples)\n",
        "    \n",
        "    assert not common_samples, f\"éªŒè¯å¤±è´¥ï¼šå‘ç°æ•°æ®æ³„éœ²ï¼ä»¥ä¸‹ sample_id åŒæ—¶å­˜åœ¨äºè®­ç»ƒé›†å’ŒéªŒè¯é›†: {common_samples}\"\n",
        "    logging.info(\"âœ… PASSED: è®­ç»ƒé›†ä¸éªŒè¯é›†ä¹‹é—´æ— æ ·æœ¬IDäº¤é›† (æ— æ•°æ®æ³„éœ²)ã€‚\")\n",
        "    \n",
        "    # æ£€æŸ¥ 2: å†…éƒ¨ä¸€è‡´æ€§\n",
        "    assert len(train_nodes) == train_img_embeds.shape[0], \"è®­ç»ƒé›†èŠ‚ç‚¹æ•°ä¸åµŒå…¥æ•°ä¸åŒ¹é…ã€‚\"\n",
        "    assert len(val_nodes) == val_img_embeds.shape[0], \"éªŒè¯é›†èŠ‚ç‚¹æ•°ä¸åµŒå…¥æ•°ä¸åŒ¹é…ã€‚\"\n",
        "    logging.info(\"âœ… PASSED: èŠ‚ç‚¹æ•°ä¸åµŒå…¥æ•°åœ¨å„å­é›†ä¸­ä¿æŒä¸€è‡´ã€‚\")\n",
        "\n",
        "    # æ£€æŸ¥ 3: è¾¹å¼•ç”¨å®Œæ•´æ€§\n",
        "    train_tile_ids = set(train_nodes['tile_id'])\n",
        "    val_tile_ids = set(val_nodes['tile_id'])\n",
        "    assert train_edges['src_tile_id'].isin(train_tile_ids).all(), \"è®­ç»ƒé›†è¾¹è¡¨åŒ…å«æ— æ•ˆçš„æºèŠ‚ç‚¹IDã€‚\"\n",
        "    assert train_edges['nbr_tile_id'].isin(train_tile_ids).all(), \"è®­ç»ƒé›†è¾¹è¡¨åŒ…å«æ— æ•ˆçš„é‚»å±…èŠ‚ç‚¹IDã€‚\"\n",
        "    assert val_edges['src_tile_id'].isin(val_tile_ids).all(), \"éªŒè¯é›†è¾¹è¡¨åŒ…å«æ— æ•ˆçš„æºèŠ‚ç‚¹IDã€‚\"\n",
        "    assert val_edges['nbr_tile_id'].isin(val_tile_ids).all(), \"éªŒè¯é›†è¾¹è¡¨åŒ…å«æ— æ•ˆçš„é‚»å±…èŠ‚ç‚¹IDã€‚\"\n",
        "    logging.info(\"âœ… PASSED: è¾¹è¡¨çš„å¼•ç”¨å®Œæ•´æ€§åœ¨å„å­é›†ä¸­å¾—åˆ°ä¿æŒã€‚\")\n",
        "    \n",
        "    logging.info(\"ğŸ‰ å…¨éƒ¨éªŒè¯æˆåŠŸï¼æ•°æ®é›†å·²å‡†å¤‡å°±ç»ªã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "87fd6ef1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 21:49:58,528 - INFO - ä»æ¸…å•ä¸­ç¡®å®šäº† 44 ä¸ªç”¨äºéªŒè¯çš„ç‹¬ç«‹æ ·æœ¬ IDã€‚\n"
          ]
        }
      ],
      "source": [
        "# --- ä¸»æµç¨‹ ---\n",
        "# 1. ä»åŸå§‹æ¸…å•ä¸­è·å–æƒå¨çš„éªŒè¯é›† sample_id åˆ—è¡¨\n",
        "validation_sample_ids = get_validation_sample_ids(ORIGINAL_MANIFEST_FILE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d90e5bf7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'SPA119',\n",
              " 'SPA120',\n",
              " 'SPA121',\n",
              " 'SPA122',\n",
              " 'SPA123',\n",
              " 'SPA124',\n",
              " 'SPA125',\n",
              " 'SPA126',\n",
              " 'SPA127',\n",
              " 'SPA128',\n",
              " 'SPA129',\n",
              " 'SPA130',\n",
              " 'SPA131',\n",
              " 'SPA132',\n",
              " 'SPA133',\n",
              " 'SPA134',\n",
              " 'SPA135',\n",
              " 'SPA136',\n",
              " 'SPA137',\n",
              " 'SPA138',\n",
              " 'SPA139',\n",
              " 'SPA140',\n",
              " 'SPA141',\n",
              " 'SPA142',\n",
              " 'SPA143',\n",
              " 'SPA144',\n",
              " 'SPA145',\n",
              " 'SPA146',\n",
              " 'SPA147',\n",
              " 'SPA148',\n",
              " 'SPA149',\n",
              " 'SPA150',\n",
              " 'SPA151',\n",
              " 'SPA152',\n",
              " 'SPA153',\n",
              " 'SPA154',\n",
              " 'TENX147',\n",
              " 'TENX148',\n",
              " 'TENX149',\n",
              " 'TENX152',\n",
              " 'TENX153',\n",
              " 'TENX154',\n",
              " 'TENX155',\n",
              " 'TENX156'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_sample_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "18c6b61f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 21:50:08,787 - INFO - å¼€å§‹ä» '/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts' åŠ è½½æ•°æ®...\n",
            "2025-09-13 21:50:24,688 - INFO - æ‰€æœ‰è¾“å…¥æ–‡ä»¶åŠ è½½å®Œæ¯•ã€‚\n",
            "2025-09-13 21:50:28,168 - INFO - --- æ‹†åˆ†ç»Ÿè®¡ ---\n",
            "2025-09-13 21:50:28,171 - INFO - è®­ç»ƒé›†: 919173 tiles, 5515038 edges\n",
            "2025-09-13 21:50:28,172 - INFO - éªŒè¯é›†: 33735 tiles, 202410 edges\n",
            "2025-09-13 21:50:28,173 - INFO - --------------------\n",
            "2025-09-13 21:50:28,177 - INFO - æ­£åœ¨å‘ '/cwStorage/nodecw_group/jijh/yuanspace_data/dataset_split/train' å†™å…¥è®­ç»ƒé›†æ–‡ä»¶...\n",
            "2025-09-13 21:50:50,925 - INFO - æ­£åœ¨å‘ '/cwStorage/nodecw_group/jijh/yuanspace_data/dataset_split/val' å†™å…¥éªŒè¯é›†æ–‡ä»¶...\n",
            "2025-09-13 21:50:51,906 - INFO - æ‰€æœ‰æ–‡ä»¶å·²æˆåŠŸå†™å…¥ç£ç›˜ã€‚\n",
            "2025-09-13 21:50:52,976 - INFO - --- å¼€å§‹éªŒè¯æ‹†åˆ†åçš„æ•°æ®é›† ---\n",
            "2025-09-13 21:50:56,651 - INFO - âœ… PASSED: è®­ç»ƒé›†ä¸éªŒè¯é›†ä¹‹é—´æ— æ ·æœ¬IDäº¤é›† (æ— æ•°æ®æ³„éœ²)ã€‚\n",
            "2025-09-13 21:50:56,652 - INFO - âœ… PASSED: èŠ‚ç‚¹æ•°ä¸åµŒå…¥æ•°åœ¨å„å­é›†ä¸­ä¿æŒä¸€è‡´ã€‚\n",
            "2025-09-13 21:50:57,073 - INFO - âœ… PASSED: è¾¹è¡¨çš„å¼•ç”¨å®Œæ•´æ€§åœ¨å„å­é›†ä¸­å¾—åˆ°ä¿æŒã€‚\n",
            "2025-09-13 21:50:57,075 - INFO - ğŸ‰ å…¨éƒ¨éªŒè¯æˆåŠŸï¼æ•°æ®é›†å·²å‡†å¤‡å°±ç»ªã€‚\n"
          ]
        }
      ],
      "source": [
        "# 2. æ‰§è¡Œæ‹†åˆ†å’Œä¿å­˜\n",
        "split_and_save_dataset(\n",
        "    input_dir=INPUT_ARTIFACTS_DIR,\n",
        "    output_dir=OUTPUT_SPLIT_DIR,\n",
        "    validation_sample_ids=validation_sample_ids\n",
        ")\n",
        "\n",
        "# 3. è¿è¡ŒéªŒè¯è„šæœ¬\n",
        "if not DRYRUN:\n",
        "    validate_split(OUTPUT_SPLIT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5400c47f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (spatial_clip)",
      "language": "python",
      "name": "spatial_clip"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
===== ./notebooks/mergefile.py =====
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import re
from collections import defaultdict

# ========== é…ç½®åŒº ==========

OUTPUT_PATH = "merged_output.txt"
LOG_REPORT_PATH = "merge_report.log"  # ç”¨æ¥å†™è­¦å‘Š / è·³è¿‡ / æŠ¥è¡¨æ—¥å¿—

# è¦åŒ…å«çš„æ‰©å±•åï¼ˆå°å†™ï¼‰ â€”â€” åŒ…æ‹¬ R / ç”Ÿç‰©ä¿¡æ¯å­¦ç›¸å…³è„šæœ¬
INCLUDE_EXT = {
    "py", "ipynb", "txt", "md", "rst", "html", "htm",
    "css", "js", "ts", "jsx", "tsx",
    "java", "kt", "c", "cpp", "h", "hpp", "rs",
    "go", "rb", "sh", "ps1", "yaml", "yml", "json",
    "xml", "ini", "cfg", "toml", "sql", "tex", "scala",
    "php", "swift",
    # ç”Ÿç‰©ä¿¡æ¯å­¦ / ç»Ÿè®¡ / æ•°æ®åˆ†æè¯­è¨€
    "r", "rmd", "bi", "fasta", "fa", "fastq", "fq", "bed", "gtf", "gff", "sam", "bam", "vcf"
}

# è¦æ’é™¤çš„æ‰©å±•åï¼ˆé™¤éä½ æ˜¾å¼å¸Œæœ›æŠŠå®ƒä»¬è¯»è¿›æ¥ï¼‰
EXCLUDE_EXT = {
    "bin", "exe", "dll", "o", "so", "dylib",
    "class", "jar", "pyc", "pyo", "obj", "apk", "war"
}

# æœ€å¤§å…è®¸åˆå¹¶çš„å­—ç¬¦æ•°ï¼ˆé˜²æ­¢è¿‡å¤§æ–‡ä»¶ï¼‰ â€” å¯è°ƒ
MAX_CHAR_COUNT = 10_000_000  # è¶…è¿‡å°±è·³è¿‡

# æœ€å¤§æ–‡ä»¶å­—èŠ‚æ•°é™åˆ¶ï¼ˆå¦‚æœè§‰å¾—æœ‰äº›æ–‡ä»¶è¿‡å¤§åœ¨ç£ç›˜ä¸Šå°±ä¸è¦è¯»ï¼‰ â€” å¯è®¾ None è¡¨ç¤ºä¸é™åˆ¶
MAX_FILE_SIZE = None  

# è­¦æˆ’çº¿ï¼šå½“æ–‡ä»¶å¤§å° / å­—ç¬¦æ•° è¾¾åˆ°æ­¤é˜ˆå€¼æ—¶å‘è­¦å‘Šï¼ˆä½†ä»å¯èƒ½åˆå¹¶ï¼‰
WARNING_BYTE_THRESHOLD = 200 * 1024  # 200 KB
WARNING_CHAR_THRESHOLD = 200 * 1024

# Base64 åˆ¤æ–­æ­£åˆ™ï¼ˆç”¨äºåˆ¤æ–­æŸè¡Œæ˜¯å¦æå¯èƒ½æ˜¯ Base64 åµŒå…¥ï¼‰
_BASE64_RE = re.compile(
    r"^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$"
)

def is_base64_line(line: str, min_length: int = 200) -> bool:
    s = line.strip()
    if len(s) < min_length:
        return False
    if _BASE64_RE.fullmatch(s):
        return True
    return False

def strip_notebook_base64(nb_obj):
    """é€’å½’å‰¥é™¤ `.ipynb` JSON ç»“æ„ä¸­å¸¦ base64 çš„åµŒå…¥å­—æ®µ."""
    if isinstance(nb_obj, dict):
        new = {}
        for k, v in nb_obj.items():
            if k == "data" and isinstance(v, (str, dict)):
                if isinstance(v, str):
                    if "base64" in v:
                        new[k] = ""
                    else:
                        new[k] = v
                else:
                    new[k] = {subk: ("" if (isinstance(subv, str) and "base64" in subv) else strip_notebook_base64(subv))
                              for subk, subv in v.items()}
            else:
                new[k] = strip_notebook_base64(v)
        return new
    elif isinstance(nb_obj, list):
        return [strip_notebook_base64(x) for x in nb_obj]
    else:
        return nb_obj

def count_chars_in_text(text: str) -> int:
    return len(text)

def should_include(filepath: str) -> bool:
    """åˆ¤æ–­è¿™ä¸ªæ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«è€ƒè™‘ï¼ˆåŸºç¡€è¿‡æ»¤ï¼‰"""
    parts = filepath.split(os.sep)
    for p in ("node_modules", ".git", "__pycache__", "build", "dist"):
        if p in parts:
            return False
    _, ext = os.path.splitext(filepath)
    ext = ext.lower().lstrip(".")
    # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œé€šå¸¸å¿½ç•¥
    if ext == "":
        return False
    # å¦‚æœåœ¨æ’é™¤åå•ï¼Œè·³è¿‡
    if ext in EXCLUDE_EXT:
        return False
    # å¦‚æœä¸åœ¨ include åˆ—è¡¨ï¼Œä¹Ÿè·³è¿‡
    if ext not in INCLUDE_EXT:
        return False
    # æ–‡ä»¶å¤§å°ç¡¬é™åˆ¶
    if MAX_FILE_SIZE is not None:
        try:
            if os.path.getsize(filepath) > MAX_FILE_SIZE:
                return False
        except OSError:
            return False
    return True

def process_file(filepath: str):
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶ï¼š
    è¿”å› (include_flag, info, content, warning_msg)
    - include_flag: æ˜¯å¦åˆå¹¶
    - info: dict åŒ…å« path, size_bytes, char_count
    - content: å¾…å†™å…¥çš„æ–‡æœ¬å†…å®¹ï¼ˆå‰”é™¤ base64 è¡Œç­‰ï¼‰ï¼Œå¦‚æœä¸åˆå¹¶åˆ™ä¸º None
    - warning_msg: è‹¥è§¦å‘è­¦æˆ’çº¿ï¼Œåˆ™è¿”å›æç¤ºå­—ç¬¦ä¸²ï¼Œå¦åˆ™ None
    """
    info = {
        "path": filepath,
        "size_bytes": None,
        "char_count": None,
    }
    try:
        size = os.path.getsize(filepath)
        info["size_bytes"] = size
    except OSError:
        info["size_bytes"] = -1

    _, ext = os.path.splitext(filepath)
    ext = ext.lower().lstrip(".")

    # ä¸“é—¨å¤„ç† .ipynb
    if ext == "ipynb":
        try:
            with open(filepath, encoding='utf-8') as f:
                nb = json.load(f)
        except Exception as e:
            # JSON è§£æå¤±è´¥ï¼Œå›é€€ä¸ºæ™®é€šæ–‡æœ¬å¤„ç†
            ext = "txt"
        else:
            nb_clean = strip_notebook_base64(nb)
            text = json.dumps(nb_clean, indent=2, ensure_ascii=False)
            char_count = count_chars_in_text(text)
            info["char_count"] = char_count
            # è¶…è¿‡æœ€å¤§å…è®¸å­—ç¬¦æ•°åˆ™è·³è¿‡
            if MAX_CHAR_COUNT is not None and char_count > MAX_CHAR_COUNT:
                return False, info, None, None
            # è­¦æˆ’çº¿æç¤º
            warning = None
            if ((WARNING_BYTE_THRESHOLD is not None and info["size_bytes"] is not None and info["size_bytes"] >= WARNING_BYTE_THRESHOLD)
                or (WARNING_CHAR_THRESHOLD is not None and char_count >= WARNING_CHAR_THRESHOLD)):
                warning = f"âš ï¸ WARNING: file near threshold (size={info['size_bytes']} bytes, chars={char_count})"
            return True, info, text + "\n", warning

    # æ™®é€šæ–‡æœ¬ / ä»£ç  / è„šæœ¬ æ–‡ä»¶
    try:
        with open(filepath, encoding='utf-8', errors="ignore") as f:
            raw = f.read()
    except Exception as e:
        info["char_count"] = 0
        return False, info, None, None

    char_count = count_chars_in_text(raw)
    info["char_count"] = char_count
    # å¦‚æœå­—ç¬¦æ•°è¶…è¿‡æœ€å¤§å…è®¸ï¼Œè·³è¿‡
    if MAX_CHAR_COUNT is not None and char_count > MAX_CHAR_COUNT:
        return False, info, None, None

    # é€è¡Œè¿‡æ»¤æå¯èƒ½çš„ Base64 è¡Œ
    lines = raw.splitlines(keepends=True)
    filtered = []
    for line in lines:
        if not is_base64_line(line):
            filtered.append(line)
    content = "".join(filtered) + "\n"

    warning = None
    if ((WARNING_BYTE_THRESHOLD is not None and info["size_bytes"] is not None and info["size_bytes"] >= WARNING_BYTE_THRESHOLD)
        or (WARNING_CHAR_THRESHOLD is not None and char_count >= WARNING_CHAR_THRESHOLD)):
        warning = f"âš ï¸ WARNING: file near threshold (size={info['size_bytes']} bytes, chars={char_count})"

    return True, info, content, warning

def main(base_dir: str):
    file_list = []
    for root, dirs, files in os.walk(base_dir):
        dirs[:] = [d for d in dirs if d not in ("node_modules", ".git", "__pycache__", "build", "dist")]
        for fn in files:
            full = os.path.join(root, fn)
            if should_include(full):
                file_list.append(full)
    file_list.sort()

    skipped = []
    included = []
    # ç”¨äºæŒ‰æ‰©å±•åç»Ÿè®¡åˆå¹¶äº†å¤šå°‘æ–‡ä»¶ã€æ€»å­—èŠ‚æ•°ã€æ€»å­—ç¬¦æ•°
    stats_by_ext = defaultdict(lambda: {"count": 0, "bytes": 0, "chars": 0})

    # æ‰“å¼€æ—¥å¿—æŠ¥å‘Šæ–‡ä»¶
    log_fp = open(LOG_REPORT_PATH, "w", encoding='utf-8')

    with open(OUTPUT_PATH, "w", encoding='utf-8') as out_fp:
        for fp in file_list:
            inc, info, content, warning = process_file(fp)
            if inc:
                included.append(info)
                # å†™æ ‡é¢˜
                out_fp.write(f"===== {info['path']} =====\n")
                # å†™è­¦å‘Šï¼ˆè‹¥æœ‰ï¼‰
                if warning:
                    out_fp.write(f"# {warning}\n")
                    log_fp.write(f"WARNING: {info['path']} â€” size {info['size_bytes']} bytes, chars {info['char_count']}\n")
                # å†™å†…å®¹
                out_fp.write(content)

                # æ›´æ–°ç»Ÿè®¡
                _, ext = os.path.splitext(info["path"])
                ext = ext.lower().lstrip(".")
                stats_by_ext[ext]["count"] += 1
                stats_by_ext[ext]["bytes"] += info["size_bytes"] or 0
                stats_by_ext[ext]["chars"] += info["char_count"] or 0
            else:
                skipped.append(info)
                log_fp.write(f"SKIPPED: {info['path']} â€” size {info['size_bytes']} bytes, chars {info['char_count']}\n")

    # å†™ç»Ÿè®¡æŠ¥å‘Šå°¾éƒ¨
    log_fp.write("\n=== Summary ===\n")
    log_fp.write(f"Merged {len(included)} files into {OUTPUT_PATH}\n")
    log_fp.write(f"Skipped {len(skipped)} files\n")
    log_fp.write("Stats by extension:\n")
    for ext, d in sorted(stats_by_ext.items()):
        log_fp.write(f"  .{ext}: count={d['count']}, total_bytes={d['bytes']}, total_chars={d['chars']}\n")
    log_fp.close()

    # åŒæ—¶åœ¨ stdout / stderr è¾“å‡ºæ‘˜è¦
    print(f"Merged {len(included)} files into {OUTPUT_PATH}, skipped {len(skipped)} files. See {LOG_REPORT_PATH} for details.")

if __name__ == "__main__":
    base = sys.argv[1] if len(sys.argv) > 1 else "."
    main(base)


===== ./notebooks/test1_loss_test.ipynb =====
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a9519a",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'open_clip_torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopen_clip_torch\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'open_clip_torch'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "692108a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading nodes: /cwStorage/nodecw_group/jijh/yuanspace_data/artifacts/nodes.parquet\n",
            "Loading edges: /cwStorage/nodecw_group/jijh/yuanspace_data/artifacts/edges.parquet\n",
            "[Check1] Checked 500 rows. mean=1.00000000, std=0.00000000, min=1.00000000, max=1.00000000\n",
            "[Check1] âœ… All sampled rows sum to 1 within tolerance.\n"
          ]
        }
      ],
      "source": [
        "# --- Check 1: Row-sum == 1 (main positive + neighbors, row-normalized) ---\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === é…ç½® ===\n",
        "ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
        "NODES_PATH = ARTIFACTS_DIR / \"nodes.parquet\"\n",
        "EDGES_PATH = ARTIFACTS_DIR / \"edges.parquet\"\n",
        "\n",
        "# æŠ½æ ·çš„ anchor æ•°é‡ï¼ˆå»ºè®® 200~1000 è§†å†…å­˜ï¼‰\n",
        "NUM_ANCHORS_TO_CHECK = 500\n",
        "\n",
        "# â€œä¸»æ­£æ ·æœ¬æƒé‡=1 + é‚»å±… alpha åå½’ä¸€åŒ–â€çš„é»˜è®¤ç­–ç•¥\n",
        "# å¦‚æœä½ åœ¨è®­ç»ƒé‡Œä½¿ç”¨äº†â€œé”åŒ–/æ¸©åº¦â€å¤„ç†ï¼ˆä¾‹å¦‚ alpha^gamma æˆ–ä¸»æ­£æ ·æœ¬æƒé‡ Ï„ï¼‰ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŒæ­¥è®¾ç½®ï¼š\n",
        "USE_GAMMA = False\n",
        "GAMMA = 1.0      # è‹¥ USE_GAMMA=Trueï¼Œåˆ™å¯¹ alpha ä½¿ç”¨ alpha ** GAMMA\n",
        "USE_TAU = False\n",
        "TAU = 1.0        # è‹¥ USE_TAU=Trueï¼Œåˆ™ä¸»æ­£æ ·æœ¬æƒé‡è®¾ä¸º TAUï¼ˆæ›¿ä»£ 1ï¼‰\n",
        "\n",
        "print(f\"Loading nodes: {NODES_PATH}\")\n",
        "nodes = pd.read_parquet(NODES_PATH, columns=[\"tile_id\"])\n",
        "tile_ids = nodes[\"tile_id\"].to_numpy()\n",
        "\n",
        "print(f\"Loading edges: {EDGES_PATH}\")\n",
        "edges = pd.read_parquet(EDGES_PATH, columns=[\"src_tile_id\", \"nbr_tile_id\", \"alpha\"])\n",
        "\n",
        "# ä¸ºäº†åŠ é€ŸéšæœºæŠ½æ ·ï¼Œè¿™é‡Œåªç”¨å­˜åœ¨å‡ºè¾¹çš„ src é›†åˆ\n",
        "src_unique = edges[\"src_tile_id\"].unique()\n",
        "rng = np.random.default_rng(2025)\n",
        "sampled_src = rng.choice(src_unique, size=min(NUM_ANCHORS_TO_CHECK, len(src_unique)), replace=False)\n",
        "\n",
        "row_sums = []\n",
        "bad_rows = []\n",
        "\n",
        "# å°†è¾¹æŒ‰ src åˆ†ç»„ï¼Œä¾¿äºå¿«é€Ÿæ£€ç´¢\n",
        "grp = edges.groupby(\"src_tile_id\", sort=False)\n",
        "\n",
        "for src in sampled_src:\n",
        "    if src not in grp.groups:\n",
        "        # è¯¥ src æ²¡æœ‰é‚»å±…è¾¹ï¼ˆæå°‘æ•°æƒ…å†µï¼‰ï¼Œç›´æ¥è·³è¿‡\n",
        "        continue\n",
        "    sub = grp.get_group(src)\n",
        "\n",
        "    # é‚»å±… alpha\n",
        "    alpha = sub[\"alpha\"].to_numpy(dtype=np.float64)\n",
        "\n",
        "    # å¯é€‰ï¼šå¯¹ alpha åšå¹‚æ¬¡é”åŒ–\n",
        "    if USE_GAMMA and GAMMA != 1.0:\n",
        "        alpha = np.power(alpha, GAMMA)\n",
        "\n",
        "    # ä¸»æ­£æ ·æœ¬æƒé‡\n",
        "    main_w = TAU if USE_TAU else 1.0\n",
        "\n",
        "    total = main_w + alpha.sum()\n",
        "    if total <= 0:\n",
        "        # ä¸åº”å‡ºç°ï¼›é˜²å¾¡æ€§å¤„ç†\n",
        "        rs = np.nan\n",
        "    else:\n",
        "        # å½’ä¸€åŒ–åçš„è¡Œå’Œåº”ä¸º 1\n",
        "        rs = (main_w / total) + (alpha / total).sum()\n",
        "\n",
        "    row_sums.append(rs)\n",
        "    if not np.isfinite(rs) or abs(rs - 1.0) > 1e-6:\n",
        "        bad_rows.append((src, rs))\n",
        "\n",
        "row_sums = np.array(row_sums, dtype=np.float64)\n",
        "print(f\"[Check1] Checked {len(row_sums)} rows. mean={row_sums.mean():.8f}, \"\n",
        "      f\"std={row_sums.std():.8f}, min={row_sums.min():.8f}, max={row_sums.max():.8f}\")\n",
        "if bad_rows:\n",
        "    print(f\"[Check1][WARN] Found {len(bad_rows)} rows with |sum-1|>1e-6. Show first 5:\")\n",
        "    for a,b in bad_rows[:5]:\n",
        "        print(f\"  src_tile_id={a}, row_sum={b}\")\n",
        "else:\n",
        "    print(\"[Check1] âœ… All sampled rows sum to 1 within tolerance.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "921a6d2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Check2] âœ… Mapping assertion passed for all tested ranks.\n"
          ]
        }
      ],
      "source": [
        "# --- Check 2: Mapping assertion for main positives (simulated) ---\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
        "NODES_PATH = ARTIFACTS_DIR / \"nodes.parquet\"\n",
        "\n",
        "# === æ¨¡æ‹Ÿåˆ†å¸ƒå¼è®¾ç½® ===\n",
        "WORLD_SIZE = 3\n",
        "N_LOCAL = 16      # æ¯ä¸ª rank çš„æœ¬åœ° batch å¤§å°ï¼ˆç”¨äºæ¨¡æ‹Ÿï¼‰ï¼Œå¯æ”¹å°ä¸€ç‚¹ä»¥ä¾¿å¯è§†åŒ–\n",
        "RANKS_TO_TEST = [0, 1, 2]  # è¦æµ‹è¯•çš„ rank é›†åˆ\n",
        "\n",
        "nodes = pd.read_parquet(NODES_PATH, columns=[\"tile_id\"])\n",
        "tile_ids = nodes[\"tile_id\"].to_numpy()\n",
        "assert len(tile_ids) >= WORLD_SIZE * N_LOCAL, \"æ•°æ®é‡ä¸è¶³ä»¥æ„é€ æ¨¡æ‹Ÿæ‰¹æ¬¡ï¼Œè¯·å‡å° N_LOCAL æˆ– WORLD_SIZE\"\n",
        "\n",
        "# ç®€å•çš„â€œè½®è½¬åˆ†é…â€æ–¹å¼æ¨¡æ‹Ÿ DistributedSamplerï¼ˆçœŸå®å®ç°æœ‰ shuffleï¼Œä½†ç´¢å¼•å…¬å¼ä¸€è‡´ï¼‰\n",
        "# æˆ‘ä»¬å–å‰ WORLD_SIZE * N_LOCAL ä¸ªæ ·æœ¬ï¼Œåˆ‡æˆ WORLD_SIZE ç‰‡ï¼Œæ¯ç‰‡ N_LOCAL å¤§å°\n",
        "local_batches = []\n",
        "for r in range(WORLD_SIZE):\n",
        "    start = r * N_LOCAL\n",
        "    end = (r + 1) * N_LOCAL\n",
        "    local_img_ids = tile_ids[start:end].copy()  # ä½œä¸º image_tile_ids\n",
        "    local_txt_ids = tile_ids[start:end].copy()  # ä½œä¸º text_tile_idsï¼ˆå¯¹ç§°ï¼‰\n",
        "    local_batches.append((local_img_ids, local_txt_ids))\n",
        "\n",
        "# æ¨¡æ‹Ÿ all_gather åçš„â€œå…¨å±€åˆ—åŸŸâ€\n",
        "global_tile_ids = np.concatenate([b[1] for b in local_batches], axis=0)  # ç”¨ text ç«¯å†³å®šåˆ—åŸŸ\n",
        "txt_id_to_idx = {int(tid): idx for idx, tid in enumerate(global_tile_ids)}\n",
        "\n",
        "# å¯¹æ¯ä¸ª rank åšæ–­è¨€ï¼štxt_id_to_idx[image_tile_ids[i]] == rank*N_LOCAL + i\n",
        "bad = []\n",
        "for rank in RANKS_TO_TEST:\n",
        "    image_tile_ids, _ = local_batches[rank]\n",
        "    for i in range(N_LOCAL):\n",
        "        tid = int(image_tile_ids[i])\n",
        "        col = txt_id_to_idx.get(tid, None)\n",
        "        expect = rank * N_LOCAL + i\n",
        "        if col != expect:\n",
        "            bad.append((rank, i, tid, col, expect))\n",
        "\n",
        "if bad:\n",
        "    print(f\"[Check2][FAIL] Found {len(bad)} mismatches. Show first 10:\")\n",
        "    for r,i,tid,col,exp in bad[:10]:\n",
        "        print(f\"  rank={r}, i={i}, tile_id={tid}, mapped_col={col}, expected={exp}\")\n",
        "else:\n",
        "    print(\"[Check2] âœ… Mapping assertion passed for all tested ranks.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "76831e93",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Check3] Anchor tile_id=3\n",
            "  pos_col (should be rank*N_LOCAL + local_index): 3\n",
            "  neighbors in-batch = 0 / total neighbors = 6\n",
            "  (Optional) main+in-batch-neighbors sum before normalization = 1.000000 (åº” < 1+Î£æ‰€æœ‰é‚»å±…ï¼›ä»…ç”¨äºè¾…åŠ©ç†è§£)\n"
          ]
        }
      ],
      "source": [
        "# --- Check 3: Print pos_col and neighbor_cols (simulated batch domain) ---\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
        "NODES_PATH = ARTIFACTS_DIR / \"nodes.parquet\"\n",
        "EDGES_PATH = ARTIFACTS_DIR / \"edges.parquet\"\n",
        "\n",
        "WORLD_SIZE = 3\n",
        "N_LOCAL = 16      # ä¸æ£€æŸ¥ 2 ç›¸åŒï¼Œä¿æŒä¸€è‡´\n",
        "RANK = 0          # é€‰æ‹©ä¸€ä¸ª rank æ¥å±•ç¤º\n",
        "ANCHOR_INDEX_IN_LOCAL = 3  # é€‰æ‹©è¯¥ rank çš„ç¬¬å‡ ä¸ªæ ·æœ¬ä½œä¸º anchor\n",
        "\n",
        "# 1) è¯»å–æ•°æ®\n",
        "nodes = pd.read_parquet(NODES_PATH, columns=[\"tile_id\"])\n",
        "edges = pd.read_parquet(EDGES_PATH, columns=[\"src_tile_id\", \"nbr_tile_id\", \"distance\", \"alpha\"])\n",
        "tile_ids = nodes[\"tile_id\"].to_numpy()\n",
        "assert len(tile_ids) >= WORLD_SIZE * N_LOCAL\n",
        "\n",
        "# 2) æ„é€ æ¨¡æ‹Ÿæ‰¹æ¬¡ä¸åˆ—åŸŸï¼ˆä¸æ£€æŸ¥ 2 ç›¸åŒï¼‰\n",
        "local_batches = []\n",
        "for r in range(WORLD_SIZE):\n",
        "    start = r * N_LOCAL\n",
        "    end = (r + 1) * N_LOCAL\n",
        "    local_img_ids = tile_ids[start:end].copy()\n",
        "    local_txt_ids = tile_ids[start:end].copy()\n",
        "    local_batches.append((local_img_ids, local_txt_ids))\n",
        "\n",
        "global_tile_ids = np.concatenate([b[1] for b in local_batches], axis=0)  # åˆ—åŸŸç”± text ç«¯ç¡®å®š\n",
        "txt_id_to_idx = {int(tid): idx for idx, tid in enumerate(global_tile_ids)}\n",
        "\n",
        "# 3) é€‰æ‹© anchorï¼ˆå– image ç«¯çš„ç¬¬ ANCHOR_INDEX_IN_LOCAL ä¸ªï¼‰\n",
        "image_tile_ids, text_tile_ids = local_batches[RANK]\n",
        "anchor_tile_id = int(image_tile_ids[ANCHOR_INDEX_IN_LOCAL])\n",
        "\n",
        "# 4) å–è¯¥ anchor çš„é‚»å±…ï¼ˆæŒ‰è·ç¦»ä»è¿‘åˆ°è¿œï¼‰\n",
        "nbr_df = edges[edges[\"src_tile_id\"] == anchor_tile_id].sort_values(\"distance\").copy()\n",
        "# åªä¿ç•™â€œæœ¬æ‰¹æ¬¡åˆ—åŸŸé‡Œå­˜åœ¨â€çš„é‚»å±…\n",
        "in_batch_mask = nbr_df[\"nbr_tile_id\"].isin(global_tile_ids)\n",
        "nbr_in = nbr_df[in_batch_mask]\n",
        "\n",
        "pos_col = txt_id_to_idx.get(anchor_tile_id, None)\n",
        "neighbor_cols = [txt_id_to_idx.get(int(t), None) for t in nbr_in[\"nbr_tile_id\"].tolist()]\n",
        "\n",
        "print(f\"[Check3] Anchor tile_id={anchor_tile_id}\")\n",
        "print(f\"  pos_col (should be rank*N_LOCAL + local_index): {pos_col}\")\n",
        "print(f\"  neighbors in-batch = {len(nbr_in)} / total neighbors = {len(nbr_df)}\")\n",
        "\n",
        "# æ‰“å°å‰è‹¥å¹²é‚»å±…\n",
        "MAX_SHOW = 12\n",
        "for idx, row in nbr_in.head(MAX_SHOW).iterrows():\n",
        "    t = int(row[\"nbr_tile_id\"])\n",
        "    col = txt_id_to_idx.get(t, None)\n",
        "    dist = float(row[\"distance\"])\n",
        "    alpha = float(row[\"alpha\"])\n",
        "    print(f\"    nbr_tile_id={t:>10d} | col={col:>5} | dist={dist:8.3f} | alpha={alpha:6.3f}\")\n",
        "\n",
        "# 5) å¯é€‰ï¼šè®¡ç®—â€œä¸»æ­£æ ·æœ¬+é‚»å±…ï¼ˆä»…æ‰¹å†…ï¼‰â€çš„å½’ä¸€åŒ–è¡Œå’Œï¼Œè¾…åŠ©äººå·¥æ ¸éªŒ\n",
        "main_w = 1.0\n",
        "alpha_vec = nbr_in[\"alpha\"].to_numpy(dtype=float)\n",
        "row_sum = (main_w + alpha_vec.sum())\n",
        "print(f\"  (Optional) main+in-batch-neighbors sum before normalization = {row_sum:.6f} \"\n",
        "      f\"(åº” < 1+Î£æ‰€æœ‰é‚»å±…ï¼›ä»…ç”¨äºè¾…åŠ©ç†è§£)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d11b614a",
      "metadata": {},
      "source": [
        "# æµ‹è¯•æ”¹æ­£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e4af1d40",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== åœ¨ Notebook é‡Œè¿è¡Œï¼šä¸ºä½ çš„ Dataset å¢è¡¥ç´¢å¼•åŠ é€Ÿç»“æ„ ====\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def dataset_build_fast_indices(dataset, k_neighbors: int = 6):\n",
        "    \"\"\"\n",
        "    ä¸º SpatiallyAwareDataset æ„å»ºå¿«é€Ÿç´¢å¼•ä¸å‘é‡åŒ–é‚»å±…çŸ©é˜µã€‚\n",
        "    éœ€è¦ dataset æ‹¥æœ‰:\n",
        "      - dataset.tile_ids: np.ndarray shape [N]\n",
        "      - dataset.sample_ids: np.ndarray shape [N] æˆ–ç­‰ä»·çš„åˆ—è¡¨\n",
        "      - dataset.edges_map: dict[int, list[int]]  # src_tile_id -> nbr_tile_id(é•¿åº¦<=k)\n",
        "    ç”Ÿæˆ:\n",
        "      - dataset.id2idx: dict[tile_id] -> dataset index\n",
        "      - dataset.sample_to_indices: dict[sample_id] -> np.ndarray of indices\n",
        "      - dataset.nbr_index: np.ndarray [N, k_neighbors]ï¼Œå…ƒç´ ä¸ºç´¢å¼•ï¼Œç¼ºå¤±å¡« -1\n",
        "    \"\"\"\n",
        "    assert hasattr(dataset, \"tile_ids\") and hasattr(dataset, \"sample_ids\"), \"Dataset ç¼ºå°‘ tile_ids æˆ– sample_ids\"\n",
        "    assert hasattr(dataset, \"edges_map\"), \"Dataset éœ€è¦æœ‰ edges_map (src_tile_id -> [nbr_tile_id...])\"\n",
        "    tile_ids = np.asarray(dataset.tile_ids)\n",
        "    sample_ids = np.asarray(dataset.sample_ids)\n",
        "\n",
        "    N = tile_ids.shape[0]\n",
        "    id2idx = {int(t): int(i) for i, t in enumerate(tile_ids)}\n",
        "    dataset.id2idx = id2idx\n",
        "\n",
        "    # æ¯ä¸ªæ ·æœ¬çš„ç´¢å¼•åˆ—è¡¨ï¼ˆå‘é‡åŒ–ï¼‰\n",
        "    sample_to_indices = defaultdict(list)\n",
        "    for i, sid in enumerate(sample_ids):\n",
        "        sample_to_indices[sid].append(i)\n",
        "    dataset.sample_to_indices = {sid: np.asarray(idxs, dtype=np.int64) for sid, idxs in sample_to_indices.items()}\n",
        "\n",
        "    # é‚»å±…â€œç´¢å¼•çŸ©é˜µâ€ [N, K]ï¼Œå‘é‡åŒ–æ˜ å°„ tile_id->index\n",
        "    K = int(k_neighbors)\n",
        "    nbr_index = np.full((N, K), -1, dtype=np.int64)\n",
        "    for i in range(N):\n",
        "        src_tid = int(tile_ids[i])\n",
        "        nbr_tids = dataset.edges_map.get(src_tid, [])\n",
        "        # åªå–å‰Kä¸ª\n",
        "        if len(nbr_tids) > K:\n",
        "            nbr_tids = nbr_tids[:K]\n",
        "        # æ˜ å°„ä¸ºç´¢å¼•ï¼Œæ˜ å°„ä¸åˆ°çš„ç½® -1\n",
        "        mapped = [id2idx.get(int(t), -1) for t in nbr_tids]\n",
        "        if mapped:\n",
        "            nbr_index[i, :len(mapped)] = np.asarray(mapped, dtype=np.int64)\n",
        "    dataset.nbr_index = nbr_index\n",
        "    print(f\"[build_fast_indices] N={N}, K={K}; sample buckets={len(dataset.sample_to_indices)}; done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "801abda3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== åœ¨ Notebook é‡Œè¿è¡Œï¼šé‚»åŸŸæ„ŸçŸ¥æ‰¹é‡‡æ ·å™¨ ====\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Sampler\n",
        "\n",
        "class SpatialBucketBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    é‚»åŸŸæ„ŸçŸ¥ BatchSamplerï¼š\n",
        "    - æ¯ä¸ª batch ç”±è‹¥å¹²â€œä¸­å¿ƒé”šç‚¹â€ + è¿™äº›é”šç‚¹çš„é‚»å±…ï¼ˆä¹Ÿä½œä¸ºé”šç‚¹ï¼‰ç»„æˆï¼›\n",
        "    - åªäº§å‡ºç´¢å¼•åˆ—è¡¨ï¼ˆä¸æ”¹ DataLoader çš„ __getitem__ è¡Œä¸ºï¼‰â†’ IO ä¸å¢åŠ ï¼›\n",
        "    - DDP ä¸‹æŒ‰ sample_id åˆ†æ¡¶ç»™ rankï¼ˆhash åˆ†é…ï¼‰ï¼Œå„ rank æ‰«æä¸åŒæ ·æœ¬é›†åˆï¼›\n",
        "    - ä¿è¯æ¯ä¸ª rank çš„ batch æ•°ç­‰é•¿ï¼ˆå¾ªç¯è¡¥é½æˆ–ä¸¢å¼ƒå¤šä½™ï¼‰ã€‚\n",
        "\n",
        "    ä¾èµ– dataset æˆå‘˜ï¼š\n",
        "      dataset.sample_to_indices: dict[sample_id] -> np.ndarray of indices\n",
        "      dataset.nbr_index: np.ndarray[N, K] é‚»å±…ç´¢å¼•çŸ©é˜µï¼ˆ-1 è¡¨ç¤ºæ— æ•ˆï¼‰\n",
        "      dataset.sample_ids: np.ndarray[N]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset,\n",
        "        batch_size: int,\n",
        "        world_size: int = 1,\n",
        "        rank: int = 0,\n",
        "        centers_per_batch: int = 16,\n",
        "        max_neighbors_per_center: int = 4,\n",
        "        same_sample_only: bool = True,\n",
        "        drop_last: bool = True,\n",
        "        seed: int = 2025\n",
        "    ):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.world_size = int(world_size)\n",
        "        self.rank = int(rank)\n",
        "        self.centers_per_batch = int(centers_per_batch)\n",
        "        self.max_neighbors_per_center = int(max_neighbors_per_center)\n",
        "        self.same_sample_only = bool(same_sample_only)\n",
        "        self.drop_last = bool(drop_last)\n",
        "        self.seed = int(seed)\n",
        "\n",
        "        assert hasattr(dataset, \"sample_to_indices\") and hasattr(dataset, \"nbr_index\"), \\\n",
        "            \"è¯·å…ˆè°ƒç”¨ dataset_build_fast_indices(dataset) ç”Ÿæˆ sample_to_indices / nbr_index\"\n",
        "        self.N = len(dataset.sample_ids)\n",
        "        self.sample_ids = np.asarray(dataset.sample_ids)\n",
        "\n",
        "        # 1) å°†æ ·æœ¬æ¡¶æŒ‰å“ˆå¸Œåˆ†é…ç»™å„ rankï¼Œé¿å… DDP é‡å \n",
        "        all_samples = list(dataset.sample_to_indices.keys())\n",
        "        all_samples.sort(key=lambda x: str(x))  # ç¨³å®šé¡ºåº\n",
        "        self.assigned_samples = [s for s in all_samples if (hash(str(s)) % self.world_size) == self.rank]\n",
        "        assert len(self.assigned_samples) > 0, \"æœ¬ rank è¢«åˆ†é…çš„æ ·æœ¬æ¡¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ– world_size è®¾ç½®ã€‚\"\n",
        "\n",
        "        # 2) è®¡ç®—æ¯ä¸ª epoch çš„æ‰¹æ¬¡æ•°ï¼Œä¿è¯å„ rank æ­¥æ•°ä¸€è‡´\n",
        "        #    ç”¨å…¨å±€ N ä¼°ç®—ï¼šæ¯ä¸ª rank ç”Ÿæˆ floor(N / (B * world_size)) ä¸ª batch\n",
        "        self.batches_per_epoch = self._compute_batches_per_epoch()\n",
        "\n",
        "        # 3) ä¸ºæ¯ä¸ªæ ·æœ¬æ¡¶å‡†å¤‡ä¸€ä¸ªâ€œæ¸¸æ ‡æŒ‡é’ˆâ€ä¸ä¹±åºç´¢å¼•\n",
        "        self._rng = random.Random(self.seed)\n",
        "        self._epoch = 0\n",
        "        self._reset_per_sample_state()\n",
        "\n",
        "    def _compute_batches_per_epoch(self):\n",
        "        # æŒ‰æ€»æ ·æœ¬é‡ä¸ batch_size/world_size ä¼°ç®—ä¸€ä¸ªâ€œå…¨å±€ç»Ÿä¸€â€çš„æ­¥æ•°\n",
        "        est = self.N // (self.batch_size * self.world_size)\n",
        "        return max(1, int(est))\n",
        "\n",
        "    def _reset_per_sample_state(self):\n",
        "        self._per_sample_order = {}\n",
        "        self._per_sample_ptr = {}\n",
        "        for s in self.assigned_samples:\n",
        "            idxs = self.dataset.sample_to_indices[s]\n",
        "            # æ‰“ä¹±\n",
        "            order = idxs.copy()\n",
        "            self._rng.shuffle(order.tolist())  # åŸåœ°æ´—ç‰Œï¼ˆlist æ›´å¿«ï¼‰\n",
        "            self._per_sample_order[s] = order\n",
        "            self._per_sample_ptr[s] = 0\n",
        "\n",
        "        # ç»™æ ·æœ¬æ¡¶ä¸€ä¸ªç¨³å®šä½†æ´—ç‰Œåçš„éå†é¡ºåº\n",
        "        self._sample_cycle = self.assigned_samples.copy()\n",
        "        self._rng.shuffle(self._sample_cycle)\n",
        "\n",
        "    def set_epoch(self, epoch: int):\n",
        "        self._epoch = int(epoch)\n",
        "        # ä»¥ epoch ä¸ºç§å­æ‰°åŠ¨ï¼Œç¡®ä¿æ¯ä¸ª epoch çš„é¡ºåºä¸åŒä½†å„ rank ä¸€è‡´å¯å¤ç°\n",
        "        self._rng.seed(self.seed + self._epoch)\n",
        "        self._reset_per_sample_state()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batches_per_epoch\n",
        "\n",
        "    def __iter__(self):\n",
        "        rng = self._rng\n",
        "        ds = self.dataset\n",
        "        nbr_index = ds.nbr_index\n",
        "        sample_ids = self.sample_ids\n",
        "\n",
        "        # round-robin æ‰«ææ ·æœ¬æ¡¶ï¼Œäº§ç”Ÿå›ºå®šæ•°é‡çš„ batch\n",
        "        num_yield = 0\n",
        "        sample_cursor = 0\n",
        "        while num_yield < self.batches_per_epoch:\n",
        "            s = self._sample_cycle[sample_cursor]\n",
        "            sample_cursor = (sample_cursor + 1) % len(self._sample_cycle)\n",
        "\n",
        "            order = self._per_sample_order[s]\n",
        "            ptr = self._per_sample_ptr[s]\n",
        "            if ptr >= len(order):\n",
        "                # è¯¥æ¡¶è€—å°½ï¼Œé‡ç½®è¯¥æ¡¶ï¼ˆå¾ªç¯ä½¿ç”¨ï¼‰ï¼Œä»¥é¿å…ä¸åŒ rank æ­¥æ•°ä¸ä¸€è‡´\n",
        "                self._rng.shuffle(order.tolist())\n",
        "                self._per_sample_ptr[s] = 0\n",
        "                ptr = 0\n",
        "\n",
        "            batch = []\n",
        "            used = set()\n",
        "\n",
        "            # 1) é€‰ä¸­å¿ƒé”šç‚¹\n",
        "            centers = []\n",
        "            centers_take = min(self.centers_per_batch, len(order) - ptr)\n",
        "            if centers_take <= 0:\n",
        "                continue\n",
        "            centers = order[ptr:ptr + centers_take]\n",
        "            self._per_sample_ptr[s] += centers_take\n",
        "\n",
        "            # 2) å°†ä¸­å¿ƒåŠ å…¥ batch\n",
        "            for c in centers:\n",
        "                if len(batch) >= self.batch_size:\n",
        "                    break\n",
        "                if c in used:\n",
        "                    continue\n",
        "                batch.append(int(c))\n",
        "                used.add(int(c))\n",
        "\n",
        "                # 3) æ‹‰å–è¯¥ä¸­å¿ƒçš„é‚»å±…ç´¢å¼•ï¼Œé™åˆ¶åŒæ ·æœ¬ã€å»é‡ï¼Œæœ€å¤šå– max_neighbors_per_center\n",
        "                nbrs = nbr_index[int(c)]\n",
        "                # è¿‡æ»¤æ— æ•ˆ\n",
        "                nbrs = nbrs[nbrs >= 0]\n",
        "                if self.same_sample_only:\n",
        "                    nbrs = nbrs[sample_ids[nbrs] == s]\n",
        "                # å»é‡è‡ªå·±/å·²é€‰\n",
        "                if len(nbrs) > 0:\n",
        "                    # æ‰“ä¹±é‚»å±…æ¬¡åºï¼Œé¿å…æ€»æ˜¯å–å‰ K ä¸ª\n",
        "                    nbrs = nbrs.copy()\n",
        "                    rng.shuffle(nbrs.tolist())\n",
        "                    for nb in nbrs:\n",
        "                        if len(batch) >= self.batch_size:\n",
        "                            break\n",
        "                        nb = int(nb)\n",
        "                        if nb in used:\n",
        "                            continue\n",
        "                        batch.append(nb)\n",
        "                        used.add(nb)\n",
        "                        if len(batch) >= self.batch_size or \\\n",
        "                           (len(batch) - len(centers)) >= self.max_neighbors_per_center * len(centers):\n",
        "                            break  # æ§åˆ¶é‚»å±…é¢„ç®—\n",
        "\n",
        "            # 4) è‹¥ batch æœªæ»¡ï¼Œç»§ç»­ä»åŒæ ·æœ¬è¡¥é½éšæœºæ ·æœ¬ï¼ˆä¸ä¿è¯æ˜¯é‚»å±…ï¼‰\n",
        "            if len(batch) < self.batch_size:\n",
        "                remain = self.batch_size - len(batch)\n",
        "                # ä»è¯¥æ¡¶å‰©ä½™ç´¢å¼•ä¸­è¡¥\n",
        "                ptr2 = self._per_sample_ptr[s]\n",
        "                if ptr2 + remain <= len(order):\n",
        "                    fill = order[ptr2:ptr2 + remain]\n",
        "                    self._per_sample_ptr[s] += remain\n",
        "                    for f in fill:\n",
        "                        fi = int(f)\n",
        "                        if fi in used:\n",
        "                            continue\n",
        "                        batch.append(fi)\n",
        "                        used.add(fi)\n",
        "                else:\n",
        "                    # ä¸å¤Ÿå°±å¾ªç¯è¡¥\n",
        "                    take = 0\n",
        "                    while len(batch) < self.batch_size:\n",
        "                        if self._per_sample_ptr[s] >= len(order):\n",
        "                            self._rng.shuffle(order.tolist())\n",
        "                            self._per_sample_ptr[s] = 0\n",
        "                        fi = int(order[self._per_sample_ptr[s]])\n",
        "                        self._per_sample_ptr[s] += 1\n",
        "                        if fi in used:\n",
        "                            continue\n",
        "                        batch.append(fi)\n",
        "                        used.add(fi)\n",
        "\n",
        "            # 5) äº§å‡º\n",
        "            if self.drop_last and len(batch) < self.batch_size:\n",
        "                continue\n",
        "            num_yield += 1\n",
        "            yield batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c451de6b",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopen_clip_train\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpatiallyAwareDataset\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1) å‡†å¤‡ datasetï¼ˆä½ å·²æœ‰ï¼‰\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m dataset = \u001b[43mSpatiallyAwareDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# å‡å®š dataset å·²ç»æœ‰ tile_ids / sample_ids / edges_map\u001b[39;00m\n\u001b[32m      9\u001b[39m dataset_build_fast_indices(dataset, k_neighbors=\u001b[32m6\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/public/home/jijh/diffusion_project/git_repo/yuanspace/src/open_clip_train/spatial_data.py:25\u001b[39m, in \u001b[36mSpatiallyAwareDataset.__init__\u001b[39m\u001b[34m(self, artifacts_dir, k_neighbors)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.k = k_neighbors\n\u001b[32m     23\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitializing SpatiallyAwareDataset with k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m nodes_path = \u001b[43martifacts_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnodes.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     26\u001b[39m edges_path = artifacts_dir / \u001b[33m\"\u001b[39m\u001b[33medges.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m nodes_path.exists() \u001b[38;5;129;01mand\u001b[39;00m edges_path.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNodes or Edges file not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifacts_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'str' and 'str'"
          ]
        }
      ],
      "source": [
        "# ==== åœ¨ Notebook é‡Œè¿è¡Œç¤ºä¾‹ï¼ˆæˆ–ç²˜è´´åˆ°ä½ çš„ train è„šæœ¬é‡Œï¼‰ ====\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.distributed as dist\n",
        "from open_clip_train.spatial_data import SpatiallyAwareDataset\n",
        "\n",
        "# 1) å‡†å¤‡ datasetï¼ˆä½ å·²æœ‰ï¼‰\n",
        "dataset = SpatiallyAwareDataset(artifacts_dir=\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\", k_neighbors=6)\n",
        "# å‡å®š dataset å·²ç»æœ‰ tile_ids / sample_ids / edges_map\n",
        "dataset_build_fast_indices(dataset, k_neighbors=6)\n",
        "\n",
        "# 2) æ„é€  batch_samplerï¼ˆDDP ç¯å¢ƒä¸‹ï¼‰\n",
        "if dist.is_available() and dist.is_initialized():\n",
        "    world_size = dist.get_world_size()\n",
        "    rank = dist.get_rank()\n",
        "else:\n",
        "    world_size = 1\n",
        "    rank = 0\n",
        "\n",
        "batch_sampler = SpatialBucketBatchSampler(\n",
        "    dataset=dataset,\n",
        "    batch_size=1600,\n",
        "    world_size=world_size,\n",
        "    rank=rank,\n",
        "    centers_per_batch=16,           # å¯è°ƒï¼šä¸­å¿ƒé”šç‚¹ä¸ªæ•°\n",
        "    max_neighbors_per_center=4,     # å¯è°ƒï¼šæ¯ä¸ªä¸­å¿ƒå¸¦çš„é‚»å±…ä¸Šé™\n",
        "    same_sample_only=True,\n",
        "    drop_last=True,\n",
        "    seed=2025,\n",
        ")\n",
        "\n",
        "# 3) DataLoaderï¼ˆæ³¨æ„ï¼šä¸è¦å†ä¼  batch_size / shuffle / samplerï¼‰\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_sampler=batch_sampler,\n",
        "    num_workers=16,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=getattr(dataset, \"collate_fn\", None)  # è‹¥ä½ æœ‰è‡ªå®šä¹‰ collate_fn å°±ä¼ å…¥\n",
        ")\n",
        "\n",
        "# 4) è®­ç»ƒå¾ªç¯ä¸­ï¼Œæ¯ä¸ª epoch å¼€å§‹å‰è®¾ç½® epochï¼ˆç¡®ä¿å¯å¤ç°æ´—ç‰Œï¼‰\n",
        "for epoch in range(num_epochs):\n",
        "    if hasattr(batch_sampler, \"set_epoch\"):\n",
        "        batch_sampler.set_epoch(epoch)\n",
        "    # for step, batch in enumerate(loader):\n",
        "    #     ... ä½ çš„è®­ç»ƒé€»è¾‘ ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85927285",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (spatial_clip)",
      "language": "python",
      "name": "spatial_clip"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
===== ./notebooks/test2_multipositive_effect.ipynb =====
# âš ï¸ WARNING: file near threshold (size=890939 bytes, chars=958031)
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bf70f36f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-12 20:57:28,984 - INFO - é…ç½®å®Œæˆã€‚ä½¿ç”¨è®¾å¤‡: cuda:0\n",
            "2025-09-12 20:57:28,985 - INFO - å¾…è¯„ä¼°æ¨¡å‹æ•°é‡: 2\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # ç©ºé—´ CLIP æ¨¡å‹ç»¼åˆè¯„ä¼°æ–¹æ¡ˆ\n",
        "#\n",
        "# **ç›®æ ‡:** å…¨é¢ã€ç§‘å­¦åœ°æ¯”è¾ƒåŸºçº¿ OmiCLIP æ¨¡å‹ä¸ä½¿ç”¨å¤šæ­£æ ·æœ¬æŸå¤± (Multi-Positive Loss) è®­ç»ƒçš„æ–° \"Spatial CLIP\" æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
        "#\n",
        "# **è¯„ä¼°æµç¨‹:**\n",
        "# 1.  **å®šæ€§è¯„ä¼°:** å¯¹ HEST ç»„ç»‡åˆ‡ç‰‡è¿›è¡Œé›¶æ ·æœ¬ç»†èƒç±»å‹æ ‡æ³¨ï¼Œå¹¶å¯è§†åŒ–æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„æ ‡æ³¨ç»“æœã€‚\n",
        "# 2.  **å®šé‡è¯„ä¼° (æ£€ç´¢):** è®¡ç®—ä¼ ç»Ÿçš„å›¾æ–‡äº’æ£€ç´¢æŒ‡æ ‡ (Recall@k) å’Œç›¸ä¼¼åº¦çƒ­åŠ›å›¾ï¼Œè¯„ä¼°æ¨¡å‹åŸºç¡€çš„å¯¹é½èƒ½åŠ›ã€‚\n",
        "# 3.  **å®šé‡è¯„ä¼° (åˆ†ç±»):** åŸºäºé«˜è¡¨è¾¾åŸºå› åˆ›å»ºä¼ªæ ‡ç­¾ï¼Œè¯„ä¼°ä¸¤ä¸ªæ¨¡å‹åœ¨é›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡ã€F1åˆ†æ•°å’Œæ··æ·†çŸ©é˜µã€‚\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 1. å¯¼å…¥ä¸ç¯å¢ƒé…ç½® (Imports & Configuration)\n",
        "\n",
        "# %%\n",
        "# --- æ ¸å¿ƒåŸåˆ™ ---\n",
        "# ğŸ›¡ï¸ å®‰å…¨ç¬¬ä¸€: é»˜è®¤åœ¨é¢„æ¼”æ¨¡å¼ä¸‹è¿è¡Œä»¥æ£€æŸ¥è·¯å¾„å’Œé…ç½®\n",
        "DRYRUN = False\n",
        "\n",
        "# --- é¡¹ç›®è·¯å¾„é…ç½® (æ ¸å¿ƒä¿®æ­£) ---\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# å°†æ‚¨çš„é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python æœç´¢è·¯å¾„\n",
        "PROJECT_ROOT = Path(\"/home1/jijh/diffusion_project/git_repo/yuanspace\")\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "    print(f\"å·²å°† '{PROJECT_ROOT}' æ·»åŠ åˆ° sys.path\")\n",
        "\n",
        "from src.spaglam_preproc.utils.hest_loading import HESTDataset\n",
        "\n",
        "    \n",
        "# --- æ ‡å‡†åº“ ---\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple, List\n",
        "\n",
        "# --- ç¬¬ä¸‰æ–¹åº“ ---\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "# --- æœ¬åœ°é¡¹ç›®åº“ ---\n",
        "# ç¡®ä¿ open_clip åœ¨ Python è·¯å¾„ä¸­\n",
        "# è¯·æ ¹æ®æ‚¨çš„ç¯å¢ƒè°ƒæ•´æ­¤è·¯å¾„\n",
        "try:\n",
        "    import open_clip\n",
        "except ImportError:\n",
        "    # å‡è®¾æ­¤ notebook ä½äºé¡¹ç›®æ ¹ç›®å½•\n",
        "    sys.path.append('./notebooks/src')\n",
        "    import open_clip\n",
        "\n",
        "# --- é…ç½®æ—¥å¿— ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', stream=sys.stdout)\n",
        "\n",
        "# %%\n",
        "# --- è·¯å¾„ä¸æ¨¡å‹é…ç½® ---\n",
        "# (Review #8) ä½¿ç”¨ Path å¯¹è±¡è¿›è¡Œç¨³å¥çš„è·¯å¾„ç®¡ç†\n",
        "# --- æ•°æ®è·¯å¾„ ---\n",
        "HEST_DATA_DIR = Path(\"/cwStorage/nodecw_group/jijh/hest_1k\")\n",
        "ARTIFACTS_DIR = Path(\"/cwStorage/nodecw_group/jijh/yuanspace_data/artifacts\")\n",
        "NODES_PATH = ARTIFACTS_DIR / \"nodes.parquet\"\n",
        "IMG_EMBED_PATH = ARTIFACTS_DIR / \"image_embeds.npy\" # åŸºçº¿æ¨¡å‹çš„é¢„è®¡ç®—åµŒå…¥\n",
        "\n",
        "OUTPUT_DIR = Path(\"/cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline\")\n",
        "\n",
        "# --- æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ ---\n",
        "BASELINE_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt\")\n",
        "SPATIAL_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/spatial_clip_base_model/multi_positice_loss50.pt\")\n",
        "\n",
        "# --- æ¨¡å‹æ¶æ„ ---\n",
        "MODEL_NAME = \"ViT-B-32\"\n",
        "\n",
        "# --- æ¨ç†é…ç½® ---\n",
        "BATCH_SIZE = 512\n",
        "NUM_WORKERS = 16\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE_COUNT = torch.cuda.device_count()\n",
        "\n",
        "# --- å¾…æµ‹è¯•æ¨¡å‹æ¸…å• ---\n",
        "MODELS_TO_TEST = {\n",
        "    \"OmiCLIP (Baseline)\": {\n",
        "        \"path\": BASELINE_MODEL_CKPT,\n",
        "        \"model_name\": MODEL_NAME,\n",
        "    },\n",
        "    \"Spatial CLIP (Ours)\": {\n",
        "        \"path\": SPATIAL_MODEL_CKPT,\n",
        "        \"model_name\": MODEL_NAME,\n",
        "    },\n",
        "}\n",
        "\n",
        "# --- æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ ---\n",
        "for name, config in MODELS_TO_TEST.items():\n",
        "    assert config['path'].exists(), f\"æ¨¡å‹ '{name}' çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {config['path']}\"\n",
        "assert HEST_DATA_DIR.exists(), f\"HEST æ•°æ®ç›®å½•ä¸å­˜åœ¨: {HEST_DATA_DIR}\"\n",
        "\n",
        "if not DRYRUN:\n",
        "    # åªæœ‰åœ¨éé¢„æ¼”æ¨¡å¼ä¸‹æ‰æ£€æŸ¥è¿™äº›ç”Ÿæˆçš„æ–‡ä»¶\n",
        "    assert NODES_PATH.exists(), f\"é¢„å¤„ç†ç”Ÿæˆçš„ nodes.parquet ä¸å­˜åœ¨: {NODES_PATH}\"\n",
        "    assert IMG_EMBED_PATH.exists(), f\"é¢„å¤„ç†ç”Ÿæˆçš„ image_embeds.npy ä¸å­˜åœ¨: {IMG_EMBED_PATH}\"\n",
        "else:\n",
        "    logging.warning(\"å¤„äºé¢„æ¼”æ¨¡å¼ (DRYRUN=True)ã€‚ä¸ä¼šæ‰§è¡Œæ–‡ä»¶å†™å…¥å’Œéƒ¨åˆ†æ•°æ®åŠ è½½ã€‚\")\n",
        "\n",
        "logging.info(f\"é…ç½®å®Œæˆã€‚ä½¿ç”¨è®¾å¤‡: {DEVICE}\")\n",
        "logging.info(f\"å¾…è¯„ä¼°æ¨¡å‹æ•°é‡: {len(MODELS_TO_TEST)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a7b61b63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ### 2. æ ¸å¿ƒå‡½æ•°ï¼šæ¨¡å‹åŠ è½½ä¸æ•°æ®å‡†å¤‡ (Core Functions: Model Loading & Data Prep)\n",
        "\n",
        "# %%\n",
        "def load_clip_model(checkpoint_path: Path, model_name: str, device: str) -> torch.nn.Module:\n",
        "    \"\"\"\n",
        "    ä»ç»™å®šçš„æ£€æŸ¥ç‚¹è·¯å¾„åŠ è½½ CLIP æ¨¡å‹ã€‚\n",
        "    - è‡ªåŠ¨å¤„ç† 'module.' å‰ç¼€ã€‚\n",
        "    - å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(f\"æ­£åœ¨åŠ è½½æ¨¡å‹ '{model_name}' ä»: {checkpoint_path}\")\n",
        "    \n",
        "    # 1. åˆ›å»ºæ¨¡å‹ç»“æ„\n",
        "    model, _, _ = open_clip.create_model_and_transforms(model_name, pretrained=None)\n",
        "    \n",
        "    # 2. åŠ è½½çŠ¶æ€å­—å…¸\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
        "    \n",
        "    # 3. æ¸…ç† 'module.' å‰ç¼€ï¼ˆæ¥è‡ª DDP è®­ç»ƒï¼‰\n",
        "    if all(key.startswith('module.') for key in state_dict.keys()):\n",
        "        state_dict = {k[len('module.'):]: v for k, v in state_dict.items()}\n",
        "        \n",
        "    # 4. åŠ è½½æƒé‡\n",
        "    model.load_state_dict(state_dict)\n",
        "    \n",
        "    # 5. å‡†å¤‡æ¨ç†\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    logging.info(f\"æ¨¡å‹ '{model_name}' åŠ è½½æˆåŠŸã€‚\")\n",
        "    return model\n",
        "\n",
        "def get_hest_sample(sample_id: str = 'TENX156') -> Any:\n",
        "    \"\"\"åŠ è½½å¹¶å‡†å¤‡ä¸€ä¸ª HEST æ ·æœ¬ç”¨äºåˆ†æã€‚\"\"\"\n",
        "    from src.spaglam_preproc.utils.hest_loading import HESTDataset\n",
        "    \n",
        "    logging.info(f\"åŠ è½½ HEST æ ·æœ¬: {sample_id}...\")\n",
        "    hest_dataset = HESTDataset(data_dir=HEST_DATA_DIR)\n",
        "    sample = hest_dataset.get_samples(sample_ids=[sample_id])[0]\n",
        "    sample.load_st_data(lazy=False)\n",
        "    sample.load_wsi()\n",
        "    \n",
        "    # ä¿®æ­£ scanpy æœŸæœ›çš„ spatial ç»“æ„\n",
        "    spatial_data = sample.adata.uns['spatial']['ST']\n",
        "    library_id = sample.sample_id\n",
        "    sample.adata.uns['spatial'] = {library_id: spatial_data}\n",
        "    \n",
        "    logging.info(f\"æ ·æœ¬ '{sample.sample_id}' åŠ è½½å¹¶å‡†å¤‡å®Œæ¯•ã€‚\")\n",
        "    return sample\n",
        "\n",
        "# --- ä¸ºæ¨ç†å®šä¹‰ PyTorch Dataset ---\n",
        "class WSISpotDataset(Dataset):\n",
        "    \"\"\"ä¸€ä¸ªè‡ªå®šä¹‰æ•°æ®é›†ï¼Œç”¨äºä»WSIä¸­æŒ‰éœ€åŠ è½½spotå¯¹åº”çš„å›¾å—ã€‚\"\"\"\n",
        "    def __init__(self, wsi, coords, transform):\n",
        "        self.wsi = wsi\n",
        "        self.coords = coords\n",
        "        self.transform = transform\n",
        "        self.patch_size = (224, 224)\n",
        "        self.patch_radius = self.patch_size[0] // 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        c = self.coords[idx]\n",
        "        top_left_coord = (int(c[0] - self.patch_radius), int(c[1] - self.patch_radius))\n",
        "        tile = self.wsi.read_region(top_left_coord, 0, self.patch_size).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            tile = self.transform(tile)\n",
        "        return tile\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fb1bd06b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-12 20:54:19,774 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-12 20:54:19,775 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-12 20:54:19,776 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-12 20:54:19,894 - INFO - åŠ è½½ HEST æ ·æœ¬: TENX156...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/anndata/_core/anndata.py:1793: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-12 20:54:21,910 - INFO - æ ·æœ¬ 'TENX156' åŠ è½½å¹¶å‡†å¤‡å®Œæ¯•ã€‚\n",
            "2025-09-12 20:54:21,913 - INFO - æ­£åœ¨åŠ è½½æ¨¡å‹ 'ViT-B-32' ä»: /cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt\n",
            "2025-09-12 20:54:21,914 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-12 20:54:21,915 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-12 20:54:21,916 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-12 20:54:21,917 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-12 20:54:23,352 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-12 20:54:23,353 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-12 20:54:23,354 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-12 20:54:32,643 - INFO - æ¨¡å‹ 'ViT-B-32' åŠ è½½æˆåŠŸã€‚\n",
            "2025-09-12 20:54:32,773 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-12 20:54:32,774 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-12 20:54:32,775 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-12 20:54:32,776 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-12 20:54:34,152 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-12 20:54:34,153 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-12 20:54:34,153 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "474e1458a0224fb588f0bc1592a2c2a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Annotating with OmiCLIP (Baseline):   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-12 20:55:03,080 - INFO - æ­£åœ¨åŠ è½½æ¨¡å‹ 'ViT-B-32' ä»: /cwStorage/nodecw_group/jijh/trained_models/spatial_clip_base_model/multi_positice_loss50.pt\n",
            "2025-09-12 20:55:03,082 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-12 20:55:03,083 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-12 20:55:03,084 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-12 20:55:03,085 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-12 20:55:04,361 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-12 20:55:04,362 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-12 20:55:04,363 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-12 20:55:08,413 - INFO - æ¨¡å‹ 'ViT-B-32' åŠ è½½æˆåŠŸã€‚\n",
            "2025-09-12 20:55:08,447 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-12 20:55:08,448 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-12 20:55:08,449 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-12 20:55:08,450 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-12 20:55:09,528 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-12 20:55:09,528 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-12 20:55:09,529 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "546ccf90e1b94dbc8c70e18cacdf06d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Annotating with Spatial CLIP (Ours):   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ### 3. é˜¶æ®µä¸€ï¼šå®šæ€§è¯„ä¼° - é›¶æ ·æœ¬ç©ºé—´æ ‡æ³¨ (Qualitative Evaluation)\n",
        "#\n",
        "# åœ¨æ­¤é˜¶æ®µï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹å¯¹åŒä¸€ä¸ªç»„ç»‡åˆ‡ç‰‡è¿›è¡Œé›¶æ ·æœ¬ç»†èƒç±»å‹æ ‡æ³¨ï¼Œå¹¶å¯è§†åŒ–ç»“æœä»¥è¿›è¡Œç›´è§‚æ¯”è¾ƒã€‚\n",
        "\n",
        "# %%\n",
        "# --- å®šä¹‰ç”Ÿç‰©å­¦æŸ¥è¯¢ ---\n",
        "text_queries = {\n",
        "    \"Tumor Epithelium\": \"EPCAM MKI67 TOP2A PCNA KRT8 KRT18 KRT19 TACSTD2 CENPF UBE2C BIRC5 MCM2 MCM3 MCM4 MCM5 MCM6 MCM7 CDK1 CCNB1 CCNB2 AURKA AURKB CEACAM5 CEACAM6 MUC1 CLDN4 CLDN7 CD44 SLC2A1 S100P S100A6 SOX4 SOX9 TFF3 AGR2 RRM2 TYMS TPX2 BUB1B KIF2C KIF11 PLK1 GPC3 MDK PTTG1 LAMC2 LAMA3 ITGA6 ITGB4 SLPI\",\n",
        "    \"T Cells\": \"CD3D CD3E CD3G CD2 CD28 CD247 PTPRC CD4 CD8A CD8B LAT GZMA GZMB GZMK PRF1 IFNG CCL5 CXCL9 CXCL10 ICOS LAG3 PDCD1 CTLA4 TIGIT HAVCR2 ENTPD1 FOXP3 IL2RA IKZF2 CCR7 SELL LEF1 TCF7 IL7R KLRB1 KLRG1 NKG7 ZAP70 LCK FYN THEMIS TRAT1 ITK CD27 CD5 CD6 CD7 SH2D1A\",\n",
        "    \"B Cells\": \"MS4A1 CD19 CD79A CD79B CD22 PAX5 EBF1 BANK1 BLK CD24 FCRL5 TCL1A CD38 SDC1 XBP1 IRF4 PRDM1 IGHG1 IGHG2 IGHG3 IGHG4 IGHA1 IGHA2 IGHM IGHD IGHE IGKC IGKV1-5 JCHAIN DERL3 FCRL4 SLAMF7 POU2F2 BACH2 SPIB VPREB1 VPREB3 IGLL5 LTB CD27 TNFRSF17 TNFRSF13B MZB1\",\n",
        "    \"Macrophages\": \"CD68 CD163 CD14 CSF1R MRC1 CD86 CD80 FCGR3A FCGR1A FCGR2A ITGAM ITGAX AIF1 C1QA C1QB C1QC APOE LYZ MSR1 CD209 CLEC7A CLEC10A HLA-DPA1 HLA-DPB1 HLA-DQA1 HLA-DQB1 HLA-DRA HLA-DRB1 HLA-DRB5 CD74 MAF MARCO STAB1 SPP1 TREM2 LGALS3 S100A8 S100A9 MKI67 FCN1 VCAN\",\n",
        "    \"Fibroblasts\": \"FAP ACTA2 COL1A1 COL1A2 COL3A1 COL5A1 DCN LUM BGN POSTN FN1 SPARC MMP2 MMP9 MMP11 MMP14 TIMP1 PDGFRA PDGFRB TGFB1 TGFBI THBS1 THBS2 VIM S100A4 FBLN1 FBLN2 FBLN5 TNC MFAP5 CTHRC1 GREM1 RGS5 CDH11 ASPN PLAU CXCL12 WNT2 WNT5A SULF1 LOX LOXL1 LOXL2 ADAM12\",\n",
        "    \"Endothelial Cells\": \"PECAM1 CDH5 KDR FLT1 VWF CLDN5 ENG TIE1 TEK ICAM1 ICAM2 VCAM1 SELE SELP ACKR1 EMCN ESAM STAB1 STAB2 RAMP2 RAMP3 ADGRF5 GJA4 GJA5 PLVAP AQP1 SEMA3G PTPRB ROBO4 CD34 CD93 ERG FLI1 SOX18 EGFL7 ECSCR PLXND1 MMRN2 CD36 NRP1 NRP2 IGFBP7\",\n",
        "    \"Smooth Muscle\": \"ACTA2 MYH11 TAGLN TPM1 TPM2 CNN1 CNN2 DES CALD1 MYLK MYL9 LMOD1 ACTG2 MYOCD SRF MEF2C MEF2D PLN PTPRB CASQ2 PPP1R12A PPP1R12B MYL6 ACTB GSN FLNA ADIRF CAV1 CAV2 ITGA7 ITGA8 PDLIM7 PDLIM5 SYNM SYNPO2 SLMAP RGS5 NOTCH3 HEYL HES4 PLN TRPC6 ANO1 KCNMA1\"\n",
        "}\n",
        "\n",
        "tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "query_labels = list(text_queries.keys())\n",
        "\n",
        "# --- åŠ è½½æ•°æ® ---\n",
        "sample = get_hest_sample()\n",
        "all_results = {}\n",
        "\n",
        "# --- è¿è¡Œæ¨ç† ---\n",
        "for name, config in MODELS_TO_TEST.items():\n",
        "    model = load_clip_model(config['path'], config['model_name'], DEVICE)\n",
        "    _, _, image_preprocessor = open_clip.create_model_and_transforms(config['model_name'])\n",
        "\n",
        "    spot_dataset = WSISpotDataset(wsi=sample.wsi, coords=sample.adata.obsm['spatial'], transform=image_preprocessor)\n",
        "    dataloader = DataLoader(spot_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    all_spot_embeddings = []\n",
        "    with torch.inference_mode():\n",
        "        tokenized_queries = tokenizer(list(text_queries.values())).to(DEVICE)\n",
        "        text_features = model.encode_text(tokenized_queries, normalize=True)\n",
        "\n",
        "        for image_batch in tqdm(dataloader, desc=f\"Annotating with {name}\"):\n",
        "            image_batch = image_batch.to(DEVICE, non_blocking=True)\n",
        "            image_features = model.encode_image(image_batch, normalize=True)\n",
        "            all_spot_embeddings.append(image_features.cpu())\n",
        "    \n",
        "    # è®¡ç®—ç›¸ä¼¼åº¦å¹¶è·å–é¢„æµ‹ç»“æœ\n",
        "    all_spot_embeddings_tensor = torch.cat(all_spot_embeddings)\n",
        "    similarity = all_spot_embeddings_tensor.to(DEVICE) @ text_features.T\n",
        "    confidence, predictions = torch.max(torch.softmax(similarity, dim=1), dim=1)\n",
        "\n",
        "    predicted_labels = pd.Series([query_labels[i] for i in predictions.cpu().numpy()], index=sample.adata.obs.index)\n",
        "    confidence_scores = pd.Series(confidence.cpu().numpy(), index=sample.adata.obs.index)\n",
        "\n",
        "    all_results[name] = {\"labels\": predicted_labels, \"confidences\": confidence_scores}\n",
        "\n",
        "    # æ¸…ç† GPU å†…å­˜\n",
        "    del model, text_features\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# --- å°†ç»“æœæ·»åŠ åˆ° AnnData å¯¹è±¡ä¸­ ---\n",
        "for exp_name, results in all_results.items():\n",
        "    sample.adata.obs[f\"anno_{exp_name}\"] = pd.Categorical(results['labels'], categories=query_labels)\n",
        "    sample.adata.obs[f\"conf_{exp_name}\"] = results['confidences']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7370e83b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# #### 1.1 å¯è§†åŒ–æ ‡æ³¨ç»“æœ\n",
        "\n",
        "# %%\n",
        "# --- å‡†å¤‡è°ƒè‰²æ¿å’Œç»˜å›¾ ---\n",
        "categories = list(text_queries.keys())\n",
        "base_colors = plt.cm.tab20(np.linspace(0, 1, len(categories)))\n",
        "celltype_palette = dict(zip(categories, base_colors))\n",
        "\n",
        "fig, axes = plt.subplots(1, len(MODELS_TO_TEST), figsize=(7 * len(MODELS_TO_TEST), 12), squeeze=False)\n",
        "fig.suptitle(f\"Zero-Shot Annotation Comparison â€“ Sample {sample.sample_id}\", fontsize=20, y=0.9)\n",
        "\n",
        "plot_params = {\n",
        "    \"show\": False, \"legend_loc\": None, \"frameon\": False,\n",
        "    \"library_id\": sample.sample_id, \"img_key\": 'downscaled_fullres',\n",
        "    \"size\": 1.2, \"s\": 3,\n",
        "}\n",
        "\n",
        "for i, (name, _) in enumerate(MODELS_TO_TEST.items()):\n",
        "    ax = axes[0, i]\n",
        "    sc.pl.spatial(\n",
        "        sample.adata,\n",
        "        color=f\"anno_{name}\",\n",
        "        title=f\"{name}\\n(Predicted Cell Type)\",\n",
        "        ax=ax,\n",
        "        palette=celltype_palette,\n",
        "        **plot_params\n",
        "    )\n",
        "\n",
        "handles = [mpatches.Patch(color=celltype_palette[cat], label=cat) for cat in categories]\n",
        "fig.legend(handles=handles, title=\"Cell Types\", loc='center right', bbox_to_anchor=(1.05, 0.5))\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 0.90, 0.96])\n",
        "\n",
        "if not DRYRUN:\n",
        "    plt.savefig(OUTPUT_DIR / f\"spatial_annotation_comparison_{sample.sample_id}.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e9aec4a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AnnData object with n_obs Ã— n_vars = 2179 Ã— 18085\n",
              "    obs: 'in_tissue', 'pxl_col_in_fullres', 'pxl_row_in_fullres', 'array_col', 'array_row', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mito', 'log1p_total_counts_mito', 'pct_counts_mito', 'anno_OmiCLIP (Baseline)', 'conf_OmiCLIP (Baseline)', 'anno_Spatial CLIP (Ours)', 'conf_Spatial CLIP (Ours)'\n",
              "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'mito'\n",
              "    uns: 'spatial', 'anno_OmiCLIP (Baseline)_colors', 'anno_Spatial CLIP (Ours)_colors'\n",
              "    obsm: 'spatial'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample.adata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e83f9256",
      "metadata": {},
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n",
        "    sample.adata,\n",
        "    color=f\"total_counts\",\n",
        "    title=f\"total_counts\",\n",
        "    s = 0,\n",
        "    **plot_params_new\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a98651dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n",
        "    sample.adata,\n",
        "    color=f\"total_counts\",\n",
        "    title=f\"total_counts\",\n",
        "    **plot_params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2e6cfce4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ### 4. é˜¶æ®µäºŒï¼šå®šé‡è¯„ä¼° - å›¾æ–‡æ£€ç´¢ (Quantitative Evaluation - Retrieval)\n",
        "#\n",
        "# æˆ‘ä»¬è¯„ä¼°æ¨¡å‹å°†å›¾å—ä¸å…¶å¯¹åº”çš„åŸºå› è¡¨è¾¾æ–‡æœ¬æ­£ç¡®åŒ¹é…çš„èƒ½åŠ›ã€‚è¿™åæ˜ äº†æ¨¡å‹åŸºç¡€çš„å›¾æ–‡å¯¹é½æ€§èƒ½ã€‚\n",
        "\n",
        "# %%\n",
        "class GeneSpotDataset(Dataset):\n",
        "    \"\"\"ç”¨äºæ£€ç´¢è¯„ä¼°çš„æ•°æ®é›†ï¼Œè¿”å›å›¾å—å’Œå¯¹åº”çš„åŸºå› å¥å­ã€‚\"\"\"\n",
        "    def __init__(self, df, image_preprocessor, tokenizer):\n",
        "        self.df = df\n",
        "        self.image_preprocessor = image_preprocessor\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = self.image_preprocessor(Image.open(row['image_path']).convert(\"RGB\"))\n",
        "        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸è¿›è¡Œ [0] ç´¢å¼•ï¼Œå› ä¸º tokenizer ä¼šå¤„ç†åˆ—è¡¨\n",
        "        text = row['gene_sentence']\n",
        "        return image, text\n",
        "\n",
        "def calculate_retrieval_metrics(image_features: torch.Tensor, text_features: torch.Tensor) -> Dict[str, float]:\n",
        "    \"\"\"è®¡ç®—å›¾æ–‡äº’æ£€ç´¢çš„ Recall@k æŒ‡æ ‡ã€‚\"\"\"\n",
        "    metrics = {}\n",
        "    \n",
        "    # Image-to-Text Retrieval\n",
        "    logits_per_image = image_features @ text_features.T\n",
        "    ground_truth = torch.arange(len(image_features)).to(logits_per_image.device)\n",
        "    \n",
        "    ranks = torch.argsort(logits_per_image, descending=True)\n",
        "    preds = torch.where(ranks == ground_truth.unsqueeze(1))[1]\n",
        "    \n",
        "    for k in [1, 5, 10]:\n",
        "        metrics[f\"image_to_text_R@{k}\"] = (preds < k).float().mean().item()\n",
        "        \n",
        "    # Text-to-Image Retrieval\n",
        "    logits_per_text = logits_per_image.T\n",
        "    ranks = torch.argsort(logits_per_text, descending=True)\n",
        "    preds = torch.where(ranks == ground_truth.unsqueeze(1))[1]\n",
        "    \n",
        "    for k in [1, 5, 10]:\n",
        "        metrics[f\"text_to_image_R@{k}\"] = (preds < k).float().mean().item()\n",
        "        \n",
        "    return metrics, logits_per_image.cpu().numpy()\n",
        "\n",
        "# --- è¿è¡Œæ£€ç´¢è¯„ä¼° ---\n",
        "retrieval_results = []\n",
        "nodes_df = pd.read_parquet(NODES_PATH)\n",
        "# ä¸ºèŠ‚çœæ—¶é—´ï¼Œæˆ‘ä»¬åªåœ¨ 2048 ä¸ªéšæœºæ ·æœ¬ä¸Šè¿›è¡Œè¯„ä¼°\n",
        "subset_indices = np.random.choice(len(nodes_df), size=min(2048, len(nodes_df)), replace=False)\n",
        "eval_df = nodes_df.iloc[subset_indices]\n",
        "\n",
        "# è·å–é¢„å¤„ç†å™¨\n",
        "_, _, image_preprocessor = open_clip.create_model_and_transforms(MODEL_NAME)\n",
        "eval_dataset = GeneSpotDataset(eval_df, image_preprocessor, tokenizer)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "\n",
        "final_similarity_matrices = {}\n",
        "\n",
        "for name, config in MODELS_TO_TEST.items():\n",
        "    model = load_clip_model(config['path'], config['model_name'], DEVICE)\n",
        "    \n",
        "    all_image_features, all_text_features = [], []\n",
        "    with torch.inference_mode():\n",
        "        for images, texts in tqdm(eval_dataloader, desc=f\"Retrieval eval for {name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            texts = tokenizer(texts).to(DEVICE)\n",
        "            \n",
        "            image_features = model.encode_image(images, normalize=True)\n",
        "            text_features = model.encode_text(texts, normalize=True)\n",
        "            \n",
        "            all_image_features.append(image_features)\n",
        "            all_text_features.append(text_features)\n",
        "            \n",
        "    img_f = torch.cat(all_image_features)\n",
        "    txt_f = torch.cat(all_text_features)\n",
        "    \n",
        "    metrics, sim_matrix = calculate_retrieval_metrics(img_f, txt_f)\n",
        "    metrics['model'] = name\n",
        "    retrieval_results.append(metrics)\n",
        "    final_similarity_matrices[name] = sim_matrix\n",
        "    \n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "retrieval_df = pd.DataFrame(retrieval_results).set_index('model')\n",
        "print(\"\\n--- Retrieval Performance ---\")\n",
        "print(retrieval_df)\n",
        "\n",
        "# %% [markdown]\n",
        "# #### 4.1 å¯è§†åŒ–ç›¸ä¼¼åº¦çƒ­åŠ›å›¾\n",
        "\n",
        "# %%\n",
        "fig, axes = plt.subplots(1, len(MODELS_TO_TEST), figsize=(8 * len(MODELS_TO_TEST), 7))\n",
        "if len(MODELS_TO_TEST) == 1: axes = [axes] # ç¡®ä¿ axes æ˜¯å¯è¿­ä»£çš„\n",
        "\n",
        "for ax, (name, sim_matrix) in zip(axes, final_similarity_matrices.items()):\n",
        "    sns.heatmap(sim_matrix, ax=ax, cmap='viridis')\n",
        "    ax.set_title(f\"Similarity Matrix - {name}\")\n",
        "    ax.set_xlabel(\"Text Samples\")\n",
        "    ax.set_ylabel(\"Image Samples\")\n",
        "\n",
        "plt.tight_layout()\n",
        "if not DRYRUN:\n",
        "    plt.savefig(OUTPUT_DIR / \"retrieval_similarity_heatmaps.png\", dpi=300)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b1e8910e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ### 5. é˜¶æ®µä¸‰ï¼šå®šé‡è¯„ä¼° - é›¶æ ·æœ¬åˆ†ç±» (Quantitative Evaluation - Classification)\n",
        "#\n",
        "# æˆ‘ä»¬é€šè¿‡åŸºå› è¡¨è¾¾æ•°æ®åˆ›å»ºä¼ªæ ‡ç­¾ï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šç”Ÿç‰©å­¦ç±»åˆ«ä¸Šçš„åˆ†ç±»å‡†ç¡®æ€§ã€‚\n",
        "\n",
        "# %%\n",
        "def create_pseudo_labels(adata: sc.AnnData, queries: Dict[str, str], top_n_spots: int = 50) -> pd.DataFrame:\n",
        "    \"\"\"åŸºäºå•ä¸ªæ ‡å¿—æ€§åŸºå› çš„é«˜è¡¨è¾¾åŒºåŸŸåˆ›å»ºä¼ªæ ‡ç­¾ã€‚\"\"\"\n",
        "    pseudo_labels = pd.Series(index=adata.obs.index, dtype=str)\n",
        "    \n",
        "    # ä¸ºæ¯ä¸ªç±»åˆ«é€‰æ‹©ä¸€ä¸ªä»£è¡¨æ€§å¼ºã€é€šå¸¸å·®å¼‚è¡¨è¾¾çš„åŸºå› \n",
        "    marker_map = {\n",
        "        \"Tumor Epithelium\": \"EPCAM\", \"T Cells\": \"CD3D\", \"B Cells\": \"MS4A1\",\n",
        "        \"Macrophages\": \"CD68\", \"Fibroblasts\": \"FAP\", \"Endothelial Cells\": \"PECAM1\",\n",
        "        \"Smooth Muscle\": \"ACTA2\"\n",
        "    }\n",
        "    \n",
        "    available_genes = adata.var_names\n",
        "    \n",
        "    for label, marker in marker_map.items():\n",
        "        if marker in available_genes:\n",
        "            gene_expression = adata[:, marker].X.toarray().flatten()\n",
        "            top_indices = np.argsort(gene_expression)[-top_n_spots:]\n",
        "            pseudo_labels.iloc[top_indices] = label\n",
        "            \n",
        "    return pseudo_labels.dropna()\n",
        "\n",
        "# --- è¿è¡Œåˆ†ç±»è¯„ä¼° ---\n",
        "pseudo_ground_truth = create_pseudo_labels(sample.adata, text_queries)\n",
        "logging.info(f\"åˆ›å»ºäº† {len(pseudo_ground_truth)} ä¸ªä¼ªæ ‡ç­¾ç”¨äºåˆ†ç±»è¯„ä¼°ã€‚\")\n",
        "classification_results = []\n",
        "\n",
        "for name, results in all_results.items():\n",
        "    predictions = results['labels'].loc[pseudo_ground_truth.index]\n",
        "    \n",
        "    acc = accuracy_score(pseudo_ground_truth, predictions)\n",
        "    f1 = f1_score(pseudo_ground_truth, predictions, average='weighted')\n",
        "    \n",
        "    classification_results.append({\"model\": name, \"accuracy\": acc, \"f1_weighted\": f1})\n",
        "    \n",
        "    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
        "    cm = confusion_matrix(pseudo_ground_truth, predictions, labels=query_labels)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=query_labels)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
        "    ax.set_title(f\"Confusion Matrix - {name}\")\n",
        "    if not DRYRUN:\n",
        "        plt.savefig(OUTPUT_DIR / f\"confusion_matrix_{name.replace(' ', '_')}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "classification_df = pd.DataFrame(classification_results).set_index('model')\n",
        "print(\"\\n--- Zero-Shot Classification Performance (on Pseudo-Labels) ---\")\n",
        "print(classification_df)\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 6. ç»“è®ºä¸æ€»ç»“\n",
        "#\n",
        "# åœ¨è¿™ä¸ª Notebook ä¸­ï¼Œæˆ‘ä»¬ä»ä¸‰ä¸ªæ–¹é¢å¯¹åŸºçº¿ OmiCLIP å’Œæ–°çš„ Spatial CLIP æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼š\n",
        "#\n",
        "# 1.  **å®šæ€§ç©ºé—´æ ‡æ³¨:** è§†è§‰å¯¹æ¯”äº†ä¸¤ä¸ªæ¨¡å‹åœ¨ HEST åˆ‡ç‰‡ä¸Šçš„æ ‡æ³¨ç»“æœã€‚Spatial CLIP æ˜¯å¦åœ¨ç”Ÿç‰©å­¦ä¸Šæ›´åˆç†åœ°èšé›†äº†ç»†èƒç±»å‹ï¼Ÿå®ƒæ˜¯å¦æ›´å¥½åœ°è¯†åˆ«äº†è‚¿ç˜¤è¾¹ç•Œæˆ–å…ç–«æµ¸æ¶¦åŒºåŸŸï¼Ÿ\n",
        "# 2.  **å®šé‡æ£€ç´¢æ€§èƒ½:** é€šè¿‡ Recall@k æŒ‡æ ‡ï¼Œæˆ‘ä»¬è¡¡é‡äº†æ¨¡å‹çš„åŸºç¡€å›¾æ–‡åŒ¹é…èƒ½åŠ›ã€‚å¦‚æœ Spatial CLIP çš„æŒ‡æ ‡æ˜¾è‘—ä½äºåŸºçº¿ï¼Œå¯èƒ½æ„å‘³ç€åœ¨å­¦ä¹ ç©ºé—´å…³ç³»æ—¶ç‰ºç‰²äº†ä¸€éƒ¨åˆ†æ ¸å¿ƒå¯¹é½èƒ½åŠ›ã€‚\n",
        "# 3.  **å®šé‡åˆ†ç±»æ€§èƒ½:** é€šè¿‡åœ¨ä¼ªæ ‡ç­¾ä¸Šçš„å‡†ç¡®ç‡å’Œ F1 åˆ†æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªæ›´å®¢è§‚çš„æ€§èƒ½åº¦é‡ã€‚Spatial CLIP åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„æå‡å°†æ˜¯å…¶æœ‰æ•ˆæ€§çš„æœ‰åŠ›è¯æ®ã€‚\n",
        "#\n",
        "# ç»¼åˆä»¥ä¸Šä¸‰ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºå…³äºå¤šæ­£æ ·æœ¬æŸå¤±æœ‰æ•ˆæ€§çš„åˆæ­¥ç»“è®ºã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6fbb6981",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ### 6. å¯é‡ç”¨çš„åˆ†ç±»ä¸å¯è§†åŒ–å·¥ä½œæµ (Reusable Classification Workflow)\n",
        "#\n",
        "# è¿™ä¸ªå‡½æ•°å°†æ•´ä¸ªé›¶æ ·æœ¬åˆ†ç±»ã€ç»“æœå­˜å‚¨å’Œå¯è§†åŒ–çš„è¿‡ç¨‹æ‰“åŒ…åœ¨ä¸€èµ·ã€‚æ‚¨å¯ä»¥ä¸ºä¸åŒçš„ç”Ÿç‰©å­¦é—®é¢˜å®šä¹‰ä¸åŒçš„ `text_queries` å­—å…¸ï¼Œç„¶åè°ƒç”¨æ­¤å‡½æ•°æ¥å¿«é€Ÿç”Ÿæˆç»“æœã€‚\n",
        "\n",
        "# %%\n",
        "def run_and_visualize_classification(\n",
        "    models_to_test: Dict[str, Dict[str, Any]],\n",
        "    hest_sample: Any, # HESTSample object\n",
        "    text_queries: Dict[str, str],\n",
        "    tokenizer: Any, # open_clip tokenizer\n",
        "    experiment_name: str,\n",
        "    device: str = \"cuda:0\",\n",
        "    batch_size: int = 512,\n",
        "    num_workers: int = 16,\n",
        "):\n",
        "    \"\"\"\n",
        "    å¯¹ç»™å®šçš„æ¨¡å‹å’Œæ–‡æœ¬æŸ¥è¯¢ï¼Œæ‰§è¡Œé›¶æ ·æœ¬åˆ†ç±»ï¼Œæ›´æ–°AnnDataå¯¹è±¡ï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚\n",
        "\n",
        "    Args:\n",
        "        models_to_test (Dict): åŒ…å«æ¨¡å‹åç§°ã€è·¯å¾„å’Œé…ç½®çš„å­—å…¸ã€‚\n",
        "        hest_sample (HESTSample): å·²åŠ è½½çš„HESTæ ·æœ¬å¯¹è±¡ã€‚\n",
        "        text_queries (Dict): ç”¨äºåˆ†ç±»çš„æ–‡æœ¬æŸ¥è¯¢å­—å…¸ (key=ç±»åˆ«å, value=åŸºå› å­—ç¬¦ä¸²)ã€‚\n",
        "        tokenizer (Any): OpenCLIP çš„åˆ†è¯å™¨ã€‚\n",
        "        experiment_name (str): å®éªŒçš„å”¯ä¸€åç§°ï¼Œç”¨äºå‘½åadataåˆ—å’Œè¾“å‡ºæ–‡ä»¶ã€‚\n",
        "        device (str): ç”¨äºæ¨ç†çš„PyTorchè®¾å¤‡ã€‚\n",
        "        batch_size (int): æ¨ç†æ—¶çš„æ‰¹æ¬¡å¤§å°ã€‚\n",
        "        num_workers (int): DataLoaderçš„å·¥ä½œè¿›ç¨‹æ•°ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(f\"--- ğŸš€ å¼€å§‹å®éªŒ: {experiment_name} ---\")\n",
        "    \n",
        "    query_labels = list(text_queries.keys())\n",
        "    \n",
        "    # --- è¿è¡Œæ‰€æœ‰æ¨¡å‹çš„æ¨ç† ---\n",
        "    for model_name, config in models_to_test.items():\n",
        "        logging.info(f\"æ­£åœ¨å¤„ç†æ¨¡å‹: {model_name}...\")\n",
        "        \n",
        "        # 1. åŠ è½½æ¨¡å‹å’Œæ•°æ®é¢„å¤„ç†å™¨\n",
        "        model = load_clip_model(config['path'], config['model_name'], device)\n",
        "        _, _, image_preprocessor = open_clip.create_model_and_transforms(config['model_name'])\n",
        "\n",
        "        # 2. åˆ›å»º DataLoader\n",
        "        spot_dataset = WSISpotDataset(\n",
        "            wsi=hest_sample.wsi, \n",
        "            coords=hest_sample.adata.obsm['spatial'], \n",
        "            transform=image_preprocessor\n",
        "        )\n",
        "        dataloader = DataLoader(\n",
        "            spot_dataset, \n",
        "            batch_size=batch_size, \n",
        "            shuffle=False, \n",
        "            num_workers=num_workers, \n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        # 3. ç¼–ç æ–‡æœ¬æŸ¥è¯¢ (æ¯ä¸ªæ¨¡å‹åªéœ€ä¸€æ¬¡)\n",
        "        with torch.inference_mode():\n",
        "            tokenized_queries = tokenizer(list(text_queries.values())).to(device)\n",
        "            text_features = model.encode_text(tokenized_queries, normalize=True)\n",
        "\n",
        "            # 4. æ‰¹é‡ç¼–ç æ‰€æœ‰å›¾åƒå›¾å—\n",
        "            all_spot_embeddings = []\n",
        "            for image_batch in tqdm(dataloader, desc=f\"æ¨ç†: {model_name}\", leave=False):\n",
        "                image_batch = image_batch.to(device, non_blocking=True)\n",
        "                image_features = model.encode_image(image_batch, normalize=True)\n",
        "                all_spot_embeddings.append(image_features.cpu())\n",
        "        \n",
        "        # 5. è®¡ç®—ç›¸ä¼¼åº¦å¹¶è·å–é¢„æµ‹ç»“æœ\n",
        "        all_spot_embeddings_tensor = torch.cat(all_spot_embeddings)\n",
        "        similarity = all_spot_embeddings_tensor.to(device) @ text_features.T\n",
        "        confidence, predictions = torch.max(torch.softmax(similarity, dim=1), dim=1)\n",
        "\n",
        "        # 6. å°†ç»“æœæ·»åŠ åˆ° AnnData å¯¹è±¡\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name.replace(' ', '_')}\"\n",
        "        conf_col = f\"conf_{experiment_name}_{model_name.replace(' ', '_')}\"\n",
        "        \n",
        "        hest_sample.adata.obs[anno_col] = pd.Categorical(\n",
        "            [query_labels[i] for i in predictions.cpu().numpy()], \n",
        "            categories=query_labels\n",
        "        )\n",
        "        hest_sample.adata.obs[conf_col] = confidence.cpu().numpy()\n",
        "        logging.info(f\"ç»“æœå·²æ·»åŠ åˆ° AnnData: '{anno_col}'\")\n",
        "\n",
        "        # 7. æ¸…ç† GPU å†…å­˜\n",
        "        del model, text_features, all_spot_embeddings_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # --- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ ---\n",
        "    logging.info(\"æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...\")\n",
        "    \n",
        "    # åŠ¨æ€è®¾ç½®è°ƒè‰²æ¿\n",
        "    categories = list(text_queries.keys())\n",
        "    if len(categories) <= 10:\n",
        "        colors = plt.cm.tab10(np.linspace(0, 1, len(categories)))\n",
        "    elif len(categories) <= 20:\n",
        "        colors = plt.cm.tab20(np.linspace(0, 1, len(categories)))\n",
        "    else: # å¯¹äºæ›´å¤šç±»åˆ«ï¼Œä½¿ç”¨è¿ç»­è‰²è°±\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(categories)))\n",
        "    palette = dict(zip(categories, colors))\n",
        "\n",
        "    # åˆ›å»ºå­å›¾\n",
        "    fig, axes = plt.subplots(\n",
        "        1, len(models_to_test), \n",
        "        figsize=(7 * len(models_to_test), 12), \n",
        "        squeeze=False\n",
        "    )\n",
        "    fig.suptitle(f\"{experiment_name} â€“ Sample {hest_sample.sample_id}\", fontsize=20, y=0.9)\n",
        "\n",
        "    plot_params = {\n",
        "        \"show\": False, \"legend_loc\": None, \"frameon\": False,\n",
        "        \"library_id\": hest_sample.sample_id, \"img_key\": 'downscaled_fullres',\n",
        "        \"size\": 1.2, \"s\": 3,\n",
        "    }\n",
        "\n",
        "    for i, (model_name, _) in enumerate(models_to_test.items()):\n",
        "        ax = axes[0, i]\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name.replace(' ', '_')}\"\n",
        "        sc.pl.spatial(\n",
        "            hest_sample.adata,\n",
        "            color=anno_col,\n",
        "            title=f\"{model_name}\\n({experiment_name})\",\n",
        "            ax=ax,\n",
        "            palette=palette,\n",
        "            **plot_params\n",
        "        )\n",
        "\n",
        "    # åˆ›å»ºç»Ÿä¸€çš„å›¾ä¾‹\n",
        "    handles = [mpatches.Patch(color=palette[cat], label=cat) for cat in categories]\n",
        "    fig.legend(handles=handles, title=\"Categories\", loc='center right', bbox_to_anchor=(1.05, 0.5))\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0, 0.90, 0.96])\n",
        "    \n",
        "    if not DRYRUN:\n",
        "        save_path = OUTPUT_DIR / f\"vis_{experiment_name}_comparison_{hest_sample.sample_id}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        logging.info(f\"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    logging.info(f\"--- âœ… å®éªŒ '{experiment_name}' å®Œæˆ ---\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 7. è¿è¡ŒäºŒåˆ†ç±»ä»»åŠ¡ (Tumor vs. Normal)\n",
        "#\n",
        "# ç°åœ¨ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªä¸“é—¨ç”¨äºâ€œè‚¿ç˜¤â€ä¸â€œæ­£å¸¸ç»„ç»‡â€äºŒåˆ†ç±»çš„æŸ¥è¯¢å­—å…¸ï¼Œå¹¶è°ƒç”¨ä¸Šé¢åˆ›å»ºçš„å‡½æ•°ã€‚\n",
        "\n",
        "# %%\n",
        "# --- 1. å®šä¹‰äºŒåˆ†ç±»æŸ¥è¯¢å­—å…¸ ---\n",
        "# non-tumor æŸ¥è¯¢ç»“åˆäº†å¤šç§åŸºè´¨å’Œç»“æ„ç»†èƒç±»å‹çš„æ ‡å¿—æ€§ä½è¡¨è¾¾åŸºå› \n",
        "binary_tumor_queries = {\n",
        "    \"Tumor\": \"EPCAM MKI67 TOP2A PCNA KRT8 KRT18 KRT19 TACSTD2 CENPF UBE2C BIRC5 MCM2 MCM3 MCM4 MCM5 MCM6 MCM7 CDK1 CCNB1 CCNB2 AURKA AURKB CEACAM5 CEACAM6 MUC1 CLDN4 CLDN7 CD44\",\n",
        "    \"Non-Tumor Stroma\": \"TP53 COL1A1 COL1A2 DCN LUM POSTN FN1 SPARC ACTA2 MYH11 TAGLN CNN1 DES MYLK PECAM1 VWF CDH5 KDR CLDN5 TIE1 TEK\"\n",
        "}\n",
        "\n",
        "# --- 2. è¿è¡Œå®éªŒ ---\n",
        "# ç¡®ä¿ sample å’Œ tokenizer å·²ç»åŠ è½½\n",
        "if 'sample' not in locals():\n",
        "    sample = get_hest_sample()\n",
        "if 'tokenizer' not in locals():\n",
        "    tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "    \n",
        "run_and_visualize_classification(\n",
        "    models_to_test=MODELS_TO_TEST,\n",
        "    hest_sample=sample,\n",
        "    text_queries=binary_tumor_queries,\n",
        "    tokenizer=tokenizer,\n",
        "    experiment_name=\"Binary_Tumor_vs_Normal\",\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 8. (å¯é€‰) ä½¿ç”¨åŸå§‹å¤šåˆ†ç±»æŸ¥è¯¢å†æ¬¡è¿è¡Œ\n",
        "#\n",
        "# ä¸ºäº†å±•ç¤ºå‡½æ•°çš„çµæ´»æ€§ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°ä½¿ç”¨åŸå§‹çš„å¤šåˆ†ç±»æŸ¥è¯¢å­—å…¸å†æ¬¡è¿è¡Œå®ƒï¼Œç”Ÿæˆå¦ä¸€ç»„ç‹¬ç«‹çš„åˆ†æç»“æœã€‚\n",
        "\n",
        "# %%\n",
        "# --- 1. ä½¿ç”¨åŸå§‹çš„å¤šåˆ†ç±»æŸ¥è¯¢å­—å…¸ ---\n",
        "# (è¿™ä¸ªå­—å…¸å·²åœ¨ä¹‹å‰çš„å•å…ƒæ ¼ä¸­å®šä¹‰)\n",
        "\n",
        "# --- 2. è¿è¡Œå¤šåˆ†ç±»å®éªŒ ---\n",
        "run_and_visualize_classification(\n",
        "    models_to_test=MODELS_TO_TEST,\n",
        "    hest_sample=sample,\n",
        "    text_queries=text_queries, # ä½¿ç”¨åŸå§‹çš„å¤šåˆ†ç±»å­—å…¸\n",
        "    tokenizer=tokenizer,\n",
        "    experiment_name=\"Multi_Class_Annotation\",\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71dd372d",
      "metadata": {},
      "source": [
        "# New Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "964abb8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # å¯å¤ç”¨çš„ç©ºé—´CLIPæ¨¡å‹è¯„ä¼°å·¥ä½œæµ\n",
        "#\n",
        "# **ç›®æ ‡:** æä¾›ä¸€ä¸ªæ¨¡å—åŒ–çš„å‡½æ•°ï¼Œå¯ä»¥å¯¹ä»»æ„HESTæ ·æœ¬å’Œä»»æ„ç”Ÿç‰©å­¦æŸ¥è¯¢é›†ï¼Œæ‰§è¡Œå¤šæ¨¡å‹çš„é›¶æ ·æœ¬åˆ†ç±»æ¯”è¾ƒï¼Œå¹¶ç”Ÿæˆæ ‡å‡†åŒ–çš„å¯è§†åŒ–æŠ¥å‘Šã€‚\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 1. å¯¼å…¥ä¸ç¯å¢ƒé…ç½® (Imports & Configuration)\n",
        "\n",
        "# %%\n",
        "# --- æ ¸å¿ƒåŸåˆ™ ---\n",
        "# ğŸ›¡ï¸ å®‰å…¨ç¬¬ä¸€: é»˜è®¤åœ¨é¢„æ¼”æ¨¡å¼ä¸‹è¿è¡Œä»¥æ£€æŸ¥è·¯å¾„å’Œé…ç½®\n",
        "DRYRUN = False\n",
        "\n",
        "# --- æ ‡å‡†åº“ ---\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple, List\n",
        "\n",
        "# --- ç¬¬ä¸‰æ–¹åº“ ---\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "from PIL import Image, ImageFile\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# --- é¡¹ç›®è·¯å¾„é…ç½® ---\n",
        "PROJECT_ROOT = Path(\"/home1/jijh/diffusion_project/git_repo/yuanspace\")\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "    print(f\"å·²å°† '{PROJECT_ROOT}' æ·»åŠ åˆ° sys.path\")\n",
        "\n",
        "# --- æœ¬åœ°é¡¹ç›®åº“ ---\n",
        "try:\n",
        "    import open_clip\n",
        "    from src.spaglam_preproc.utils.hest_loading import HESTDataset, HESTSample\n",
        "except ImportError as e:\n",
        "    print(f\"å¯¼å…¥é”™è¯¯: {e}\\nè¯·ç¡®ä¿æ‚¨çš„é¡¹ç›®ç»“æ„å’Œè·¯å¾„é…ç½®æ­£ç¡®ã€‚\")\n",
        "    raise\n",
        "\n",
        "# --- é…ç½®æ—¥å¿— ---\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', stream=sys.stdout)\n",
        "\n",
        "\n",
        "# %%\n",
        "# --- è·¯å¾„ä¸æ¨¡å‹é…ç½® ---\n",
        "# --- æ•°æ®è·¯å¾„ ---\n",
        "HEST_DATA_DIR = Path(\"/cwStorage/nodecw_group/jijh/hest_1k\")\n",
        "\n",
        "# --- è¾“å‡ºç›®å½• (æ–°) ---\n",
        "OUTPUT_DIR = Path(\"/cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline\")\n",
        "\n",
        "# --- æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ ---\n",
        "BASELINE_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt\")\n",
        "SPATIAL_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/spatial_clip_base_model/multi_positice_loss50.pt\")\n",
        "\n",
        "# --- æ¨¡å‹æ¶æ„ ---\n",
        "MODEL_NAME = \"ViT-B-32\"\n",
        "\n",
        "# --- æ¨ç†é…ç½® ---\n",
        "BATCH_SIZE = 512\n",
        "NUM_WORKERS = 16\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- å¾…æµ‹è¯•æ¨¡å‹æ¸…å• ---\n",
        "MODELS_TO_TEST = {\n",
        "    \"OmiCLIP (Baseline)\": {\n",
        "        \"path\": BASELINE_MODEL_CKPT,\n",
        "        \"model_name\": MODEL_NAME,\n",
        "    },\n",
        "    \"Spatial CLIP (Ours)\": {\n",
        "        \"path\": SPATIAL_MODEL_CKPT,\n",
        "        \"model_name\": MODEL_NAME,\n",
        "    },\n",
        "}\n",
        "\n",
        "# --- æ£€æŸ¥ä¸å‡†å¤‡ ---\n",
        "if not DRYRUN:\n",
        "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "    logging.info(f\"è¾“å‡ºå°†ä¿å­˜åˆ°: {OUTPUT_DIR}\")\n",
        "\n",
        "for name, config in MODELS_TO_TEST.items():\n",
        "    assert config['path'].exists(), f\"æ¨¡å‹ '{name}' çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {config['path']}\"\n",
        "assert HEST_DATA_DIR.exists(), f\"HEST æ•°æ®ç›®å½•ä¸å­˜åœ¨: {HEST_DATA_DIR}\"\n",
        "\n",
        "logging.info(f\"é…ç½®å®Œæˆã€‚ä½¿ç”¨è®¾å¤‡: {DEVICE}\")\n",
        "logging.info(f\"é¢„æ¼”æ¨¡å¼ (DRYRUN): {DRYRUN}\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 2. æ ¸å¿ƒå‡½æ•°ï¼šæ¨¡å‹åŠ è½½ä¸æ•°æ®å‡†å¤‡ (Core Functions)\n",
        "\n",
        "# %%\n",
        "def load_clip_model(checkpoint_path: Path, model_name: str, device: str) -> torch.nn.Module:\n",
        "    \"\"\"ä»ç»™å®šçš„æ£€æŸ¥ç‚¹è·¯å¾„åŠ è½½ CLIP æ¨¡å‹ã€‚\"\"\"\n",
        "    logging.info(f\"æ­£åœ¨åŠ è½½æ¨¡å‹ '{model_name}' ä»: {checkpoint_path}\")\n",
        "    model, _, _ = open_clip.create_model_and_transforms(model_name, pretrained=None)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
        "    if all(key.startswith('module.') for key in state_dict.keys()):\n",
        "        state_dict = {k[len('module.'):]: v for k, v in state_dict.items()}\n",
        "    try:\n",
        "        model.load_state_dict(state_dict)\n",
        "    except RuntimeError as e:\n",
        "        logging.warning(f\"åŠ è½½ state_dict ä¸¥æ ¼æ¨¡å¼å¤±è´¥: {e}ã€‚å°è¯•éä¸¥æ ¼æ¨¡å¼...\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    logging.info(f\"æ¨¡å‹ '{model_name}' åŠ è½½æˆåŠŸã€‚\")\n",
        "    return model\n",
        "\n",
        "def get_hest_sample(sample_id: str) -> HESTSample:\n",
        "    \"\"\"åŠ è½½å¹¶å‡†å¤‡ä¸€ä¸ª HEST æ ·æœ¬ç”¨äºåˆ†æã€‚\"\"\"\n",
        "    logging.info(f\"åŠ è½½ HEST æ ·æœ¬: {sample_id}...\")\n",
        "    hest_dataset = HESTDataset(data_dir=HEST_DATA_DIR)\n",
        "    sample = hest_dataset.get_samples(sample_ids=[sample_id])[0]\n",
        "    sample.load_st_data(lazy=False)\n",
        "    sample.load_wsi()\n",
        "    \n",
        "    spatial_data = sample.adata.uns['spatial']['ST']\n",
        "    library_id = sample.sample_id\n",
        "    sample.adata.uns['spatial'] = {library_id: spatial_data}\n",
        "    logging.info(f\"æ ·æœ¬ '{sample.sample_id}' åŠ è½½å¹¶å‡†å¤‡å®Œæ¯•ã€‚\")\n",
        "    return sample\n",
        "\n",
        "class WSISpotDataset(Dataset):\n",
        "    \"\"\"ä¸€ä¸ªè‡ªå®šä¹‰æ•°æ®é›†ï¼Œç”¨äºä»WSIä¸­æŒ‰éœ€åŠ è½½spotå¯¹åº”çš„å›¾å—ã€‚\"\"\"\n",
        "    def __init__(self, wsi, coords, transform):\n",
        "        self.wsi = wsi\n",
        "        self.coords = coords\n",
        "        self.transform = transform\n",
        "        self.patch_size = (224, 224)\n",
        "        self.patch_radius = self.patch_size[0] // 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        c = self.coords[idx]\n",
        "        top_left_coord = (int(c[0] - self.patch_radius), int(c[1] - self.patch_radius))\n",
        "        tile = self.wsi.read_region(top_left_coord, 0, self.patch_size).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            tile = self.transform(tile)\n",
        "        return tile\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 3. ä¸»å·¥ä½œæµå‡½æ•° (Main Workflow Function)\n",
        "#\n",
        "# è¿™æ˜¯æˆ‘ä»¬å°è£…å¥½çš„æ ¸å¿ƒè¯„ä¼°å‡½æ•°ã€‚\n",
        "\n",
        "# %%\n",
        "def run_and_visualize_experiment(\n",
        "    sample_id: str,\n",
        "    text_queries: Dict[str, str],\n",
        "    experiment_name: str,\n",
        "    models_to_test: Dict[str, Dict[str, Any]] = MODELS_TO_TEST,\n",
        "    output_dir: Path = OUTPUT_DIR,\n",
        "    device: str = DEVICE,\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "    num_workers: int = NUM_WORKERS,\n",
        ") -> HESTSample:\n",
        "    \"\"\"\n",
        "    å¯¹æŒ‡å®šçš„æ ·æœ¬å’Œæ–‡æœ¬æŸ¥è¯¢ï¼Œæ‰§è¡Œå¤šæ¨¡å‹é›¶æ ·æœ¬åˆ†ç±»æ¯”è¾ƒï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šã€‚\n",
        "\n",
        "    Args:\n",
        "        sample_id (str): è¦åˆ†æçš„ HEST æ ·æœ¬ID (ä¾‹å¦‚ 'TENX99')ã€‚\n",
        "        text_queries (Dict): ç”¨äºåˆ†ç±»çš„æ–‡æœ¬æŸ¥è¯¢å­—å…¸ (key=ç±»åˆ«å, value=åŸºå› å­—ç¬¦ä¸²)ã€‚\n",
        "        experiment_name (str): å®éªŒçš„å”¯ä¸€åç§°ï¼Œç”¨äºå‘½åadataåˆ—å’Œè¾“å‡ºæ–‡ä»¶ã€‚\n",
        "        models_to_test (Dict): åŒ…å«å¾…æµ‹æ¨¡å‹é…ç½®çš„å­—å…¸ã€‚\n",
        "        output_dir (Path): ä¿å­˜å¯è§†åŒ–ç»“æœçš„ç›®å½•ã€‚\n",
        "        device (str): PyTorchè®¾å¤‡ã€‚\n",
        "        batch_size (int): æ¨ç†æ‰¹æ¬¡å¤§å°ã€‚\n",
        "        num_workers (int): DataLoaderå·¥ä½œè¿›ç¨‹æ•°ã€‚\n",
        "        \n",
        "    Returns:\n",
        "        HESTSample: åŒ…å«æ ‡æ³¨ç»“æœçš„ HEST æ ·æœ¬å¯¹è±¡ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(f\"--- ğŸš€ å¼€å§‹å®éªŒ: '{experiment_name}' on sample '{sample_id}' ---\")\n",
        "    \n",
        "    # 1. åŠ è½½æ•°æ®\n",
        "    sample = get_hest_sample(sample_id)\n",
        "    tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "    query_labels = list(text_queries.keys())\n",
        "    \n",
        "    # --- 2. è¿è¡Œæ‰€æœ‰æ¨¡å‹çš„æ¨ç† ---\n",
        "    for model_name, config in models_to_test.items():\n",
        "        logging.info(f\"æ­£åœ¨å¤„ç†æ¨¡å‹: {model_name}...\")\n",
        "        \n",
        "        model = load_clip_model(config['path'], config['model_name'], device)\n",
        "        _, _, image_preprocessor = open_clip.create_model_and_transforms(config['model_name'])\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            WSISpotDataset(wsi=sample.wsi, coords=sample.adata.obsm['spatial'], transform=image_preprocessor),\n",
        "            batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            tokenized_queries = tokenizer(list(text_queries.values())).to(device)\n",
        "            text_features = model.encode_text(tokenized_queries, normalize=True)\n",
        "\n",
        "            all_spot_embeddings = []\n",
        "            for image_batch in tqdm(dataloader, desc=f\"æ¨ç†: {model_name}\", leave=False):\n",
        "                image_features = model.encode_image(image_batch.to(device), normalize=True)\n",
        "                all_spot_embeddings.append(image_features.cpu())\n",
        "        \n",
        "        all_spot_embeddings_tensor = torch.cat(all_spot_embeddings)\n",
        "        similarity = all_spot_embeddings_tensor.to(device) @ text_features.T\n",
        "        confidence, predictions = torch.max(torch.softmax(similarity, dim=1), dim=1)\n",
        "\n",
        "        # --- 3. å°†ç»“æœæ·»åŠ åˆ° AnnData å¯¹è±¡ ---\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        conf_col = f\"conf_{experiment_name}_{model_name_safe}\"\n",
        "        \n",
        "        sample.adata.obs[anno_col] = pd.Categorical(\n",
        "            [query_labels[i] for i in predictions.cpu().numpy()], \n",
        "            categories=query_labels\n",
        "        )\n",
        "        sample.adata.obs[conf_col] = confidence.cpu().numpy()\n",
        "        logging.info(f\"ç»“æœå·²æ·»åŠ åˆ° AnnData: '{anno_col}'\")\n",
        "\n",
        "        del model, text_features, all_spot_embeddings_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # --- 4. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ ---\n",
        "    logging.info(\"æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...\")\n",
        "    \n",
        "    categories = list(text_queries.keys())\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(categories))) if len(categories) <= 10 else plt.cm.viridis(np.linspace(0, 1, len(categories)))\n",
        "    palette = dict(zip(categories, sns.color_palette(\"Set1\", len(categories))))\n",
        "\n",
        "    fig, axes = plt.subplots(1, len(models_to_test), figsize=(7 * len(models_to_test), 12), squeeze=False)\n",
        "    fig.suptitle(f\"'{experiment_name}' on Sample '{sample_id}'\", fontsize=20, y=0.9)\n",
        "\n",
        "    plot_params = {\n",
        "        \"show\": False, \"legend_loc\": None, \"frameon\": False,\n",
        "        \"library_id\": sample.sample_id, \"img_key\": 'downscaled_fullres', \"size\": 1.2, \"s\": 1.5,\n",
        "    }\n",
        "\n",
        "    for i, (model_name, _) in enumerate(models_to_test.items()):\n",
        "        ax = axes[0, i]\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        sc.pl.spatial(sample.adata, color=anno_col, title=f\"{model_name}\", ax=ax, palette=palette, **plot_params)\n",
        "\n",
        "    handles = [mpatches.Patch(color=palette[cat], label=cat) for cat in categories]\n",
        "    fig.legend(handles=handles, title=\"Categories\", loc='center right', bbox_to_anchor=(1.05, 0.5))\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0, 0.90, 0.96])\n",
        "    \n",
        "    if not DRYRUN:\n",
        "        save_path = output_dir / f\"vis_{experiment_name}_comparison_{sample_id}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        logging.info(f\"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    logging.info(f\"--- âœ… å®éªŒ '{experiment_name}' å®Œæˆ ---\")\n",
        "    return sample\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 4. æ‰§è¡ŒäºŒåˆ†ç±»ä¹³è…ºç™Œå®éªŒ (Run Binary Breast Cancer Experiment)\n",
        "#\n",
        "# ç°åœ¨ï¼Œæˆ‘ä»¬å®šä¹‰é’ˆå¯¹ä¹³è…ºç™Œçš„äºŒåˆ†ç±»æŸ¥è¯¢ï¼Œå¹¶ä½¿ç”¨æ–°æ ·æœ¬ `TENX99` è°ƒç”¨ä¸»å‡½æ•°ã€‚\n",
        "\n",
        "# %%\n",
        "# --- 1. å®šä¹‰ä¹³è…ºç™ŒäºŒåˆ†ç±»æŸ¥è¯¢ ---\n",
        "# åŸºäºæ‚¨çš„æè¿°ï¼Œ\"non-tumor\" æŸ¥è¯¢å°†åŒ…å«è‚¿ç˜¤ä½è¡¨è¾¾çš„åŸºå› ã€‚\n",
        "# è¿™é‡Œçš„åŸºå› åˆ—è¡¨æ˜¯ç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥æ›¿æ¢ä¸ºæ›´ç²¾ç¡®çš„åˆ—è¡¨ã€‚\n",
        "breast_cancer_binary_queries = {\n",
        "    \"Tumor (IDC)\": (\n",
        "        \"KRT8 KRT18 KRT19 EPCAM MUC1 CLDN3 CLDN4 CLDN7 CDH1 KRT7 \"\n",
        "        \"ERBB2 GRB7 ERBB3 ESR1 PGR FOXA1 GATA3 AGR2 TFF1 TFF3 \"\n",
        "        \"TRPS1 SCGB2A2 BCL2 AR MKI67 TOP2A MYC CCND1 EGFR BIRC5 \"\n",
        "        \"UBE2C CCNA2 CCNB1 CDC20 PLK1 AURKA AURKB CENPF NUSAP1 KIF11 \"\n",
        "        \"KIF2C PTTG1 PRC1 ANLN MCM2 MCM4 MCM6 MCM7 TK1 PCNA\"\n",
        "    ),\n",
        "    \"Normal & Stroma\": (\n",
        "        \"COL1A1 COL1A2 COL3A1 COL5A1 COL5A2 COL6A1 COL6A2 COL6A3 FN1 VIM \"\n",
        "        \"LUM DCN BGN THY1 FAP PDGFRB RGS5 CSPG4 ACTA2 TAGLN \"\n",
        "        \"MYH11 CNN1 DES VWF PECAM1 CLDN5 KDR FLT1 ENG CD34 \"\n",
        "        \"MCAM PDPN PROX1 LYVE1 PTPRC LST1 LYZ CSF1R CD68 C1QB \"\n",
        "        \"ITGAM ITGAX HLA-DRA HLA-DPB1 CD3D CD4 CD8A TRAC MS4A1 CD79A\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "# --- 2. è¿è¡Œå®éªŒ ---\n",
        "if not DRYRUN:\n",
        "    # åªæœ‰åœ¨éé¢„æ¼”æ¨¡å¼ä¸‹æ‰è¿è¡Œï¼Œå› ä¸ºå®ƒæ¶‰åŠå¤§é‡è®¡ç®—\n",
        "    sample_with_results = run_and_visualize_experiment(\n",
        "        sample_id=\"TENX99\",\n",
        "        text_queries=breast_cancer_binary_queries,\n",
        "        experiment_name=\"Breast_Cancer_Binary\"\n",
        "    )\n",
        "else:\n",
        "    logging.warning(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡å®éªŒæ‰§è¡Œã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7db817a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n",
        "    sample_with_results.adata,\n",
        "    color=f\"anno_Breast_Cancer_Binary_OmiCLIP_Baseline\",\n",
        "    title=f\"OmiCLIP (Baseline) - Breast Cancer Binary Annotation\",\n",
        "    s = 0,\n",
        "    show = True,\n",
        "    legend_loc = None,\n",
        "    frameon = False,\n",
        "    library_id = sample_with_results.sample_id, \n",
        "    img_key = 'downscaled_fullres',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7b660a97",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ### 3. ä¸»å·¥ä½œæµå‡½æ•° (Main Workflow Function) - V2 with Quantitative Metrics\n",
        "#\n",
        "# è¿™ä¸ªæ›´æ–°ç‰ˆæœ¬å¢åŠ äº†è‡ªåŠ¨ç”Ÿæˆä¼ªæ ‡ç­¾å’Œè®¡ç®—å®šé‡æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€F1åˆ†æ•°ã€æ··æ·†çŸ©é˜µï¼‰çš„åŠŸèƒ½ã€‚\n",
        "\n",
        "# %%\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def create_pseudo_labels(\n",
        "    adata: sc.AnnData, \n",
        "    marker_map: Dict[str, str], \n",
        "    top_n_spots: int = 50\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    åŸºäºå•ä¸ªæ ‡å¿—æ€§åŸºå› çš„é«˜è¡¨è¾¾åŒºåŸŸåˆ›å»ºä¼ªæ ‡ç­¾ã€‚\n",
        "\n",
        "    Args:\n",
        "        adata (sc.AnnData): åŒ…å«åŸºå› è¡¨è¾¾æ•°æ®çš„ AnnData å¯¹è±¡ã€‚\n",
        "        marker_map (Dict[str, str]): å°†ç±»åˆ«åæ˜ å°„åˆ°å…¶ä»£è¡¨æ€§æ ‡å¿—åŸºå› çš„å­—å…¸ã€‚\n",
        "        top_n_spots (int): ä¸ºæ¯ä¸ªæ ‡å¿—åŸºå› é€‰æ‹©çš„æœ€é«˜è¡¨è¾¾ spot çš„æ•°é‡ã€‚\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: ç´¢å¼•ä¸º spot IDï¼Œå€¼ä¸ºä¼ªæ ‡ç­¾çš„ Seriesã€‚\n",
        "    \"\"\"\n",
        "    pseudo_labels = pd.Series(index=adata.obs.index, dtype=object)\n",
        "    available_genes = adata.var_names\n",
        "    \n",
        "    logging.info(f\"æ­£åœ¨åˆ›å»ºä¼ªæ ‡ç­¾ (top {top_n_spots} spots per marker)...\")\n",
        "    \n",
        "    # ä¸ºäº†é¿å…é‡å ï¼Œæˆ‘ä»¬è®°å½•å·²è¢«åˆ†é…çš„ spots\n",
        "    assigned_indices = set()\n",
        "\n",
        "    for label, marker in marker_map.items():\n",
        "        if marker not in available_genes:\n",
        "            logging.warning(f\"æ ‡å¿—æ€§åŸºå›  '{marker}' åœ¨æ•°æ®ä¸­æœªæ‰¾åˆ°ï¼Œè·³è¿‡ '{label}' ç±»åˆ«ã€‚\")\n",
        "            continue\n",
        "            \n",
        "        gene_expression = adata[:, marker].X.toarray().flatten()\n",
        "        \n",
        "        # æ’åºæ‰€æœ‰ spotsï¼Œæ‰¾åˆ°è¡¨è¾¾é‡æœ€é«˜çš„\n",
        "        sorted_indices = np.argsort(gene_expression)[::-1]\n",
        "        \n",
        "        # ä»æœªè¢«åˆ†é…çš„ spots ä¸­é€‰æ‹© top_n\n",
        "        top_unassigned_indices = [\n",
        "            idx for idx in sorted_indices if idx not in assigned_indices\n",
        "        ][:top_n_spots]\n",
        "        \n",
        "        if top_unassigned_indices:\n",
        "            pseudo_labels.iloc[top_unassigned_indices] = label\n",
        "            assigned_indices.update(top_unassigned_indices)\n",
        "            logging.info(f\"ä¸º '{label}' åˆ†é…äº† {len(top_unassigned_indices)} ä¸ªä¼ªæ ‡ç­¾ (åŸºäºåŸºå›  {marker})ã€‚\")\n",
        "\n",
        "    labeled_spots = pseudo_labels.dropna()\n",
        "    logging.info(f\"ä¼ªæ ‡ç­¾åˆ›å»ºå®Œæˆï¼Œå…±æ ‡è®°äº† {len(labeled_spots)} ä¸ª spotsï¼Œæ¶µç›– {labeled_spots.nunique()} ä¸ªç±»åˆ«ã€‚\")\n",
        "    return labeled_spots\n",
        "\n",
        "\n",
        "def run_and_visualize_experiment(\n",
        "    sample_id: str,\n",
        "    text_queries: Dict[str, str],\n",
        "    experiment_name: str,\n",
        "    marker_map: Dict[str, str], # æ–°å¢ï¼šæ ‡å¿—æ€§åŸºå› æ˜ å°„\n",
        "    models_to_test: Dict[str, Dict[str, Any]] = MODELS_TO_TEST,\n",
        "    output_dir: Path = OUTPUT_DIR,\n",
        "    device: str = DEVICE,\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "    num_workers: int = NUM_WORKERS,\n",
        ") -> HESTSample:\n",
        "    \"\"\"\n",
        "    å¯¹æŒ‡å®šçš„æ ·æœ¬å’ŒæŸ¥è¯¢ï¼Œæ‰§è¡Œå¤šæ¨¡å‹é›¶æ ·æœ¬åˆ†ç±»ï¼Œè¿›è¡Œå®šæ€§å¯è§†åŒ–å’Œå®šé‡è¯„ä¼°ã€‚\n",
        "\n",
        "    Args:\n",
        "        sample_id (str): è¦åˆ†æçš„ HEST æ ·æœ¬IDã€‚\n",
        "        text_queries (Dict): ç”¨äºåˆ†ç±»çš„æ–‡æœ¬æŸ¥è¯¢å­—å…¸ã€‚\n",
        "        experiment_name (str): å®éªŒçš„å”¯ä¸€åç§°ã€‚\n",
        "        marker_map (Dict[str, str]): å°†ç±»åˆ«åæ˜ å°„åˆ°æ ‡å¿—åŸºå› çš„å­—å…¸ï¼Œç”¨äºç”Ÿæˆä¼ªæ ‡ç­¾ã€‚\n",
        "        (å…¶ä»–å‚æ•°åŒå‰)\n",
        "        \n",
        "    Returns:\n",
        "        HESTSample: åŒ…å«æ ‡æ³¨å’Œè¯„ä¼°ç»“æœçš„ HEST æ ·æœ¬å¯¹è±¡ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(f\"--- ğŸš€ å¼€å§‹å®éªŒ: '{experiment_name}' on sample '{sample_id}' ---\")\n",
        "    \n",
        "    # 1. åŠ è½½æ•°æ®\n",
        "    sample = get_hest_sample(sample_id)\n",
        "    tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "    query_labels = list(text_queries.keys())\n",
        "    \n",
        "    # --- 2. è¿è¡Œæ‰€æœ‰æ¨¡å‹çš„æ¨ç† (æ­¤éƒ¨åˆ†é€»è¾‘ä¸å˜) ---\n",
        "    for model_name, config in models_to_test.items():\n",
        "        logging.info(f\"æ­£åœ¨å¤„ç†æ¨¡å‹: {model_name}...\")\n",
        "        \n",
        "        model = load_clip_model(config['path'], config['model_name'], device)\n",
        "        _, _, image_preprocessor = open_clip.create_model_and_transforms(config['model_name'])\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            WSISpotDataset(wsi=sample.wsi, coords=sample.adata.obsm['spatial'], transform=image_preprocessor),\n",
        "            batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            tokenized_queries = tokenizer(list(text_queries.values())).to(device)\n",
        "            text_features = model.encode_text(tokenized_queries, normalize=True)\n",
        "\n",
        "            all_spot_embeddings = []\n",
        "            for image_batch in tqdm(dataloader, desc=f\"æ¨ç†: {model_name}\", leave=False):\n",
        "                image_features = model.encode_image(image_batch.to(device), normalize=True)\n",
        "                all_spot_embeddings.append(image_features.cpu())\n",
        "        \n",
        "        all_spot_embeddings_tensor = torch.cat(all_spot_embeddings)\n",
        "        similarity = all_spot_embeddings_tensor.to(device) @ text_features.T\n",
        "        confidence, predictions = torch.max(torch.softmax(similarity, dim=1), dim=1)\n",
        "\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        conf_col = f\"conf_{experiment_name}_{model_name_safe}\"\n",
        "        \n",
        "        sample.adata.obs[anno_col] = pd.Categorical(\n",
        "            [query_labels[i] for i in predictions.cpu().numpy()], \n",
        "            categories=query_labels\n",
        "        )\n",
        "        sample.adata.obs[conf_col] = confidence.cpu().numpy()\n",
        "        logging.info(f\"ç»“æœå·²æ·»åŠ åˆ° AnnData: '{anno_col}'\")\n",
        "\n",
        "        del model, text_features, all_spot_embeddings_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # --- 3. å®šæ€§å¯è§†åŒ– (æ­¤éƒ¨åˆ†é€»è¾‘ä¸å˜) ---\n",
        "    logging.info(\"--- ğŸ“Š é˜¶æ®µä¸€: å®šæ€§è¯„ä¼° (å¯è§†åŒ–) ---\")\n",
        "    # ... (å¯è§†åŒ–ä»£ç ä¿æŒä¸å˜ï¼Œæ­¤å¤„ä¸ºç²¾ç®€ç‰ˆ) ...\n",
        "    fig, axes = plt.subplots(1, len(models_to_test), figsize=(7 * len(models_to_test), 12), squeeze=False)\n",
        "    # ... (å®Œæ•´ç»˜å›¾ä»£ç ) ...\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # --- 4. å®šé‡è¯„ä¼° (æ–°å¢) ---\n",
        "    logging.info(\"--- ğŸ“ˆ é˜¶æ®µäºŒ: å®šé‡è¯„ä¼° (åŸºäºä¼ªæ ‡ç­¾) ---\")\n",
        "    pseudo_ground_truth = create_pseudo_labels(sample.adata, marker_map)\n",
        "    \n",
        "    if pseudo_ground_truth.empty:\n",
        "        logging.warning(\"æœªèƒ½ç”Ÿæˆä»»ä½•ä¼ªæ ‡ç­¾ï¼Œè·³è¿‡å®šé‡è¯„ä¼°ã€‚è¯·æ£€æŸ¥ marker_map ä¸­çš„åŸºå› æ˜¯å¦å­˜åœ¨äºæ•°æ®ä¸­ã€‚\")\n",
        "        return sample\n",
        "\n",
        "    classification_results = []\n",
        "    \n",
        "    # å‡†å¤‡æ··æ·†çŸ©é˜µçš„å­å›¾\n",
        "    fig_cm, axes_cm = plt.subplots(1, len(models_to_test), figsize=(8 * len(models_to_test), 7), squeeze=False)\n",
        "    fig_cm.suptitle(f\"Confusion Matrices for '{experiment_name}' on Sample '{sample_id}'\", fontsize=20, y=1.02)\n",
        "    axes_cm = axes_cm.flatten()\n",
        "\n",
        "    for i, (model_name, _) in enumerate(models_to_test.items()):\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        \n",
        "        predictions = sample.adata.obs[anno_col].loc[pseudo_ground_truth.index]\n",
        "        \n",
        "        # ç¡®ä¿æ ‡ç­¾é›†ä¸€è‡´\n",
        "        labels = sorted(list(set(pseudo_ground_truth) | set(predictions)))\n",
        "        \n",
        "        acc = accuracy_score(pseudo_ground_truth, predictions)\n",
        "        f1 = f1_score(pseudo_ground_truth, predictions, average='weighted', labels=labels, zero_division=0)\n",
        "        \n",
        "        classification_results.append({\"model\": model_name, \"accuracy\": acc, \"f1_weighted\": f1})\n",
        "        \n",
        "        # è®¡ç®—å¹¶ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
        "        cm = confusion_matrix(pseudo_ground_truth, predictions, labels=labels)\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        disp.plot(ax=axes_cm[i], xticks_rotation='vertical', cmap='Blues')\n",
        "        axes_cm[i].set_title(f\"{model_name}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if not DRYRUN:\n",
        "        save_path = output_dir / f\"conf_matrix_{experiment_name}_comparison_{sample_id}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        logging.info(f\"æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜åˆ°: {save_path}\")\n",
        "    plt.show()\n",
        "    \n",
        "    classification_df = pd.DataFrame(classification_results).set_index('model')\n",
        "    print(\"\\n--- Zero-Shot Classification Performance (on Pseudo-Labels) ---\")\n",
        "    print(classification_df)\n",
        "    if not DRYRUN:\n",
        "        df_save_path = output_dir / f\"metrics_{experiment_name}_{sample_id}.csv\"\n",
        "        classification_df.to_csv(df_save_path)\n",
        "        logging.info(f\"åˆ†ç±»æŒ‡æ ‡å·²ä¿å­˜åˆ°: {df_save_path}\")\n",
        "\n",
        "    logging.info(f\"--- âœ… å®éªŒ '{experiment_name}' å®Œæˆ ---\")\n",
        "    return sample\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 4. æ‰§è¡ŒäºŒåˆ†ç±»ä¹³è…ºç™Œå®éªŒ (Run Binary Breast Cancer Experiment)\n",
        "#\n",
        "# ç°åœ¨ï¼Œæˆ‘ä»¬å®šä¹‰é’ˆå¯¹ä¹³è…ºç™Œçš„äºŒåˆ†ç±»æŸ¥è¯¢**ä»¥åŠå¯¹åº”çš„æ ‡å¿—æ€§åŸºå› æ˜ å°„**ï¼Œç„¶åè°ƒç”¨ä¸»å‡½æ•°ã€‚\n",
        "\n",
        "# %%\n",
        "# --- 1. å®šä¹‰æŸ¥è¯¢å­—å…¸ ---\n",
        "breast_cancer_binary_queries = {\n",
        "    \"Tumor (IDC)\": (\n",
        "        \"KRT8 KRT18 KRT19 EPCAM MUC1 CLDN3 CLDN4 CLDN7 CDH1 KRT7 \"\n",
        "        \"ERBB2 GRB7 ERBB3 ESR1 PGR FOXA1 GATA3 AGR2 TFF1 TFF3 \"\n",
        "        \"TRPS1 SCGB2A2 BCL2 AR MKI67 TOP2A MYC CCND1 EGFR BIRC5 \"\n",
        "        \"UBE2C CCNA2 CCNB1 CDC20 PLK1 AURKA AURKB CENPF NUSAP1 KIF11 \"\n",
        "        \"KIF2C PTTG1 PRC1 ANLN MCM2 MCM4 MCM6 MCM7 TK1 PCNA\"\n",
        "    ),\n",
        "    \"Normal & Stroma\": (\n",
        "        \"COL1A1 COL1A2 COL3A1 COL5A1 COL5A2 COL6A1 COL6A2 COL6A3 FN1 VIM \"\n",
        "        \"LUM DCN BGN THY1 FAP PDGFRB RGS5 CSPG4 ACTA2 TAGLN \"\n",
        "        \"MYH11 CNN1 DES VWF PECAM1 CLDN5 KDR FLT1 ENG CD34 \"\n",
        "        \"MCAM PDPN PROX1 LYVE1 PTPRC LST1 LYZ CSF1R CD68 C1QB \"\n",
        "        \"ITGAM ITGAX HLA-DRA HLA-DPB1 CD3D CD4 CD8A TRAC MS4A1 CD79A\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "# --- 2. å®šä¹‰ç”¨äºç”Ÿæˆä¼ªæ ‡ç­¾çš„æ ‡å¿—æ€§åŸºå› æ˜ å°„ ---\n",
        "#    - key å¿…é¡»ä¸ä¸Šé¢æŸ¥è¯¢å­—å…¸çš„ key å®Œå…¨åŒ¹é…ã€‚\n",
        "#    - value æ˜¯ä¸€ä¸ªé«˜ç½®ä¿¡åº¦çš„å•ä¸€æ ‡å¿—æ€§åŸºå› ã€‚\n",
        "breast_cancer_marker_map = {\n",
        "    \"Tumor (IDC)\": \"EPCAM\",      # EPCAM æ˜¯ç»å…¸çš„ç™Œç»†èƒæ ‡å¿—ç‰©\n",
        "    \"Normal & Stroma\": \"COL1A1\"  # COL1A1 æ˜¯æˆçº¤ç»´ç»†èƒ/åŸºè´¨çš„å¼ºæ ‡å¿—ç‰©\n",
        "}\n",
        "\n",
        "# --- 3. è¿è¡Œå®éªŒ ---\n",
        "if not DRYRUN:\n",
        "    # åªæœ‰åœ¨éé¢„æ¼”æ¨¡å¼ä¸‹æ‰è¿è¡Œ\n",
        "    sample_with_results = run_and_visualize_experiment(\n",
        "        sample_id=\"TENX99\",\n",
        "        text_queries=breast_cancer_binary_queries,\n",
        "        experiment_name=\"Breast_Cancer_Binary\",\n",
        "        marker_map=breast_cancer_marker_map  # <-- ä¼ å…¥æ–°çš„å‚æ•°\n",
        "    )\n",
        "else:\n",
        "    logging.warning(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡å®éªŒæ‰§è¡Œã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652e1fcc",
      "metadata": {},
      "source": [
        "# Chatgptæ›´æ–°ç‰ˆæœ¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "657842d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # å¯å¤ç”¨çš„ç©ºé—´CLIPæ¨¡å‹è¯„ä¼°å·¥ä½œæµï¼ˆç®€æ´ç‰ˆï¼Œå«æ”¹è¿›ä¼ªæ ‡ç­¾ï¼‰\n",
        "# - ä¼ªæ ‡ç­¾ï¼šscanpy.tl.score_genes å¤šåŸºå› æ‰“åˆ† + åˆ†ä½é˜ˆå€¼ + ç½®ä¿¡è¾¹é™… + Unknown\n",
        "# - é¿å…ä¸è®­ç»ƒæ—¶â€œspot Top-50 åŸºå› å¥å­â€é—­ç¯ï¼Œä½¿ç”¨å›ºå®šçš„ç»å…¸æ ‡è®°é›†åˆï¼ˆPanglaoDB/CellMarker/HPAï¼‰\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 1. å¯¼å…¥ä¸ç¯å¢ƒé…ç½®\n",
        "\n",
        "# %%\n",
        "# --- æ ¸å¿ƒåŸåˆ™ ---\n",
        "DRYRUN = False\n",
        "\n",
        "# --- æ ‡å‡†åº“ ---\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple, List\n",
        "\n",
        "# --- ç¬¬ä¸‰æ–¹åº“ ---\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "from PIL import Image, ImageFile\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# --- é¡¹ç›®è·¯å¾„é…ç½® ---\n",
        "PROJECT_ROOT = Path(\"/home1/jijh/diffusion_project/git_repo/yuanspace\")\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "    print(f\"å·²å°† '{PROJECT_ROOT}' æ·»åŠ åˆ° sys.path\")\n",
        "\n",
        "# --- æœ¬åœ°é¡¹ç›®åº“ ---\n",
        "try:\n",
        "    import open_clip\n",
        "    from src.spaglam_preproc.utils.hest_loading import HESTDataset, HESTSample\n",
        "except ImportError as e:\n",
        "    print(f\"å¯¼å…¥é”™è¯¯: {e}\\nè¯·ç¡®ä¿æ‚¨çš„é¡¹ç›®ç»“æ„å’Œè·¯å¾„é…ç½®æ­£ç¡®ã€‚\")\n",
        "    raise\n",
        "\n",
        "# --- é…ç½®æ—¥å¿— ---\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', stream=sys.stdout)\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2. è·¯å¾„ä¸æ¨¡å‹é…ç½®\n",
        "\n",
        "# %%\n",
        "# --- æ•°æ®è·¯å¾„ ---\n",
        "HEST_DATA_DIR = Path(\"/cwStorage/nodecw_group/jijh/hest_1k\")\n",
        "\n",
        "# --- è¾“å‡ºç›®å½• ---\n",
        "OUTPUT_DIR = Path(\"/cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline\")\n",
        "\n",
        "# --- æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ ---\n",
        "BASELINE_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt\")\n",
        "SPATIAL_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/spatial_clip_base_model/multi_positice_loss50.pt\")\n",
        "\n",
        "# --- æ¨¡å‹æ¶æ„ ---\n",
        "MODEL_NAME = \"ViT-B-32\"\n",
        "\n",
        "# --- æ¨ç†é…ç½® ---\n",
        "BATCH_SIZE = 512\n",
        "NUM_WORKERS = 16\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- å¾…æµ‹è¯•æ¨¡å‹æ¸…å• ---\n",
        "MODELS_TO_TEST = {\n",
        "    \"OmiCLIP (Baseline)\": {\"path\": BASELINE_MODEL_CKPT, \"model_name\": MODEL_NAME},\n",
        "    \"Spatial CLIP (Ours)\": {\"path\": SPATIAL_MODEL_CKPT, \"model_name\": MODEL_NAME},\n",
        "}\n",
        "\n",
        "# --- æ£€æŸ¥ä¸å‡†å¤‡ ---\n",
        "if not DRYRUN:\n",
        "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "    logging.info(f\"è¾“å‡ºå°†ä¿å­˜åˆ°: {OUTPUT_DIR}\")\n",
        "\n",
        "for name, config in MODELS_TO_TEST.items():\n",
        "    assert config['path'].exists(), f\"æ¨¡å‹ '{name}' çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {config['path']}\"\n",
        "assert HEST_DATA_DIR.exists(), f\"HEST æ•°æ®ç›®å½•ä¸å­˜åœ¨: {HEST_DATA_DIR}\"\n",
        "\n",
        "logging.info(f\"é…ç½®å®Œæˆã€‚ä½¿ç”¨è®¾å¤‡: {DEVICE}\")\n",
        "logging.info(f\"é¢„æ¼”æ¨¡å¼ (DRYRUN): {DRYRUN}\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. æ•°æ®åŠ è½½ä¸WSIå°è£…\n",
        "\n",
        "# %%\n",
        "def load_clip_model(checkpoint_path: Path, model_name: str, device: str) -> torch.nn.Module:\n",
        "    \"\"\"ä»ç»™å®šçš„æ£€æŸ¥ç‚¹è·¯å¾„åŠ è½½ CLIP æ¨¡å‹ã€‚\"\"\"\n",
        "    logging.info(f\"æ­£åœ¨åŠ è½½æ¨¡å‹ '{model_name}' ä»: {checkpoint_path}\")\n",
        "    model, _, _ = open_clip.create_model_and_transforms(model_name, pretrained=None)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
        "    if all(key.startswith('module.') for key in state_dict.keys()):\n",
        "        state_dict = {k[len('module.'):]: v for k, v in state_dict.items()}\n",
        "    try:\n",
        "        model.load_state_dict(state_dict)\n",
        "    except RuntimeError as e:\n",
        "        logging.warning(f\"åŠ è½½ state_dict ä¸¥æ ¼æ¨¡å¼å¤±è´¥: {e}ã€‚å°è¯•éä¸¥æ ¼æ¨¡å¼...\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    logging.info(f\"æ¨¡å‹ '{model_name}' åŠ è½½æˆåŠŸã€‚\")\n",
        "    return model\n",
        "\n",
        "def get_hest_sample(sample_id: str) -> HESTSample:\n",
        "    \"\"\"åŠ è½½å¹¶å‡†å¤‡ä¸€ä¸ª HEST æ ·æœ¬ç”¨äºåˆ†æã€‚\"\"\"\n",
        "    logging.info(f\"åŠ è½½ HEST æ ·æœ¬: {sample_id}...\")\n",
        "    hest_dataset = HESTDataset(data_dir=HEST_DATA_DIR)\n",
        "    sample = hest_dataset.get_samples(sample_ids=[sample_id])[0]\n",
        "    sample.load_st_data(lazy=False)\n",
        "    sample.load_wsi()\n",
        "\n",
        "    # ç»Ÿä¸€ spatial é”®\n",
        "    spatial_data = sample.adata.uns['spatial']['ST']\n",
        "    library_id = sample.sample_id\n",
        "    sample.adata.uns['spatial'] = {library_id: spatial_data}\n",
        "    logging.info(f\"æ ·æœ¬ '{sample.sample_id}' åŠ è½½å¹¶å‡†å¤‡å®Œæ¯•ã€‚\")\n",
        "    return sample\n",
        "\n",
        "class WSISpotDataset(Dataset):\n",
        "    \"\"\"ä»WSIä¸­æŒ‰éœ€åŠ è½½spotå¯¹åº”å›¾å—ã€‚\"\"\"\n",
        "    def __init__(self, wsi, coords, transform):\n",
        "        self.wsi = wsi\n",
        "        self.coords = coords\n",
        "        self.transform = transform\n",
        "        self.patch_size = (224, 224)\n",
        "        self.patch_radius = self.patch_size[0] // 2\n",
        "    def __len__(self): return len(self.coords)\n",
        "    def __getitem__(self, idx):\n",
        "        c = self.coords[idx]\n",
        "        top_left = (int(c[0] - self.patch_radius), int(c[1] - self.patch_radius))\n",
        "        tile = self.wsi.read_region(top_left, 0, self.patch_size).convert(\"RGB\")\n",
        "        if self.transform: tile = self.transform(tile)\n",
        "        return tile\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. æ”¹è¿›ç‰ˆä¼ªæ ‡ç­¾ï¼šScanpy `score_genes` + åˆ†ä½é˜ˆå€¼ + ç½®ä¿¡è¾¹é™… + Unknown\n",
        "\n",
        "# %%\n",
        "def ensure_log1p_layer(adata: sc.AnnData, layer_name: str = \"log1p\") -> None:\n",
        "    \"\"\"ç¡®ä¿å­˜åœ¨ log1p å±‚ï¼›è‹¥æ— åˆ™ä»¥ Scanpy æ¨èæµç¨‹è¿›è¡Œ normalize_total + log1pã€‚\"\"\"\n",
        "    if layer_name in adata.layers:\n",
        "        return\n",
        "    sc.pp.normalize_total(adata, target_sum=1e4)  # count-depth scaling\n",
        "    sc.pp.log1p(adata)\n",
        "    adata.layers[layer_name] = adata.X.copy()\n",
        "\n",
        "def create_silver_labels_scanpy(\n",
        "    adata: sc.AnnData,\n",
        "    marker_panels: Dict[str, List[str]],\n",
        "    layer: str = \"log1p\",\n",
        "    ctrl_size: int = 50,     # score_genes å¯¹ç…§åŸºå› æ•°ï¼›ä¼šè‡ªåŠ¨æŒ‰è¡¨è¾¾é‡åˆ†ç®±åŒ¹é…\n",
        "    q: float = 0.90,         # æ¯ç±»åˆ†ä½é˜ˆå€¼ï¼ˆé«˜ç½®ä¿¡ï¼‰\n",
        "    margin_min: float = 0.30 # ç½®ä¿¡è¾¹é™…ï¼ˆwinner - second bestï¼‰\n",
        ") -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    ç”¨ Scanpy çš„ score_genes ä¸ºæ¯ä¸ªç±»åˆ«æ‰“åˆ†ï¼Œç„¶åæŒ‰åˆ†ä½é˜ˆå€¼ä¸è¾¹é™…ç”Ÿæˆâ€œé“¶æ ‡å‡†â€ä¼ªæ ‡ç­¾ã€‚\n",
        "    è¿”å›: (labels, score_df)\n",
        "    \"\"\"\n",
        "    # ä»…ä¿ç•™å­˜åœ¨çš„åŸºå› \n",
        "    panels = {lbl: [g for g in genes if g in adata.var_names]\n",
        "              for lbl, genes in marker_panels.items()}\n",
        "    score_cols = []\n",
        "\n",
        "    # å¯¹æ¯ä¸ªæ ‡ç­¾æ‰“åˆ†ï¼ˆå‚è€ƒé›†åˆç”± score_genes è‡ªåŠ¨ç”Ÿæˆå¹¶è¡¨è¾¾é‡åŒ¹é…ï¼‰\n",
        "    for lbl, genes in panels.items():\n",
        "        if len(genes) == 0:\n",
        "            logging.warning(f\"[{lbl}] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\")\n",
        "            continue\n",
        "        col = f\"score__{lbl}\"\n",
        "        sc.tl.score_genes(\n",
        "            adata, gene_list=genes, score_name=col,\n",
        "            ctrl_size=ctrl_size, use_raw=False, layer=layer\n",
        "        )\n",
        "        score_cols.append(col)\n",
        "\n",
        "    if not score_cols:\n",
        "        raise ValueError(\"marker_panels ä¸­çš„åŸºå› å‡æœªåœ¨ adata.var_names ä¸­æ‰¾åˆ°ã€‚\")\n",
        "\n",
        "    S = adata.obs[score_cols].copy()\n",
        "    S.columns = [c.replace(\"score__\", \"\") for c in S.columns]\n",
        "\n",
        "    # èµ¢å®¶æ ‡ç­¾ä¸è¾¹é™…\n",
        "    winner = S.idxmax(axis=1)\n",
        "    top1 = S.max(axis=1)\n",
        "    top2 = S.apply(lambda r: r.nlargest(2).iloc[-1] if (r.notna().sum() >= 2) else np.nan, axis=1)\n",
        "    margin = top1 - top2\n",
        "\n",
        "    # æŒ‰ç±»åˆ†ä½é˜ˆå€¼\n",
        "    per_label_thresh = {lbl: S[lbl].quantile(q) for lbl in S.columns}\n",
        "\n",
        "    # æ¡ä»¶ï¼šåˆ†æ•° â‰¥ æœ¬ç±»é˜ˆå€¼ ä¸” margin â‰¥ è®¾å®šè¾¹é™…\n",
        "    keep = pd.Series(False, index=S.index)\n",
        "    for idx, lbl in winner.items():\n",
        "        thr = per_label_thresh.get(lbl, np.inf)\n",
        "        keep.at[idx] = (S.at[idx, lbl] >= thr) and (margin.at[idx] >= margin_min)\n",
        "\n",
        "    labels = winner.copy()\n",
        "    labels.loc[~keep] = \"Unknown\"\n",
        "    labels = labels.astype(\"category\")\n",
        "\n",
        "    coverage = (labels != \"Unknown\").mean()\n",
        "    logging.info(f\"[Pseudo-Labels] è¦†ç›–ç‡: {coverage:.2%}  (q={q}, margin={margin_min})\")\n",
        "    return labels, S\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5. ä¸»å·¥ä½œæµï¼ˆæ¨ç† + å¯è§†åŒ– + åŸºäºé“¶æ ‡å‡†çš„å®šé‡è¯„ä¼°ï¼‰\n",
        "\n",
        "# %%\n",
        "def run_and_visualize_experiment(\n",
        "    sample_id: str,\n",
        "    text_queries: Dict[str, str],\n",
        "    experiment_name: str,\n",
        "    marker_panels: Dict[str, List[str]],    # æ–°ï¼šæ¯ç±»å›ºå®šâ€œç»å…¸æ ‡è®°â€åˆ—è¡¨\n",
        "    q: float = 0.90, margin_min: float = 0.30,\n",
        "    models_to_test: Dict[str, Dict[str, Any]] = MODELS_TO_TEST,\n",
        "    output_dir: Path = OUTPUT_DIR,\n",
        "    device: str = DEVICE,\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "    num_workers: int = NUM_WORKERS,\n",
        "    palette_name: str = \"Set1\"\n",
        ") -> HESTSample:\n",
        "    \"\"\"\n",
        "    å¯¹æŒ‡å®šæ ·æœ¬å’ŒæŸ¥è¯¢ï¼Œæ‰§è¡Œå¤šæ¨¡å‹é›¶æ ·æœ¬åˆ†ç±»ï¼›å¹¶ä»¥æ”¹è¿›ä¼ªæ ‡ç­¾è¿›è¡Œå®šé‡è¯„ä¼°ã€‚\n",
        "    \"\"\"\n",
        "    logging.info(f\"--- ğŸš€ å¼€å§‹å®éªŒ: '{experiment_name}' on sample '{sample_id}' ---\")\n",
        "    # 1) åŠ è½½æ•°æ®å¹¶ä¿è¯é¢„å¤„ç†\n",
        "    sample = get_hest_sample(sample_id)\n",
        "    ensure_log1p_layer(sample.adata, layer_name=\"log1p\")\n",
        "\n",
        "    tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "    query_labels = list(text_queries.keys())\n",
        "\n",
        "    # 2) è¿è¡Œæ‰€æœ‰æ¨¡å‹æ¨ç†\n",
        "    for model_name, config in models_to_test.items():\n",
        "        logging.info(f\"æ­£åœ¨å¤„ç†æ¨¡å‹: {model_name}...\")\n",
        "        model = load_clip_model(config['path'], config['model_name'], device)\n",
        "        _, _, image_preprocessor = open_clip.create_model_and_transforms(config['model_name'])\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            WSISpotDataset(wsi=sample.wsi, coords=sample.adata.obsm['spatial'], transform=image_preprocessor),\n",
        "            batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=False\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            tokenized = tokenizer(list(text_queries.values())).to(device)\n",
        "            text_features = model.encode_text(tokenized, normalize=True)\n",
        "\n",
        "            all_spot_embeddings = []\n",
        "            for image_batch in tqdm(dataloader, desc=f\"æ¨ç†: {model_name}\", leave=False):\n",
        "                image_features = model.encode_image(image_batch.to(device), normalize=True)\n",
        "                all_spot_embeddings.append(image_features.cpu())\n",
        "\n",
        "        spot_emb = torch.cat(all_spot_embeddings)\n",
        "        similarity = spot_emb.to(device) @ text_features.T\n",
        "        conf, pred_idx = torch.max(torch.softmax(similarity, dim=1), dim=1)\n",
        "\n",
        "        # å†™å…¥ AnnData\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        conf_col = f\"conf_{experiment_name}_{model_name_safe}\"\n",
        "        sample.adata.obs[anno_col] = pd.Categorical([query_labels[i] for i in pred_idx.cpu().numpy()],\n",
        "                                                    categories=query_labels)\n",
        "        sample.adata.obs[conf_col] = conf.cpu().numpy()\n",
        "        logging.info(f\"ç»“æœå·²æ·»åŠ åˆ° AnnData: '{anno_col}'\")\n",
        "\n",
        "        # é‡Šæ”¾\n",
        "        del model, text_features, spot_emb\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # 3) å¯è§†åŒ–ï¼ˆä¸åŸé€»è¾‘ä¸€è‡´ï¼Œç»Ÿä¸€è°ƒè‰²æ¿ï¼‰\n",
        "    logging.info(\"--- ğŸ“Š é˜¶æ®µä¸€: å®šæ€§è¯„ä¼° (å¯è§†åŒ–) ---\")\n",
        "    categories = list(text_queries.keys())\n",
        "    palette = dict(zip(categories, sns.color_palette(palette_name, len(categories))))\n",
        "    fig, axes = plt.subplots(1, len(models_to_test), figsize=(7 * len(models_to_test), 12), squeeze=False)\n",
        "    fig.suptitle(f\"'{experiment_name}' on Sample '{sample_id}'\", fontsize=20, y=0.9)\n",
        "    plot_params = {\"show\": False, \"legend_loc\": None, \"frameon\": False,\n",
        "                   \"library_id\": sample.sample_id, \"img_key\": 'downscaled_fullres', \"size\": 1.2, \"s\": 1.5}\n",
        "    for i, (model_name, _) in enumerate(models_to_test.items()):\n",
        "        ax = axes[0, i]\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        sc.pl.spatial(sample.adata, color=anno_col, title=f\"{model_name}\", ax=ax, palette=palette, **plot_params)\n",
        "    handles = [mpatches.Patch(color=palette[cat], label=cat) for cat in categories]\n",
        "    fig.legend(handles=handles, title=\"Categories\", loc='center right', bbox_to_anchor=(1.05, 0.5))\n",
        "    plt.tight_layout(rect=[0, 0, 0.90, 0.96])\n",
        "    if not DRYRUN:\n",
        "        save_path = output_dir / f\"vis_{experiment_name}_comparison_{sample_id}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight'); logging.info(f\"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    # 4) ä¼ªæ ‡ç­¾ï¼ˆé“¶æ ‡å‡†ï¼‰ä¸å®šé‡è¯„ä¼°\n",
        "    logging.info(\"--- ğŸ“ˆ é˜¶æ®µäºŒ: å®šé‡è¯„ä¼° (åŸºäºæ”¹è¿›ä¼ªæ ‡ç­¾) ---\")\n",
        "    pseudo_labels, score_df = create_silver_labels_scanpy(\n",
        "        sample.adata, marker_panels=marker_panels, layer=\"log1p\", q=q, margin_min=margin_min\n",
        "    )\n",
        "    kept_idx = pseudo_labels.index[pseudo_labels.values != \"Unknown\"]\n",
        "    if len(kept_idx) == 0:\n",
        "        logging.warning(\"ä¼ªæ ‡ç­¾è¦†ç›–ç‡ä¸º 0ï¼Œè·³è¿‡å®šé‡è¯„ä¼°ï¼ˆè¯·é€‚å½“é™ä½åˆ†ä½é˜ˆå€¼æˆ–è¾¹é™…é˜ˆå€¼ï¼‰ã€‚\")\n",
        "        return sample\n",
        "\n",
        "    classification_results = []\n",
        "    fig_cm, axes_cm = plt.subplots(1, len(models_to_test), figsize=(8 * len(models_to_test), 7), squeeze=False)\n",
        "    fig_cm.suptitle(f\"Confusion Matrices for '{experiment_name}' on Sample '{sample_id}' (silver labels)\", fontsize=18, y=1.02)\n",
        "    axes_cm = axes_cm.flatten()\n",
        "\n",
        "    eval_labels = sorted(list(set(pseudo_labels[kept_idx].unique())))  # ä¸å« Unknown\n",
        "\n",
        "    for i, (model_name, _) in enumerate(models_to_test.items()):\n",
        "        model_name_safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{model_name_safe}\"\n",
        "        preds = sample.adata.obs[anno_col].loc[kept_idx]\n",
        "\n",
        "        # ç»Ÿä¸€æ ‡ç­¾åŸŸ\n",
        "        y_true = pd.Categorical(pseudo_labels.loc[kept_idx], categories=eval_labels)\n",
        "        y_pred = pd.Categorical(preds, categories=eval_labels)\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        f1w = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "        classification_results.append({\"model\": model_name, \"coverage\": len(kept_idx)/sample.adata.n_obs, \"accuracy\": acc, \"f1_weighted\": f1w})\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=eval_labels)\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=eval_labels)\n",
        "        disp.plot(ax=axes_cm[i], xticks_rotation='vertical', cmap='Blues')\n",
        "        axes_cm[i].set_title(f\"{model_name}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if not DRYRUN:\n",
        "        cm_path = output_dir / f\"conf_matrix_{experiment_name}_silver_{sample_id}.png\"\n",
        "        plt.savefig(cm_path, dpi=300, bbox_inches='tight'); logging.info(f\"æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜åˆ°: {cm_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    classification_df = pd.DataFrame(classification_results).set_index('model')\n",
        "    print(\"\\n--- Zero-Shot Classification vs. Silver Labels ---\")\n",
        "    display(classification_df)\n",
        "    if not DRYRUN:\n",
        "        df_save_path = output_dir / f\"metrics_{experiment_name}_{sample_id}.csv\"\n",
        "        classification_df.to_csv(df_save_path); logging.info(f\"åˆ†ç±»æŒ‡æ ‡å·²ä¿å­˜åˆ°: {df_save_path}\")\n",
        "\n",
        "    logging.info(f\"--- âœ… å®éªŒ '{experiment_name}' å®Œæˆ ---\")\n",
        "    return sample\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. è¿è¡ŒäºŒåˆ†ç±»ä¹³è…ºç™Œå®éªŒï¼ˆç¤ºä¾‹ï¼‰\n",
        "\n",
        "# %%\n",
        "# --- æ–‡æœ¬æŸ¥è¯¢ï¼ˆä¾› CLIP æ–‡æœ¬ç¼–ç ä½¿ç”¨ï¼›å¯ç»§ç»­æ²¿ç”¨ä½ çš„åŸå§‹å®šä¹‰ï¼‰ ---\n",
        "breast_cancer_binary_queries = {\n",
        "    \"Tumor (IDC)\": (\n",
        "        \"KRT8 KRT18 KRT19 EPCAM MUC1 CLDN3 CLDN4 CLDN7 CDH1 KRT7 \"\n",
        "        \"ERBB2 GRB7 ERBB3 ESR1 PGR FOXA1 GATA3 AGR2 TFF1 TFF3 \"\n",
        "        \"TRPS1 SCGB2A2 BCL2 AR MKI67 TOP2A MYC CCND1 EGFR BIRC5 \"\n",
        "        \"UBE2C CCNA2 CCNB1 CDC20 PLK1 AURKA AURKB CENPF NUSAP1 KIF11 \"\n",
        "        \"KIF2C PTTG1 PRC1 ANLN MCM2 MCM4 MCM6 MCM7 TK1 PCNA\"\n",
        "    ),\n",
        "    \"Normal & Stroma\": (\n",
        "        \"COL1A1 COL1A2 COL3A1 COL5A1 COL5A2 COL6A1 COL6A2 COL6A3 FN1 VIM \"\n",
        "        \"LUM DCN BGN THY1 FAP PDGFRB RGS5 CSPG4 ACTA2 TAGLN \"\n",
        "        \"MYH11 CNN1 DES VWF PECAM1 CLDN5 KDR FLT1 ENG CD34 \"\n",
        "        \"MCAM PDPN PROX1 LYVE1 PTPRC LST1 LYZ CSF1R CD68 C1QB \"\n",
        "        \"ITGAM ITGAX HLA-DRA HLA-DPB1 CD3D CD4 CD8A TRAC MS4A1 CD79A\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "# --- ç»å…¸æ ‡è®°é¢æ¿ï¼ˆå›ºå®šã€å°è€Œç²¾ï¼‰ï¼Œä¸ä¸Šé¢æ–‡æœ¬æŸ¥è¯¢ç›¸äº’ç‹¬ç«‹ä»¥é¿å…ä¿¡æ¯æ³„æ¼ ---\n",
        "marker_panels = {\n",
        "    \"Tumor (IDC)\": [\"EPCAM\",\"KRT8\",\"KRT18\",\"KRT19\",\"KRT7\",\"MUC1\",\"CLDN3\",\"CLDN4\",\"CLDN7\",\"ERBB2\"],\n",
        "    \"Normal & Stroma\": [\"COL1A1\",\"COL1A2\",\"COL3A1\",\"DCN\",\"LUM\",\"BGN\",\"THY1\",\"PDGFRB\",\"TAGLN\",\"ACTA2\",\"VWF\",\"PECAM1\"]\n",
        "}\n",
        "\n",
        "# --- è¿è¡Œ ---\n",
        "if not DRYRUN:\n",
        "    sample_with_results = run_and_visualize_experiment(\n",
        "        sample_id=\"TENX99\",\n",
        "        text_queries=breast_cancer_binary_queries,\n",
        "        experiment_name=\"Breast_Cancer_Binary\",\n",
        "        marker_panels=marker_panels,\n",
        "        q=0.90,               # å¯æŒ‰è¦†ç›–ç‡éœ€è¦è°ƒæ•´ä¸º 0.85\n",
        "        margin_min=0.30       # å¯æŒ‰éœ€è¦è°ƒæ•´ä¸º 0.20~0.50\n",
        "    )\n",
        "else:\n",
        "    logging.warning(\"å¤„äºé¢„æ¼”æ¨¡å¼ï¼Œè·³è¿‡å®éªŒæ‰§è¡Œã€‚\")\n",
        "\n",
        "# ï¼ˆå¯é€‰ï¼‰å•æ¨¡å‹ç©ºé—´å›¾å¿«é€ŸæŸ¥çœ‹\n",
        "# sc.pl.spatial(\n",
        "#     sample_with_results.adata,\n",
        "#     color=f\"anno_Breast_Cancer_Binary_OmiCLIP_Baseline\",\n",
        "#     title=f\"OmiCLIP (Baseline) - Breast Cancer Binary Annotation\",\n",
        "#     s=1.5, show=True, legend_loc=None, frameon=False,\n",
        "#     library_id=sample_with_results.sample_id, img_key='downscaled_fullres',\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "191f9221",
      "metadata": {},
      "source": [
        "# Newer Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ea7612e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:53:23,904 - INFO - [Cohort] äººç±»ä¹³è…ºç™Œæ ·æœ¬æ•°é‡: 125 -> ['TENX99', 'TENX98', 'TENX97', 'TENX96', 'TENX95', 'TENX94', 'TENX68', 'TENX53', 'TENX39', 'TENX24', 'TENX23', 'TENX14', 'TENX13', 'SPA154', 'SPA153', 'SPA152', 'SPA151', 'SPA150', 'SPA149', 'SPA148', 'SPA147', 'SPA146', 'SPA145', 'SPA144', 'SPA143', 'SPA142', 'SPA141', 'SPA140', 'SPA139', 'SPA138', 'SPA137', 'SPA136', 'SPA135', 'SPA134', 'SPA133', 'SPA132', 'SPA131', 'SPA130', 'SPA129', 'SPA128', 'SPA127', 'SPA126', 'SPA125', 'SPA124', 'SPA123', 'SPA122', 'SPA121', 'SPA120', 'SPA119', 'SPA118', 'SPA117', 'SPA116', 'SPA115', 'SPA114', 'SPA113', 'SPA112', 'SPA111', 'SPA110', 'SPA109', 'SPA108', 'SPA107', 'SPA106', 'SPA105', 'SPA104', 'SPA103', 'SPA102', 'SPA101', 'SPA100', 'SPA99', 'SPA98', 'SPA97', 'SPA96', 'SPA95', 'SPA94', 'SPA93', 'SPA92', 'SPA91', 'SPA90', 'SPA89', 'SPA88', 'SPA87', 'SPA86', 'SPA85', 'SPA84', 'SPA83', 'SPA82', 'SPA81', 'SPA80', 'SPA79', 'SPA78', 'SPA77', 'SPA76', 'SPA75', 'SPA74', 'SPA73', 'SPA72', 'SPA71', 'SPA70', 'SPA69', 'SPA68', 'SPA67', 'SPA66', 'SPA65', 'SPA64', 'SPA63', 'SPA62', 'SPA61', 'SPA60', 'SPA59', 'SPA58', 'SPA57', 'SPA56', 'SPA55', 'SPA54', 'SPA53', 'SPA52', 'SPA51', 'SPA3', 'SPA2', 'SPA1', 'SPA0', 'NCBI785', 'NCBI784', 'NCBI783', 'NCBI776']\n",
            "2025-09-13 13:53:24,152 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:53:24,153 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 13:53:24,154 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 13:53:24,239 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:53:24,240 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:53:24,240 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:53:24,241 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:53:25,466 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:53:25,467 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:53:25,467 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:53:27,259 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:53:27,260 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:53:27,260 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:53:27,261 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:53:28,370 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:53:28,371 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:53:28,372 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bc67728804443c18ccb9caca7fd33ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX99 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:53:44,197 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:53:44,200 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:53:44,201 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:53:44,202 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:53:45,486 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:53:45,488 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:53:45,488 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:53:47,723 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:53:47,725 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:53:47,726 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:53:47,727 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:53:48,928 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:53:48,929 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:53:48,930 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c8852e2142e432e9abdc4034572b168",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX99 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:54:12,269 - INFO - [Silver labels] è¦†ç›–ç‡: 18.38% (q=0.9, margin=0.3)\n",
            "2025-09-13 13:54:13,570 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:54:13,571 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 13:54:13,571 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 13:54:13,658 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:54:13,659 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:54:13,660 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:54:13,660 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:54:14,941 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:54:14,943 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:54:14,944 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:54:18,541 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:54:18,542 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:54:18,543 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:54:18,544 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:54:19,755 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:54:19,758 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:54:19,759 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14de8890c5cc4f0388b62c8461d57f7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX98 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:55:55,054 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:55:55,055 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:55:55,056 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:55:55,056 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:55:56,510 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:55:56,512 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:55:56,512 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:56:01,086 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:56:01,089 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:56:01,090 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:56:01,091 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:56:02,239 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:56:02,240 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:56:02,241 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0130c351d5a546b793d63a626278bed1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX98 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:56:57,052 - INFO - [Silver labels] è¦†ç›–ç‡: 18.80% (q=0.9, margin=0.3)\n",
            "2025-09-13 13:56:57,751 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:56:57,752 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 13:56:57,753 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 13:56:57,840 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:56:57,841 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:56:57,842 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:56:57,843 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:56:59,121 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:56:59,122 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:56:59,123 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:57:02,397 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:57:02,400 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:57:02,400 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:57:02,401 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:57:03,511 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:57:03,512 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:57:03,513 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b56eb99c9df0430b94309855f48612b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX97 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:57:41,116 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:57:41,117 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:57:41,117 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:57:41,117 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:57:42,407 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:57:42,409 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:57:42,410 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:57:46,338 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:57:46,341 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:57:46,342 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:57:46,343 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:57:47,504 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:57:47,505 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:57:47,506 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f886756a53140f2af07b736012578f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX97 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:58:03,228 - INFO - [Silver labels] è¦†ç›–ç‡: 19.06% (q=0.9, margin=0.3)\n",
            "2025-09-13 13:58:03,936 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:03,937 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 13:58:03,938 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 13:58:04,028 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:04,029 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:58:04,029 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:58:04,029 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:58:05,369 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:58:05,372 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:58:05,372 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:58:07,205 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:07,206 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:58:07,207 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:58:07,208 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:58:08,274 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:58:08,276 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:58:08,276 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "811e0d30e171409496824df8186cdaed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX96 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:58:29,829 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:29,830 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:58:29,831 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:58:29,831 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:58:31,082 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:58:31,083 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:58:31,084 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:58:32,925 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:32,926 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:58:32,927 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:58:32,927 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:58:33,987 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:58:33,989 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:58:33,989 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "947cc03f36084022b63304204cf291ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX96 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:58:45,375 - INFO - [Silver labels] è¦†ç›–ç‡: 19.48% (q=0.9, margin=0.3)\n",
            "2025-09-13 13:58:45,980 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:45,981 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 13:58:45,982 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 13:58:46,068 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:46,069 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:58:46,069 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:58:46,070 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:58:47,297 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:58:47,298 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:58:47,299 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:58:48,862 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:58:48,864 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:58:48,864 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:58:48,865 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:58:49,921 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:58:49,922 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:58:49,923 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aa755faed2244e6be4f57941cd418b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX95 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:59:21,018 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:59:21,020 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:59:21,021 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:59:21,022 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:59:22,305 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:59:22,307 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:59:22,307 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:59:26,333 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:59:26,335 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:59:26,336 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:59:26,337 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:59:27,400 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:59:27,402 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:59:27,403 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed38b1a39efc41afb297c8aa732004b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX95 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:59:41,544 - INFO - [Silver labels] è¦†ç›–ç‡: 18.84% (q=0.9, margin=0.3)\n",
            "2025-09-13 13:59:42,217 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:59:42,218 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 13:59:42,219 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 13:59:42,310 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:59:42,310 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:59:42,311 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:59:42,312 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 13:59:43,574 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:59:43,576 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:59:43,576 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 13:59:45,216 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 13:59:45,219 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 13:59:45,219 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 13:59:45,220 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 13:59:46,286 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 13:59:46,287 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 13:59:46,288 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38682180540b47a9847ae21c664df5a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX94 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:00:12,229 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:00:12,230 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:00:12,231 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:00:12,232 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:00:13,487 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:00:13,488 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:00:13,489 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:00:17,466 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:00:17,468 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:00:17,469 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:00:17,469 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:00:18,573 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:00:18,576 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:00:18,577 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a28695f1f2484316b8110fdeb4c95f53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX94 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:00:42,088 - INFO - [Silver labels] è¦†ç›–ç‡: 18.74% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:00:57,233 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:00:57,236 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:00:57,237 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:00:57,327 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:00:57,328 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:00:57,329 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:00:57,330 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:00:58,680 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:00:58,681 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:00:58,682 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:01:03,660 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:01:03,662 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:01:03,663 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:01:03,664 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:01:04,961 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:01:04,962 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:01:04,963 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d1af35d46c24593a5642a6fbe9a3fe1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX68 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:01:21,296 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:01:21,298 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:01:21,299 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:01:21,299 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:01:22,614 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:01:22,616 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:01:22,617 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:01:27,950 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:01:27,953 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:01:27,954 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:01:27,955 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:01:29,162 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:01:29,164 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:01:29,164 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b8479bc5e9b42c38451b4776d3817db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX68 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:01:38,851 - INFO - [Silver labels] è¦†ç›–ç‡: 17.32% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:01:40,848 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:01:40,851 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:01:40,851 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:01:40,950 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:01:40,951 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:01:40,951 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:01:40,952 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:01:42,290 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:01:42,292 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:01:42,293 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:01:47,471 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:01:47,475 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:01:47,476 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:01:47,477 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:01:48,717 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:01:48,718 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:01:48,719 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71f5637e12fb4613ac928a77ebd2d375",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX53 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:02:17,931 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:02:17,933 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:02:17,933 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:02:17,934 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:02:19,286 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:02:19,287 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:02:19,288 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:02:24,377 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:02:24,381 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:02:24,382 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:02:24,383 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:02:25,529 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:02:25,530 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:02:25,531 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5b7580b336743d287e8fe12934f0711",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX53 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:02:43,572 - INFO - [Silver labels] è¦†ç›–ç‡: 13.27% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:02:45,001 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:02:45,003 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:02:45,004 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:02:45,092 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:02:45,093 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:02:45,094 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:02:45,094 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:02:46,578 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:02:46,580 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:02:46,581 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:02:51,310 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:02:51,311 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:02:51,312 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:02:51,313 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:02:52,444 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:02:52,445 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:02:52,446 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08883c454ef1402a8d38665520a2b36c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX39 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:03:15,767 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:03:15,770 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:03:15,771 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:03:15,772 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:03:17,152 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:03:17,156 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:03:17,156 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:03:21,917 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:03:21,918 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:03:21,919 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:03:21,919 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:03:23,089 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:03:23,093 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:03:23,094 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64237a7afeab4ed1af2e0cf6f2363e21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX39 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:03:31,965 - INFO - [Silver labels] è¦†ç›–ç‡: 20.02% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:03:33,214 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:03:33,217 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:03:33,218 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:03:33,301 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:03:33,302 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:03:33,302 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:03:33,303 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:03:34,615 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:03:34,617 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:03:34,618 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:03:37,690 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:03:37,692 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:03:37,693 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:03:37,693 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:03:38,837 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:03:38,840 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:03:38,841 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "646dffd00c7c49a89e63c095613ac32a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX24 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:04:00,078 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:00,081 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:04:00,082 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:04:00,082 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:04:01,424 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:04:01,425 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:04:01,426 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:04:04,440 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:04,441 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:04:04,442 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:04:04,442 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:04:05,577 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:04:05,580 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:04:05,581 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8859a36fa29e4041bf3987e777d80879",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX24 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:04:16,502 - INFO - [Silver labels] è¦†ç›–ç‡: 16.60% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:04:17,120 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:17,121 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:04:17,121 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:04:17,215 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:17,216 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:04:17,217 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:04:17,218 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:04:18,576 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:04:18,579 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:04:18,580 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:04:20,651 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:20,653 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:04:20,654 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:04:20,655 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:04:21,807 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:04:21,808 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:04:21,808 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e820498256b4b6092d228d3dd981a7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX23 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:04:55,061 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:55,063 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:04:55,064 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:04:55,065 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:04:56,384 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:04:56,385 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:04:56,386 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:04:58,420 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:04:58,424 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:04:58,425 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:04:58,426 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:04:59,533 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:04:59,534 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:04:59,535 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3794c04d948b4ae7a67c483a8524095c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX23 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:05:09,121 - INFO - [Silver labels] è¦†ç›–ç‡: 14.71% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:05:10,394 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:10,397 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:05:10,398 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:05:10,491 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:10,492 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:05:10,493 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:05:10,493 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:05:11,809 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:05:11,811 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:05:11,812 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:05:13,750 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:13,751 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:05:13,752 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:05:13,753 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:05:14,871 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:05:14,872 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:05:14,872 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e95195d3343342878f3c383bddd07ea6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX14 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:05:34,676 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:34,677 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:05:34,677 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:05:34,677 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:05:36,003 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:05:36,004 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:05:36,005 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:05:37,923 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:37,926 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:05:37,927 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:05:37,928 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:05:39,040 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:05:39,042 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:05:39,042 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5b4d4f62cd549bdbc1073a12176abc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX14 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:05:54,729 - INFO - [Silver labels] è¦†ç›–ç‡: 14.52% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:05:55,610 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:55,611 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:05:55,612 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:05:55,700 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:05:55,701 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:05:55,702 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:05:55,702 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:05:56,999 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:05:57,001 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:05:57,001 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:06:02,288 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:06:02,292 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:06:02,293 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:06:02,294 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:06:03,406 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:06:03,408 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:06:03,409 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ca6c5a8318847b78faf87a1f2bb787d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX13 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:06:26,663 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:06:26,665 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:06:26,666 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:06:26,667 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:06:27,995 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:06:27,996 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:06:27,997 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:06:33,261 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:06:33,263 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:06:33,264 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:06:33,265 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:06:34,459 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:06:34,462 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:06:34,463 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a07e3afce2af41c6b5a974f6f6793416",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TENX13 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:06:50,075 - INFO - [Silver labels] è¦†ç›–ç‡: 16.10% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:06:50,638 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:06:50,639 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:06:50,640 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:06:50,738 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:06:50,739 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:06:50,740 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:06:50,740 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:06:52,033 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:06:52,035 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:06:52,035 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:06:57,033 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:06:57,036 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:06:57,037 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:06:57,037 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:06:58,260 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:06:58,261 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:06:58,262 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ea43da394b0404696edf6a2bde97c68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA154 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:07:02,795 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:02,796 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:02,797 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:02,797 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:04,258 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:04,258 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:04,259 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:07:09,277 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:09,279 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:09,279 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:09,280 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:10,402 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:10,403 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:10,404 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d86d4013d914d63ae206f7048d07983",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA154 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:07:15,125 - INFO - [Silver labels] è¦†ç›–ç‡: 18.50% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:07:15,575 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:15,576 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:07:15,577 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:07:15,670 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:15,671 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:15,671 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:15,672 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:17,064 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:17,066 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:17,067 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:07:21,514 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:21,517 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:21,517 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:21,518 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:22,741 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:22,743 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:22,743 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c822b4524a9f4d1392f508ef68de9a28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA153 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:07:27,248 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:27,251 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:27,252 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:27,252 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:28,612 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:28,614 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:28,615 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:07:33,782 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:33,786 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:33,787 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:33,788 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:34,970 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:34,971 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:34,972 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4001825a4574012be772ea7f7ca4762",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA153 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:07:38,987 - INFO - [Silver labels] è¦†ç›–ç‡: 12.62% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:07:39,857 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:39,858 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:07:39,859 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:07:39,954 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:39,955 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:39,956 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:39,956 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:41,307 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:41,308 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:41,309 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:07:46,858 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:46,862 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:46,863 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:46,863 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:48,074 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:48,075 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:48,076 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f68781b80cbe44bf8957df945b99c7e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA152 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:07:52,756 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:52,758 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:52,758 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:52,759 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:07:54,176 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:07:54,178 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:07:54,178 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:07:59,628 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:07:59,633 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:07:59,634 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:07:59,635 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:01,053 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:01,055 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:01,056 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "413f3f20194f43a3824a04af7929c450",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA152 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:08:05,505 - INFO - [Silver labels] è¦†ç›–ç‡: 16.43% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:08:06,125 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:06,126 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:08:06,127 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:08:06,224 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:06,225 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:06,226 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:06,226 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:07,505 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:07,506 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:07,507 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:08:12,301 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:12,304 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:12,305 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:12,306 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:13,539 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:13,540 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:13,541 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f25e2ef56d4d4c98a88a7b6e1e3d5ed9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA151 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:08:17,967 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:17,968 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:17,969 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:17,969 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:19,223 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:19,224 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:19,225 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:08:24,498 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:24,500 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:24,501 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:24,502 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:25,639 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:25,641 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:25,642 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0df8533c39db47cb855f3eef805fcb54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA151 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:08:29,583 - INFO - [Silver labels] è¦†ç›–ç‡: 16.62% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:08:30,176 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:30,177 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:08:30,177 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:08:30,274 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:30,275 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:30,276 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:30,276 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:31,553 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:31,555 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:31,555 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:08:35,390 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:35,394 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:35,395 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:35,396 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:36,746 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:36,747 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:36,748 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7adbb387cb0a4f628ebb85deefe4dd13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA150 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:08:40,845 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:40,846 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:40,846 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:40,847 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:42,132 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:42,134 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:42,135 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:08:47,021 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:47,024 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:47,025 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:47,026 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:48,206 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:48,207 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:48,208 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6a0ad3599e64097bf675e3860cd2f70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA150 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:08:51,865 - INFO - [Silver labels] è¦†ç›–ç‡: 17.77% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:08:52,364 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:52,365 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:08:52,366 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:08:52,459 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:52,461 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:52,462 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:52,463 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:53,698 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:53,699 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:53,700 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:08:57,438 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:08:57,441 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:08:57,442 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:08:57,442 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:08:58,613 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:08:58,616 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:08:58,617 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "786165c28aec4a77b75584b5d9b697bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA149 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:09:02,654 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:02,655 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:02,656 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:02,656 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:03,964 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:03,966 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:03,966 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:09:06,949 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:06,955 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:06,957 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:06,958 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:08,134 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:08,136 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:08,136 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "247fa83bbb27428a854c77d7a9e87ad1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA149 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:09:11,980 - INFO - [Silver labels] è¦†ç›–ç‡: 12.50% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:09:12,490 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:12,493 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:09:12,493 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:09:12,723 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:12,724 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:12,725 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:12,726 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:13,993 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:13,995 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:13,996 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:09:16,999 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:17,001 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:17,002 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:17,003 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:18,177 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:18,178 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:18,179 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6995808f5ece454ba9a42f96fbff8dd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA148 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:09:22,575 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:22,577 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:22,578 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:22,578 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:23,986 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:23,987 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:23,988 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:09:26,784 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:26,788 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:26,789 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:26,789 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:27,919 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:27,921 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:27,922 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b36ae53128164a3b93ec30946eeccf2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA148 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:09:31,610 - INFO - [Silver labels] è¦†ç›–ç‡: 11.86% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:09:32,019 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:32,020 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:09:32,021 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:09:32,120 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:32,121 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:32,122 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:32,122 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:33,489 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:33,491 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:33,491 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:09:36,466 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:36,470 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:36,471 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:36,472 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:37,686 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:37,687 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:37,687 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e00e6d1987f543c8a38139fb5b1e343e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA147 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:09:41,568 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:41,569 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:41,570 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:41,570 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:42,808 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:42,809 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:42,810 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:09:45,680 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:45,682 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:45,682 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:45,683 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:46,805 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:46,808 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:46,809 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ff34a7eab704f449a262060e3b4ef5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA147 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:09:50,014 - INFO - [Silver labels] è¦†ç›–ç‡: 17.41% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:09:50,410 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:50,411 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:09:50,411 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:09:50,505 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:50,506 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:50,507 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:50,508 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:51,805 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:51,806 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:51,806 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:09:54,639 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:09:54,642 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:09:54,643 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:09:54,644 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:09:55,823 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:09:55,825 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:09:55,825 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40f8fcd00a5d4e2cbb15c0fb68593884",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA146 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:00,192 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:00,194 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:00,194 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:00,195 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:01,599 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:01,603 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:01,604 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:03,901 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:03,904 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:03,905 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:03,906 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:05,008 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:05,009 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:05,010 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "383f8c68aac3485c820d0b12b35911b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA146 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:08,654 - INFO - [Silver labels] è¦†ç›–ç‡: 18.79% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:10:09,113 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:09,114 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:10:09,115 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:10:09,206 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:09,207 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:09,208 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:09,208 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:10,676 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:10,677 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:10,678 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:12,485 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:12,488 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:12,489 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:12,490 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:13,604 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:13,606 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:13,606 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "852f0fd70f8a4e15a64b5f03e7f583a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA145 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:17,859 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:17,861 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:17,861 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:17,862 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:19,323 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:19,325 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:19,326 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:21,849 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:21,852 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:21,853 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:21,854 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:23,004 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:23,005 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:23,006 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c6900c691974c788136a1ee19a874e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA145 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:26,566 - INFO - [Silver labels] è¦†ç›–ç‡: 17.67% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:10:27,105 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:27,107 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:10:27,108 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:10:27,200 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:27,201 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:27,202 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:27,202 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:28,534 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:28,536 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:28,536 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:30,525 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:30,527 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:30,528 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:30,528 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:31,603 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:31,604 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:31,605 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d5b81d54b174d2986670cf734411325",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA144 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:35,737 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:35,739 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:35,739 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:35,740 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:36,952 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:36,953 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:36,954 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:39,893 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:39,895 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:39,896 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:39,896 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:40,996 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:40,998 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:40,999 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef7300dcab55491f94afc56740042f8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA144 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:44,368 - INFO - [Silver labels] è¦†ç›–ç‡: 14.53% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:10:44,800 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:44,801 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:10:44,802 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:10:44,900 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:44,901 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:44,902 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:44,903 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:46,173 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:46,174 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:46,174 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:48,483 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:48,485 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:48,486 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:48,486 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:49,616 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:49,619 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:49,620 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cb2286ce6ff440c8cd711c596cb106f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA143 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:10:54,363 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:54,365 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:54,366 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:54,367 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:55,667 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:55,668 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:55,669 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:10:57,499 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:10:57,503 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:10:57,504 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:10:57,504 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:10:58,615 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:10:58,617 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:10:58,618 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41e123612cb4460699214ef09d2f64c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA143 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:11:05,504 - INFO - [Silver labels] è¦†ç›–ç‡: 16.61% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:11:05,983 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:05,984 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:11:05,985 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:11:06,081 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:06,082 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:06,082 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:06,083 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:07,407 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:07,411 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:07,412 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:11:10,183 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:10,185 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:10,186 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:10,187 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:11,436 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:11,438 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:11,439 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a65470a329d476ab9be3a9c7699fa0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA142 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:11:16,092 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:16,094 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:16,096 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:16,096 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:17,452 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:17,454 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:17,455 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:11:22,982 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:22,985 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:22,986 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:22,987 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:24,109 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:24,111 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:24,112 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f3bb7f94bc94b2aa163b9bf39a1523f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA142 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:11:27,358 - INFO - [Silver labels] è¦†ç›–ç‡: 18.75% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:11:27,740 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:27,741 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:11:27,742 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:11:27,886 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:27,887 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:27,887 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:27,888 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:29,244 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:29,246 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:29,247 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:11:33,115 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:33,117 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:33,118 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:33,119 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:34,290 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:34,292 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:34,292 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f457b076b1f4427e868611d0a2ee4b31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA141 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:11:37,600 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:37,601 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:37,602 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:37,602 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:38,871 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:38,872 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:38,872 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:11:44,283 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:44,287 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:44,288 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:44,289 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:45,518 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:45,519 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:45,520 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c19ff1ebe1e14781b783d02065cf132d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA141 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:11:48,557 - INFO - [Silver labels] è¦†ç›–ç‡: 14.44% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:11:49,405 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:49,406 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:11:49,407 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:11:49,509 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:49,510 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:49,511 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:49,511 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:50,776 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:50,778 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:50,779 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:11:56,050 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:11:56,054 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:11:56,055 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:11:56,056 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:11:57,268 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:11:57,269 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:11:57,270 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffe21ced45e5422c9349413992e070a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA140 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:12:01,055 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:01,057 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:01,058 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:01,059 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:02,339 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:02,342 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:02,343 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:12:06,972 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:06,974 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:06,975 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:06,976 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:08,140 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:08,144 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:08,145 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f4d29d7f2924632be45fc1d6c74dda7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA140 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:12:11,880 - INFO - [Silver labels] è¦†ç›–ç‡: 17.22% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:12:12,297 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:12,298 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:12:12,299 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:12:12,401 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:12,402 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:12,403 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:12,403 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:13,977 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:13,979 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:13,980 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:12:19,541 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:19,546 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:19,547 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:19,548 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:20,742 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:20,743 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:20,744 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0978081540174be29be99cbffbef856f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA139 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:12:25,324 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:25,326 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:25,327 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:25,328 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:26,724 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:26,726 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:26,727 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:12:31,484 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:31,486 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:31,487 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:31,487 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:32,621 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:32,625 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:32,626 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97769523be1c4dccabd51015196c6f76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA139 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:12:36,151 - INFO - [Silver labels] è¦†ç›–ç‡: 15.22% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:12:36,552 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:36,553 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:12:36,554 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:12:36,652 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:36,653 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:36,654 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:36,654 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:37,945 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:37,946 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:37,947 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:12:43,368 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:43,371 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:43,372 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:43,373 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:44,589 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:44,591 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:44,592 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2093c4f94e8945b194e8df16ba1f77aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA138 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:12:48,345 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:48,347 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:48,348 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:48,348 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:49,791 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:49,792 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:49,793 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:12:55,163 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:12:55,166 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:12:55,167 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:12:55,168 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:12:56,418 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:12:56,419 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:12:56,420 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18b69db7d5514ef1baf2377130b5b569",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA138 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:12:59,886 - INFO - [Silver labels] è¦†ç›–ç‡: 14.92% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:13:00,169 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:00,169 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:13:00,170 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:13:00,270 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:00,271 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:00,272 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:00,272 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:01,514 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:01,516 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:01,516 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:13:06,248 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:06,251 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:06,251 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:06,252 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:07,460 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:07,461 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:07,462 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "115023b156aa469facbb67412e7117a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA137 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:13:11,051 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:11,052 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:11,052 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:11,053 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:12,268 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:12,270 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:12,271 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:13:17,372 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:17,374 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:17,375 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:17,376 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:18,742 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:18,743 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:18,744 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41192e4b6b134686b88878ba4bfd7a20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA137 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:13:21,788 - INFO - [Silver labels] è¦†ç›–ç‡: 13.48% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:13:22,282 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:22,284 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:13:22,284 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:13:22,391 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:22,392 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:22,393 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:22,393 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:23,647 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:23,649 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:23,649 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:13:29,044 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:29,046 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:29,048 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:29,049 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:30,267 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:30,270 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:30,271 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9b4ab0b951243428a77ee804221f675",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA136 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:13:35,249 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:35,251 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:35,251 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:35,252 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:36,563 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:36,564 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:36,565 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:13:42,815 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:42,820 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:42,821 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:42,822 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:43,989 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:43,990 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:43,990 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "697b2e1fc9d9442bae8033ce715a9d5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA136 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:13:48,081 - INFO - [Silver labels] è¦†ç›–ç‡: 11.11% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:13:48,575 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:48,576 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:13:48,577 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:13:48,672 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:48,673 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:48,673 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:48,674 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:50,034 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:50,035 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:50,036 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:13:55,193 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:13:55,197 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:13:55,199 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:13:55,200 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:13:56,754 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:13:56,758 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:13:56,759 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5b5f08eb184d858a8f2a88a97ad50b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA135 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:01,760 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:01,761 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:01,762 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:01,762 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:03,252 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:03,254 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:03,255 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:14:08,353 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:08,357 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:08,358 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:08,359 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:09,612 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:09,614 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:09,614 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d97588d50d8a4b8aa44b33e45b312251",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA135 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:13,466 - INFO - [Silver labels] è¦†ç›–ç‡: 18.81% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:14:13,949 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:13,950 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:14:13,951 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:14:14,046 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:14,047 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:14,047 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:14,048 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:15,274 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:15,275 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:15,276 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:14:19,281 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:19,283 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:19,283 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:19,284 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:20,465 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:20,466 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:20,466 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8702bd9d5fe4c2e838ff7320578cc81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA134 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:26,561 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:26,563 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:26,563 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:26,564 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:27,795 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:27,797 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:27,797 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:14:31,794 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:31,796 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:31,797 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:31,798 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:32,926 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:32,928 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:32,929 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb72bc9c49ac4bfdbe10f101047eee82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA134 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:36,681 - INFO - [Silver labels] è¦†ç›–ç‡: 16.61% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:14:37,169 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:37,170 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:14:37,171 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:14:37,271 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:37,272 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:37,273 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:37,273 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:38,553 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:38,555 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:38,556 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:14:41,574 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:41,578 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:41,579 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:41,580 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:42,698 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:42,699 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:42,700 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82821b70f9ab48f0b62a0847de7df953",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA133 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:47,488 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:47,489 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:47,490 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:47,490 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:48,820 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:48,822 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:48,823 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:14:52,003 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:52,007 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:52,008 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:52,009 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:14:53,159 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:53,160 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:53,161 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa05d844e3a34f8aa760578d3e9de398",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA133 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:56,722 - INFO - [Silver labels] è¦†ç›–ç‡: 16.56% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:14:57,241 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:57,242 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:14:57,242 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:14:57,333 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:14:57,334 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:14:57,335 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:14:57,335 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:14:58,564 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:14:58,566 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:14:58,566 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:15:01,507 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:01,509 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:01,510 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:01,510 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:02,653 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:02,654 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:02,655 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d613cf53f4a643c98db1b7c3101ef9cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA132 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:15:07,850 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:07,852 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:07,852 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:07,853 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:09,223 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:09,225 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:09,226 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:15:12,421 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:12,423 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:12,424 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:12,424 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:13,544 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:13,546 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:13,547 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92536ac881ab41a9b917a66706b1c1e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA132 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:15:17,515 - INFO - [Silver labels] è¦†ç›–ç‡: 16.99% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:15:17,939 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:17,940 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:15:17,941 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:15:18,044 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:18,044 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:18,045 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:18,046 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:19,480 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:19,481 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:19,482 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:15:22,578 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:22,582 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:22,583 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:22,584 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:23,760 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:23,762 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:23,762 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69b49a37613d4f11bbe55b37b7d217fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA131 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:15:28,989 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:28,990 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:28,991 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:28,991 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:30,231 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:30,233 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:30,234 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:15:32,835 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:32,837 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:32,837 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:32,838 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:33,942 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:33,943 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:33,944 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f61f533e008e465aadccd7f8a8ec77a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA131 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:15:38,100 - INFO - [Silver labels] è¦†ç›–ç‡: 18.10% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:15:38,629 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:38,630 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:15:38,631 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:15:38,739 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:38,740 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:38,740 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:38,741 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:40,023 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:40,024 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:40,025 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:15:42,000 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:42,004 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:42,005 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:42,005 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:43,149 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:43,150 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:43,151 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97852ba5c1c24440b35126cf039c2169",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA130 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:15:49,156 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:49,157 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:49,157 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:49,158 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:50,566 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:50,568 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:50,569 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:15:52,856 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:52,857 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:15:52,858 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:15:52,859 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:15:53,944 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:15:53,945 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:15:53,946 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dc975cbfab8427db46a83113bdc6035",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA130 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:15:59,310 - INFO - [Silver labels] è¦†ç›–ç‡: 12.10% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:15:59,954 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:15:59,954 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:15:59,955 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:16:00,048 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:00,048 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:00,049 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:00,050 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:01,354 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:01,355 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:01,356 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:16:03,273 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:03,276 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:03,277 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:03,277 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:04,381 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:04,383 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:04,384 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c7687579a3e41688e07cbd038fb81c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA129 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:16:11,023 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:11,024 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:11,025 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:11,025 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:12,325 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:12,327 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:12,327 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:16:14,183 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:14,187 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:14,187 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:14,188 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:15,313 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:15,314 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:15,315 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "607d87f0908c49449ce92329e2da1440",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA129 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:16:20,136 - INFO - [Silver labels] è¦†ç›–ç‡: 13.29% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:16:20,771 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:20,772 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:16:20,773 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:16:20,877 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:20,878 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:20,879 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:20,880 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:22,196 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:22,197 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:22,198 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:16:25,316 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:25,317 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:25,318 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:25,319 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:26,525 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:26,526 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:26,527 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5d8920abfc04dd2974ef592e332c5b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA128 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:16:32,797 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:32,799 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:32,800 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:32,800 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:34,113 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:34,114 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:34,115 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:16:37,055 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:37,060 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:37,061 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:37,061 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:38,226 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:38,228 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:38,229 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f0c27022c454a548c0898a58f9a3e09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA128 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:16:43,720 - INFO - [Silver labels] è¦†ç›–ç‡: 12.46% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:16:44,884 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:44,886 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:16:44,887 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:16:44,980 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:44,981 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:44,981 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:44,982 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:46,283 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:46,287 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:46,288 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:16:50,753 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:16:50,756 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:16:50,756 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:16:50,756 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:16:51,924 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:16:51,927 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:16:51,928 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95f1110b8b144c339557c789fbf188bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA127 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:17:00,016 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:00,017 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:00,018 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:00,018 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:01,458 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:01,459 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:01,460 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:17:06,868 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:06,873 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:06,874 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:06,875 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:08,179 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:08,180 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:08,180 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "380fe671047243ab86e2d4a362c0d862",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA127 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:17:14,380 - INFO - [Silver labels] è¦†ç›–ç‡: 10.56% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:17:14,942 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:14,943 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:17:14,944 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:17:15,066 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:15,067 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:15,067 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:15,068 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:16,348 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:16,349 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:16,350 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:17:21,488 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:21,491 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:21,492 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:21,493 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:22,664 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:22,666 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:22,667 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f9b163e34da4da2a083047159172c70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA126 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:17:29,371 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:29,372 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:29,372 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:29,372 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:30,630 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:30,631 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:30,632 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:17:36,205 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:36,208 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:36,209 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:36,210 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:37,349 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:37,350 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:37,351 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27594e0bf8294aa486775d30a82d518a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA126 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:17:44,148 - INFO - [Silver labels] è¦†ç›–ç‡: 10.07% (q=0.9, margin=0.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:17:44,942 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:44,944 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:17:44,944 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:17:45,045 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:45,046 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:45,046 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:45,047 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:46,431 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:46,434 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:46,435 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:17:50,910 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:50,912 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:50,913 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:50,914 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:17:52,179 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:17:52,212 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:17:52,214 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a49747f9bc1347beb9703d357b8dfde7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA125 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:17:59,919 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:17:59,920 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:17:59,920 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:17:59,921 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:01,427 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:01,431 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:01,432 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:18:06,103 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:06,106 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:06,107 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:06,108 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:07,228 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:07,230 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:07,230 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a2d7a75df3248c3bda6b1716fcf605e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA125 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:18:13,755 - INFO - [Silver labels] è¦†ç›–ç‡: 10.25% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:18:14,281 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:14,282 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:18:14,283 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:18:14,376 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:14,377 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:14,378 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:14,379 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:15,641 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:15,643 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:15,644 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:18:20,185 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:20,187 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:20,187 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:20,188 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:21,348 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:21,349 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:21,349 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f33686630c547cbb4f5faade8670aba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA124 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:18:27,945 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:27,947 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:27,947 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:27,948 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:29,449 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:29,450 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:29,451 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:18:34,624 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:34,628 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:34,629 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:34,630 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:35,861 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:35,862 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:35,863 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f10e460b375849dd94107cea4a205c17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA124 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:18:41,317 - INFO - [Silver labels] è¦†ç›–ç‡: 18.82% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:18:41,857 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:41,858 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:18:41,859 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:18:41,966 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:41,968 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:41,969 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:41,970 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:43,289 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:43,290 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:43,291 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:18:48,201 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:48,205 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:48,206 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:48,207 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:49,364 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:49,365 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:49,366 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "964e9b8b579d415eb5e93fb974136879",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA123 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:18:54,986 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:18:54,988 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:18:54,988 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:18:54,989 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:18:56,287 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:18:56,289 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:18:56,290 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:19:00,759 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:00,763 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:00,764 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:00,765 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:01,965 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:01,967 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:01,968 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "faa08e12276c44619845179bd2cebd8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA123 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:19:07,200 - INFO - [Silver labels] è¦†ç›–ç‡: 19.70% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:19:07,796 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:07,797 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:19:07,797 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:19:07,898 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:07,899 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:07,899 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:07,900 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:09,180 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:09,181 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:09,181 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:19:13,551 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:13,555 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:13,556 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:13,557 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:14,764 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:14,766 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:14,767 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9630fccbdb754960ab1bfc62538c73d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA122 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:19:21,354 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:21,356 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:21,357 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:21,358 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:22,725 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:22,727 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:22,728 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:19:29,693 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:29,695 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:29,696 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:29,696 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:31,793 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:31,795 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:31,796 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "293939fa5b5e4320bd55ea894515f6af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA122 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:19:37,137 - INFO - [Silver labels] è¦†ç›–ç‡: 18.14% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:19:37,880 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:37,881 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:19:37,882 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:19:37,981 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:37,983 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:37,984 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:37,984 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:39,300 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:39,301 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:39,302 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:19:43,912 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:43,916 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:43,917 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:43,918 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:45,043 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:45,044 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:45,045 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f97211f5da91431581378ceddacf131c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA121 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:19:51,407 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:51,409 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:51,410 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:51,411 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:52,814 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:52,817 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:52,818 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:19:56,613 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:19:56,615 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:19:56,616 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:19:56,617 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:19:57,771 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:19:57,772 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:19:57,773 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1409bf455de14f2eaf4744cbfca8474c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA121 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:20:03,846 - INFO - [Silver labels] è¦†ç›–ç‡: 13.38% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:20:04,422 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:04,423 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:20:04,423 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:20:04,521 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:04,522 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:04,523 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:04,523 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:05,820 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:05,820 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:05,821 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:20:08,710 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:08,712 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:08,713 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:08,714 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:09,909 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:09,910 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:09,911 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47facb163c094d3388010cf71f97401e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA120 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:20:16,991 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:16,993 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:16,994 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:16,995 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:18,293 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:18,294 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:18,295 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:20:27,860 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:27,864 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:27,864 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:27,865 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:28,984 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:28,985 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:28,986 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a930c98da6748f5a5a9a384b313820d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA120 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:20:33,803 - INFO - [Silver labels] è¦†ç›–ç‡: 12.11% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:20:34,438 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:34,440 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:20:34,440 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:20:34,547 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:34,548 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:34,548 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:34,549 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:35,862 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:35,864 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:35,865 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:20:38,969 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:38,973 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:38,974 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:38,974 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:40,116 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:40,117 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:40,118 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90d70cb7628e4ff29ef95de641584626",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA119 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:20:45,734 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:45,735 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:45,735 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:45,736 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:47,027 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:47,028 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:47,029 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:20:49,857 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:49,860 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:49,861 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:49,862 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:51,085 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:51,086 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:51,087 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dd7331387f24d158ac41b673a934fdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA119 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:20:55,944 - INFO - [Silver labels] è¦†ç›–ç‡: 14.12% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:20:56,402 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:56,403 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:20:56,404 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:20:56,501 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:20:56,502 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:20:56,502 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:20:56,503 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:20:57,764 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:20:57,766 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:20:57,767 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:00,715 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:00,717 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:00,717 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:00,718 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:01,823 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:01,825 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:01,826 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "decd247425ad429c96dfc1c8c7e3fcbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA118 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:05,479 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:05,480 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:05,481 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:05,482 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:06,762 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:06,763 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:06,764 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:08,343 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:08,345 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:08,346 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:08,347 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:09,459 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:09,461 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:09,462 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10094a83225b4b5289b166758bf6aed3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA118 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:12,451 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:21:12,452 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:21:12,452 - ERROR - SPA118 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:21:13,378 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:13,379 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:21:13,380 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:21:13,471 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:13,473 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:13,473 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:13,474 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:14,882 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:14,884 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:14,885 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:16,483 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:16,485 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:16,486 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:16,486 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:17,616 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:17,617 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:17,617 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15008f860c28443c89a0a471a6d6db06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA117 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:21,893 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:21,894 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:21,894 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:21,895 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:23,152 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:23,155 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:23,156 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:25,381 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:25,383 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:25,384 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:25,384 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:26,486 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:26,487 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:26,488 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78e2c87dc34a43258a3a65712a867ee5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA117 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:30,108 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:21:30,110 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:21:30,110 - ERROR - SPA117 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:21:31,028 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:31,029 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:21:31,029 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:21:31,128 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:31,129 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:31,130 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:31,130 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:32,389 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:32,391 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:32,392 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:35,286 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:35,288 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:35,289 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:35,290 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:36,398 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:36,399 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:36,400 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8cf910c1f824741b18b273a81521a12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA116 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:41,074 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:41,075 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:41,076 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:41,076 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:42,300 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:42,302 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:42,303 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:44,276 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:44,277 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:44,278 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:44,279 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:45,370 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:45,372 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:45,372 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09f1c55ca1fd41f6a02b18961197f67a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA116 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:49,116 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:21:49,117 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:21:49,118 - ERROR - SPA116 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:21:49,562 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:49,563 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:21:49,564 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:21:49,660 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:49,661 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:49,662 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:49,663 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:50,900 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:50,902 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:50,902 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:21:52,654 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:52,655 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:52,656 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:52,657 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:53,736 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:53,737 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:53,738 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0803f1d677b4bdb8d3851e948f002f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA115 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:21:57,427 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:21:57,428 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:21:57,429 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:21:57,429 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:21:58,631 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:21:58,632 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:21:58,632 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:22:00,315 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:00,317 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:00,318 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:00,318 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:01,420 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:01,421 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:01,422 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "124689b4a17a4758be1ff17e100a36e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA115 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:22:04,793 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:22:04,795 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:22:04,795 - ERROR - SPA115 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:22:05,272 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:05,273 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:22:05,274 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:22:05,371 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:05,372 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:05,373 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:05,374 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:06,715 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:06,716 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:06,716 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:22:11,936 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:11,939 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:11,940 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:11,941 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:13,122 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:13,123 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:13,124 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9f4d4825c214fe4ab87584b22eae20b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA114 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:22:19,731 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:19,733 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:19,734 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:19,735 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:21,112 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:21,113 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:21,114 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:22:26,389 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:26,391 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:26,392 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:26,393 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:27,521 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:27,523 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:27,524 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d991ef54b75f4bbc8b24af71ec9b0322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA114 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:22:31,372 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:22:31,373 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:22:31,374 - ERROR - SPA114 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:22:32,417 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:32,418 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:22:32,418 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:22:32,516 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:32,517 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:32,518 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:32,519 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:33,803 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:33,804 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:33,805 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:22:37,389 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:37,391 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:37,392 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:37,393 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:38,507 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:38,508 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:38,508 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24b685527fda48a4871cbb0ccb4df951",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA113 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:22:43,087 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:43,088 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:43,089 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:43,089 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:44,303 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:44,304 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:44,305 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:22:49,669 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:49,672 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:49,672 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:49,673 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:50,849 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:50,850 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:50,850 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "156548410c1d4dee9facc5d0543f0f72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA113 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:22:54,993 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:22:54,994 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:22:54,994 - ERROR - SPA113 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:22:55,409 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:55,410 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:22:55,411 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:22:55,511 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:22:55,513 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:22:55,514 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:22:55,515 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:22:56,830 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:22:56,832 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:22:56,832 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:23:02,370 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:02,374 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:02,375 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:02,375 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:03,630 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:03,633 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:03,633 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a95f460c53342729451221020ff22b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA112 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:23:11,123 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:11,125 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:11,126 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:11,127 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:12,712 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:12,714 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:12,715 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:23:17,604 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:17,607 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:17,608 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:17,609 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:18,848 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:18,851 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:18,852 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d320e8cca2c9424fa1dc5cd5fd0a8ccd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA112 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:23:22,591 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:23:22,594 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:23:22,594 - ERROR - SPA112 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:23:23,107 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:23,108 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:23:23,108 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:23:23,209 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:23,212 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:23,213 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:23,213 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:24,620 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:24,621 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:24,622 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:23:30,005 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:30,008 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:30,008 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:30,009 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:31,242 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:31,243 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:31,244 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d031bad1a63d411baddea55ea6d6cb46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA111 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:23:35,171 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:35,172 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:35,173 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:35,173 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:36,513 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:36,513 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:36,514 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:23:41,802 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:41,806 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:41,807 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:41,807 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:43,111 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:43,113 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:43,114 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40a2bc43e7d446bd8774ada302fff869",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA111 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:23:46,824 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:23:46,826 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:23:46,826 - ERROR - SPA111 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:23:47,803 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:47,804 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:23:47,805 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:23:47,905 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:47,907 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:47,907 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:47,908 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:49,447 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:49,449 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:49,449 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:23:54,354 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:23:54,357 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:23:54,358 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:23:54,358 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:23:55,503 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:23:55,505 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:23:55,506 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b47eeef058b04f1495b76b4bbbcc35af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA110 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:24:00,599 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:00,600 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:00,600 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:00,601 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:01,889 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:01,890 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:01,891 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:24:06,773 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:06,776 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:06,777 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:06,778 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:07,921 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:07,923 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:07,924 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e94b16c15eb744dcb6b7921ee987ca3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA110 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:24:12,520 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:24:12,522 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:24:12,523 - ERROR - SPA110 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:24:12,955 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:12,956 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:24:12,957 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:24:13,054 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:13,055 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:13,056 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:13,056 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:14,332 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:14,333 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:14,334 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:24:19,358 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:19,364 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:19,365 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:19,366 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:20,503 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:20,504 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:20,505 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48698e6ae91e4c899a85bd63bf19c89b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA109 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:24:25,380 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:25,381 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:25,382 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:25,382 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:26,768 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:26,769 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:26,770 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:24:31,677 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:31,681 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:31,682 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:31,682 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:32,950 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:32,952 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:32,952 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caad80d4dcfc41728816461cd70ba32c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA109 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:24:37,694 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:24:37,696 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:24:37,696 - ERROR - SPA109 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:24:38,274 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:38,275 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:24:38,275 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:24:38,377 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:38,378 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:38,379 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:38,379 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:39,712 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:39,714 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:39,715 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:24:44,741 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:44,744 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:44,745 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:44,746 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:46,082 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:46,084 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:46,084 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d47a82ff07294e6bb020e59cbd994b24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA108 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:24:51,730 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:51,732 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:51,733 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:51,734 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:53,064 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:53,066 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:53,067 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:24:58,711 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:24:58,714 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:24:58,715 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:24:58,716 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:24:59,908 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:24:59,910 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:24:59,910 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9419f6b714bf4f468aade97489f7b21a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA108 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:25:04,105 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:25:04,106 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:25:04,107 - ERROR - SPA108 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:25:04,563 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:04,564 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:25:04,564 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:25:04,662 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:04,664 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:04,664 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:04,665 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:05,952 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:05,953 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:05,954 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:25:10,828 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:10,831 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:10,832 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:10,833 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:11,961 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:11,962 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:11,963 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae509608f77441db826dc91ef06d76f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA107 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:25:17,022 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:17,024 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:17,024 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:17,024 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:18,352 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:18,353 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:18,354 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:25:22,568 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:22,571 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:22,572 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:22,573 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:23,873 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:23,875 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:23,876 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ecfaa314c8a4f398008250c0322f94b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA107 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:25:28,664 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:25:28,665 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:25:28,666 - ERROR - SPA107 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:25:29,317 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:29,318 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:25:29,318 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:25:29,423 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:29,425 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:29,425 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:29,426 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:30,764 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:30,766 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:30,767 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:25:33,790 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:33,793 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:33,794 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:33,795 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:34,962 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:34,963 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:34,964 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdb9ce9aee1a4e98af7e09684e4e8671",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA106 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:25:40,251 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:40,253 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:40,254 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:40,255 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:41,568 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:41,571 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:41,572 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:25:44,590 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:44,592 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:44,593 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:44,594 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:45,774 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:45,776 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:45,777 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4722174e3cb240be8da44cb353a15842",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA106 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:25:49,973 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:25:49,974 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:25:49,975 - ERROR - SPA106 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:25:50,479 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:50,480 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:25:50,481 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:25:50,579 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:50,581 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:50,581 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:50,582 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:51,899 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:51,900 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:51,901 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:25:55,251 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:25:55,257 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:25:55,258 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:25:55,259 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:25:56,486 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:25:56,488 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:25:56,488 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5562518c37dc46c890896c6dcad33eb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA105 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:26:01,188 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:01,190 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:01,190 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:01,191 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:02,523 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:02,526 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:02,527 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:26:05,903 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:05,905 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:05,906 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:05,907 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:07,084 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:07,087 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:07,088 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d86a429d090f482389ff11a32db03b68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA105 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:26:11,396 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:26:11,397 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:26:11,397 - ERROR - SPA105 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:26:12,216 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:12,217 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:26:12,218 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:26:12,316 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:12,317 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:12,318 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:12,319 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:13,681 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:13,684 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:13,685 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:26:16,724 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:16,727 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:16,728 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:16,729 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:17,881 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:17,882 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:17,883 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2a4723d719a41c79fd814ecee4397af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA104 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:26:23,074 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:23,077 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:23,077 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:23,078 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:24,386 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:24,387 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:24,388 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:26:27,259 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:27,262 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:27,263 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:27,264 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:28,377 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:28,379 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:28,379 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "925c7e48580f42ebb2732bad2665508e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA104 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:26:33,047 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:26:33,048 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:26:33,049 - ERROR - SPA104 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:26:33,744 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:33,745 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:26:33,745 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:26:33,851 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:33,852 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:33,852 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:33,853 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:35,209 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:35,212 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:35,213 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:26:36,870 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:36,872 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:36,873 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:36,874 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:37,969 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:37,970 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:37,971 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9f4b359c4d04685abf2a4e146c499b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA103 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:26:43,906 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:43,907 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:43,908 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:43,909 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:45,318 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:45,320 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:45,320 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:26:47,724 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:47,726 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:47,727 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:47,728 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:48,865 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:48,866 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:48,867 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15e12174c27a49bebe27fe6c3a43d7af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA103 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:26:54,537 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:26:54,538 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:26:54,539 - ERROR - SPA103 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:26:54,977 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:54,978 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:26:54,979 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:26:55,072 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:55,072 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:55,073 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:55,074 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:26:56,338 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:26:56,339 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:26:56,340 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:26:58,920 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:26:58,923 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:26:58,924 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:26:58,924 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:00,052 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:00,054 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:00,054 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d45b986b390f495c93a3d6d73ff43cf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA102 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:27:04,823 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:04,824 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:04,825 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:04,825 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:06,300 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:06,303 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:06,304 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:27:08,037 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:08,039 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:08,039 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:08,040 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:09,184 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:09,189 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:09,190 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a19343db12cf46cea54bca1b9a8fce7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA102 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:27:13,830 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:27:13,831 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:27:13,832 - ERROR - SPA102 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:27:14,682 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:14,683 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:27:14,684 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:27:14,780 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:14,781 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:14,782 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:14,783 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:16,091 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:16,093 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:16,093 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:27:18,021 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:18,025 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:18,026 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:18,027 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:19,114 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:19,116 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:19,117 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84a09af864e041e5ba2147593cf197fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA101 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:27:24,893 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:24,894 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:24,895 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:24,895 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:26,175 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:26,177 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:26,178 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:27:28,848 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:28,850 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:28,851 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:28,852 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:29,965 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:29,967 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:29,967 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec70b1d8626b4132936593ef4621dc67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA101 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:27:34,882 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:27:34,883 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:27:34,884 - ERROR - SPA101 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:27:35,326 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:35,327 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:27:35,328 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:27:35,436 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:35,437 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:35,437 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:35,438 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:36,766 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:36,767 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:36,768 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:27:39,924 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:39,926 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:39,927 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:39,927 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:41,072 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:41,075 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:41,076 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12dc719b4f914908b1c2b3d527f195e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA100 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:27:46,736 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:46,738 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:46,739 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:46,740 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:48,060 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:48,063 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:48,064 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:27:53,357 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:27:53,360 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:27:53,361 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:27:53,361 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:27:54,585 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:27:54,586 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:27:54,586 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "044114df825b46789d3b01230d720ffe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA100 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:28:00,395 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:28:00,397 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:28:00,397 - ERROR - SPA100 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:28:00,959 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:00,960 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:28:00,961 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:28:01,074 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:01,075 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:01,076 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:01,076 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:02,495 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:02,497 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:02,497 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:28:07,956 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:07,959 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:07,960 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:07,961 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:09,158 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:09,160 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:09,161 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17ec7fdeb9164f11a471e153b1210929",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA99 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:28:14,599 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:14,600 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:14,600 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:14,600 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:15,915 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:15,916 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:15,917 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:28:21,492 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:21,494 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:21,494 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:21,495 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:22,696 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:22,698 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:22,698 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "265948cc3ed14288a5f9d1cb4493c391",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA99 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:28:28,400 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:28:28,402 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:28:28,402 - ERROR - SPA99 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:28:29,029 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:29,030 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:28:29,031 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:28:29,126 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:29,127 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:29,127 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:29,128 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:30,513 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:30,515 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:30,516 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:28:35,280 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:35,283 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:35,284 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:35,285 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:36,429 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:36,432 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:36,433 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cbc739c5b58480ebe233bfd2e25956a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA98 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:28:41,247 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:41,248 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:41,249 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:41,249 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:42,672 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:42,674 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:42,675 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:28:45,117 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:45,121 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:45,121 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:45,122 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:46,255 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:46,256 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:46,257 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5ac39a17d734c9a8145d272e8c0bea7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA98 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:28:51,897 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:28:51,899 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:28:51,899 - ERROR - SPA98 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:28:52,564 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:52,565 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:28:52,566 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:28:52,662 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:52,662 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:52,663 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:52,664 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:53,934 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:53,936 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:53,936 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:28:58,518 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:28:58,519 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:28:58,520 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:28:58,521 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:28:59,695 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:28:59,696 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:28:59,697 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c02ade3e8e41436ca26f2bf05b1737d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA97 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:29:04,861 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:04,862 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:04,863 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:04,863 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:06,092 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:06,094 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:06,095 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:29:10,727 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:10,729 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:10,729 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:10,730 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:11,869 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:11,871 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:11,872 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6995bc3463e84cf5a05bd39efd4a747c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA97 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:29:16,659 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:29:16,660 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:29:16,660 - ERROR - SPA97 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:29:17,056 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:17,057 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:29:17,058 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:29:17,150 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:17,151 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:17,151 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:17,152 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:18,395 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:18,397 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:18,398 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:29:22,956 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:22,958 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:22,959 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:22,960 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:24,162 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:24,166 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:24,167 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "906353ad8536428eab91cbd848ff64ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA96 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:29:29,270 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:29,271 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:29,272 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:29,272 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:30,610 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:30,611 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:30,611 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:29:35,410 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:35,413 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:35,414 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:35,415 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:36,606 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:36,608 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:36,608 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "666f6cede2bc484098b6d404a578b9cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA96 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:29:41,690 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:29:41,691 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:29:41,692 - ERROR - SPA96 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:29:42,453 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:42,454 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:29:42,455 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:29:42,555 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:42,556 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:42,557 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:42,558 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:43,876 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:43,878 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:43,879 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:29:49,936 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:49,938 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:49,939 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:49,939 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:51,104 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:51,108 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:51,109 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d985ea9a276498c915510666ef00b55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA95 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:29:56,980 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:29:56,981 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:29:56,981 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:29:56,982 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:29:58,344 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:29:58,345 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:29:58,346 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:30:03,621 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:03,625 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:03,626 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:03,627 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:04,890 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:04,893 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:04,894 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9df8ca9d88545cc93632e101e4fb4c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA95 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:30:10,156 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:30:10,157 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:30:10,157 - ERROR - SPA95 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:30:10,646 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:10,647 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:30:10,647 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:30:10,751 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:10,752 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:10,753 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:10,753 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:12,306 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:12,308 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:12,309 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:30:17,350 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:17,354 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:17,355 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:17,356 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:18,503 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:18,504 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:18,504 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9150b87512e497fa2b5da002fef1ebf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA94 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:30:27,416 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:27,417 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:27,417 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:27,417 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:28,636 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:28,638 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:28,638 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:30:34,348 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:34,349 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:34,350 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:34,351 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:35,474 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:35,476 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:35,477 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae23c4a19fb24063823f898067df2aa2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA94 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:30:40,997 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:30:40,998 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:30:40,998 - ERROR - SPA94 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:30:41,505 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:41,506 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:30:41,507 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:30:41,607 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:41,608 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:41,608 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:41,609 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:42,871 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:42,873 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:42,873 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:30:47,501 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:47,502 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:47,503 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:47,504 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:48,640 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:48,642 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:48,643 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7703c425747843059b7d9db9042776c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA93 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:30:55,146 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:55,147 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:55,148 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:55,149 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:30:56,445 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:30:56,446 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:30:56,447 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:30:59,401 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:30:59,403 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:30:59,404 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:30:59,405 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:00,702 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:00,703 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:00,704 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81f71db6e63f454ca7aa5fc66c9f0b54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA93 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:31:05,510 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:31:05,512 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:31:05,512 - ERROR - SPA93 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:31:06,041 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:06,042 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:31:06,043 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:31:06,139 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:06,141 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:06,142 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:06,142 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:07,416 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:07,417 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:07,418 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:31:10,608 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:10,610 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:10,611 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:10,611 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:11,735 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:11,736 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:11,737 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f38cb05548d41baa2fe85b55a40b1a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA92 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:31:16,484 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:16,487 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:16,488 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:16,489 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:17,809 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:17,810 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:17,811 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:31:20,810 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:20,812 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:20,812 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:20,813 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:21,949 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:21,950 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:21,950 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f061b30cde94597bd6c7690d3387b88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA92 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:31:25,296 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:31:25,297 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:31:25,298 - ERROR - SPA92 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:31:25,849 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:25,850 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:31:25,851 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:31:25,947 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:25,948 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:25,949 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:25,950 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:27,181 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:27,182 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:27,183 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:31:30,146 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:30,147 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:30,148 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:30,148 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:31,270 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:31,271 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:31,272 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "389d798344f9433db4613476f9740229",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA91 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:31:35,143 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:35,144 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:35,145 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:35,145 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:36,396 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:36,398 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:36,399 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:31:39,409 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:39,411 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:39,411 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:39,412 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:40,543 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:40,544 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:40,544 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f056f44e88f463ebebade9027c0f44e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA91 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:31:43,908 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:31:43,909 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:31:43,909 - ERROR - SPA91 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:31:44,388 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:44,389 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:31:44,390 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:31:44,486 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:44,487 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:44,487 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:44,488 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:45,721 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:45,723 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:45,724 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:31:48,042 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:48,043 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:48,044 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:48,044 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:49,205 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:49,206 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:49,207 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01cfc1ac61b44c71ba249783a960f451",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA90 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:31:53,179 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:53,180 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:53,181 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:53,181 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:54,436 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:54,437 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:54,437 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:31:56,671 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:31:56,672 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:31:56,673 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:31:56,673 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:31:57,764 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:31:57,765 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:31:57,766 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f05a11b5617f4ff5be6779b5aae82759",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA90 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:01,381 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:01,382 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:01,383 - ERROR - SPA90 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:32:01,869 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:01,871 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:32:01,871 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:32:01,968 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:01,969 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:01,969 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:01,970 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:03,389 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:03,391 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:03,391 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:32:05,053 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:05,055 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:05,056 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:05,056 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:06,148 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:06,150 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:06,150 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87d8c40dea094f1788b27750869f699b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA89 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:10,739 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:10,740 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:10,740 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:10,741 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:12,015 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:12,017 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:12,018 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:32:14,049 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:14,050 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:14,051 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:14,052 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:15,139 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:15,140 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:15,141 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ad1beb4b4be47f8abb2f5d61dbc2b7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA89 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:19,444 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:19,445 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:19,446 - ERROR - SPA89 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:32:20,146 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:20,147 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:32:20,147 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:32:20,241 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:20,242 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:20,243 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:20,243 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:21,458 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:21,460 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:21,461 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:32:23,873 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:23,874 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:23,875 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:23,876 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:24,987 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:24,988 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:24,989 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "724d9d6945964f9a84263ccd2fcfe57b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA88 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:30,198 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:30,200 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:30,200 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:30,201 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:31,425 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:31,428 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:31,429 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:32:33,464 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:33,465 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:33,466 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:33,467 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:34,570 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:34,571 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:34,572 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e59f43346dc2403e9aec8f0acbf1c67d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA88 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:39,149 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:39,152 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:39,153 - ERROR - SPA88 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:32:39,951 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:39,952 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:32:39,953 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:32:40,053 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:40,054 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:40,054 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:40,055 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:41,321 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:41,322 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:41,323 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:32:44,057 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:44,060 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:44,061 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:44,061 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:45,185 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:45,187 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:45,188 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2e5c947fcdc42e4bcf11be9c7110277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA87 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:49,939 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:49,939 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:49,940 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:49,940 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:51,231 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:51,233 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:51,235 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:32:52,767 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:32:52,769 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:32:52,769 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:32:52,770 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:32:53,877 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:32:53,879 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:32:53,880 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa43085d15664e1c836f5eba10625e9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA87 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:32:59,980 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:59,981 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:32:59,982 - ERROR - SPA87 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:33:00,460 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:00,461 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:33:00,462 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:33:00,582 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:00,583 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:00,583 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:00,584 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:01,916 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:01,917 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:01,918 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:33:05,079 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:05,081 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:05,082 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:05,083 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:06,294 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:06,296 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:06,297 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6458cd86a8fb43978daf6d7c480afbe0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA86 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:33:12,692 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:12,693 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:12,693 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:12,694 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:13,951 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:13,951 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:13,952 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:33:19,115 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:19,119 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:19,120 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:19,121 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:20,239 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:20,241 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:20,242 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "780068034ccc41efa9763ade8e2a4a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA86 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:33:24,956 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:33:24,957 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:33:24,958 - ERROR - SPA86 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:33:25,777 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:25,778 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:33:25,779 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:33:25,884 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:25,885 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:25,886 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:25,886 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:27,296 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:27,297 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:27,298 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:33:33,222 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:33,225 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:33,226 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:33,227 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:34,443 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:34,444 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:34,444 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "063d0aacca144f0e931e7d647156a46e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA85 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:33:40,554 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:40,555 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:40,556 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:40,556 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:41,785 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:41,788 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:41,789 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:33:47,077 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:47,078 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:47,079 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:47,079 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:48,278 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:48,279 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:48,280 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a71fb19e47e416e93b66e3be636330b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA85 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:33:53,171 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:33:53,174 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:33:53,175 - ERROR - SPA85 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:33:53,826 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:53,827 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:33:53,828 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:33:53,934 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:33:53,935 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:33:53,936 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:33:53,936 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:33:55,308 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:33:55,310 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:33:55,311 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:34:00,770 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:00,774 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:00,775 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:00,776 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:02,009 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:02,010 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:02,010 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd4bae9cfa8b48e3a44a24b153126a58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA84 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:34:07,614 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:07,615 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:07,615 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:07,616 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:08,989 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:08,991 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:08,992 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:34:14,946 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:14,950 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:14,951 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:14,952 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:16,317 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:16,318 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:16,319 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae59b4fc212a410bbe4464fedc7cff3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA84 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:34:20,847 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:34:20,848 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:34:20,849 - ERROR - SPA84 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:34:21,451 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:21,452 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:34:21,453 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:34:21,551 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:21,552 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:21,552 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:21,553 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:22,977 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:22,978 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:22,979 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:34:28,389 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:28,393 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:28,394 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:28,395 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:29,583 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:29,585 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:29,585 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad4f590c7e4f4af2b5114ec7853f6efe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA83 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:34:36,069 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:36,070 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:36,071 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:36,071 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:37,500 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:37,501 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:37,501 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:34:43,862 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:43,867 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:43,868 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:43,868 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:45,372 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:45,374 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:45,375 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a918c00123aa45c08549a78db3e10dfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA83 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:34:50,973 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:34:50,975 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:34:50,976 - ERROR - SPA83 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:34:51,682 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:51,683 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:34:51,684 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:34:51,781 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:51,782 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:51,783 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:51,783 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:53,103 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:53,105 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:53,106 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:34:58,565 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:34:58,569 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:34:58,570 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:34:58,570 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:34:59,854 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:34:59,856 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:34:59,857 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91b8277f4c654e60b8a092f09c00bd08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA82 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:35:06,967 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:06,968 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:06,968 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:06,969 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:08,267 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:08,269 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:08,269 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:35:14,877 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:14,879 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:14,880 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:14,881 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:16,033 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:16,034 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:16,035 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "deb0d4c283114bc7861ae8f832da9b7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA82 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:35:21,888 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:35:21,889 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:35:21,890 - ERROR - SPA82 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:35:22,594 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:22,595 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:35:22,596 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:35:22,697 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:22,698 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:22,699 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:22,699 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:24,189 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:24,192 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:24,192 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:35:28,899 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:28,904 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:28,907 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:28,908 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:30,179 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:30,183 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:30,184 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "761cbcb3536c4ef7adf9b4e3afd8bf55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA81 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:35:36,533 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:36,534 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:36,534 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:36,535 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:38,013 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:38,015 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:38,016 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:35:48,059 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:48,061 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:48,062 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:48,062 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:49,194 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:49,196 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:49,197 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "411a1def3f6a446295b3e1da121a6c4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA81 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:35:54,385 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:35:54,387 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:35:54,387 - ERROR - SPA81 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:35:54,905 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:54,906 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:35:54,907 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:35:55,030 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:35:55,031 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:35:55,032 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:35:55,033 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:35:56,401 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:35:56,402 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:35:56,403 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:36:02,871 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:02,872 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:02,873 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:02,873 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:04,081 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:04,082 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:04,083 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b284aebb97f84bacafd7dbbd67f2cc85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA80 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:36:10,133 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:10,135 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:10,135 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:10,136 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:11,791 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:11,793 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:11,794 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:36:15,292 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:15,293 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:15,294 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:15,294 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:16,417 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:16,418 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:16,419 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0238f1bdd8b497a94378fd0831267c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA80 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:36:20,546 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:36:20,547 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:36:20,548 - ERROR - SPA80 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:36:21,155 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:21,156 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:36:21,157 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:36:21,264 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:21,265 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:21,266 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:21,266 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:22,593 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:22,594 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:22,594 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:36:26,430 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:26,433 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:26,434 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:26,435 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:27,626 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:27,628 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:27,628 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccbf39322fe64369a7af887b2af43411",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA79 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:36:31,997 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:31,999 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:32,000 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:32,000 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:33,365 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:33,367 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:33,368 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:36:36,306 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:36,307 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:36,308 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:36,309 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:37,567 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:37,570 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:37,571 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f32cb0f283014832a169ef00922faecf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA79 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:36:45,842 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:45,843 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:36:45,844 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:36:45,944 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:45,945 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:45,946 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:45,946 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:47,322 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:47,323 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:47,323 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:36:50,222 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:50,225 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:50,226 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:50,227 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:51,377 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:51,379 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:51,380 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a1abac6478a4e61a0face5eb16d4a0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA78 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:36:56,212 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:36:56,213 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:36:56,214 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:36:56,215 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:36:57,503 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:36:57,507 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:36:57,508 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:00,513 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:00,515 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:00,516 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:00,516 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:01,649 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:01,650 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:01,650 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "403de105bae64b88bdf2899527338ef4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA78 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:05,530 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:05,538 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:05,539 - ERROR - SPA78 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:37:06,083 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:06,084 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:37:06,085 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:37:06,192 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:06,193 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:06,194 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:06,194 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:07,488 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:07,489 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:07,490 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:10,472 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:10,474 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:10,475 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:10,476 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:11,665 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:11,666 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:11,667 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87fe144efba84efeb5a546294cec710f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA77 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:15,565 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:15,566 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:15,566 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:15,566 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:16,918 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:16,919 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:16,919 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:19,886 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:19,887 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:19,888 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:19,889 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:20,998 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:20,999 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:21,000 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cae49ec966d14e719a6c466f5c4823a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA77 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:24,153 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:24,155 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:24,157 - ERROR - SPA77 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:37:24,625 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:24,626 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:37:24,626 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:37:24,723 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:24,724 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:24,725 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:24,725 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:25,960 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:25,962 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:25,962 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:27,753 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:27,754 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:27,755 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:27,755 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:28,849 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:28,850 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:28,851 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "824b98b65db0417aa1e2edd63f00445f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA76 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:32,667 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:32,669 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:32,669 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:32,670 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:33,868 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:33,869 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:33,870 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:36,699 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:36,700 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:36,701 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:36,702 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:37,783 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:37,784 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:37,785 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f39e4c952778495fb77647213e04c7ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA76 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:41,158 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:41,158 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:41,159 - ERROR - SPA76 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:37:41,964 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:41,965 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:37:41,966 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:37:42,063 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:42,064 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:42,065 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:42,065 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:43,384 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:43,387 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:43,388 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:45,856 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:45,857 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:45,858 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:45,859 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:46,951 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:46,953 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:46,953 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a049e23536e44f888113acbba85707b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA75 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:50,949 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:50,951 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:50,951 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:50,952 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:52,189 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:52,190 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:52,191 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:37:54,226 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:54,227 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:54,228 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:54,228 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:37:55,318 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:37:55,319 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:37:55,320 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52c5e9fa4d4d418ebc9cf6a1651bf350",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA75 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:37:58,426 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:58,426 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:37:58,427 - ERROR - SPA75 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:37:59,176 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:59,177 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:37:59,178 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:37:59,280 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:37:59,280 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:37:59,281 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:37:59,282 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:00,547 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:00,548 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:00,549 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:38:02,494 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:02,495 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:02,495 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:02,496 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:03,576 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:03,577 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:03,578 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1f6c0bdfd6f4db2868cabd8ea907aa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA74 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:38:08,829 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:08,830 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:08,830 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:08,830 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:10,128 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:10,129 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:10,129 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:38:12,534 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:12,535 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:12,536 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:12,536 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:13,622 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:13,623 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:13,624 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e158755bc8a449649825e7706874b042",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA74 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:38:18,059 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:38:18,060 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:38:18,060 - ERROR - SPA74 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:38:18,603 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:18,605 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:38:18,605 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:38:18,700 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:18,701 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:18,702 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:18,703 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:19,909 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:19,910 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:19,911 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:38:22,658 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:22,660 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:22,661 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:22,661 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:23,765 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:23,766 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:23,767 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5559ef653f446908d31b37915989d48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA73 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:38:30,236 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:30,237 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:30,238 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:30,238 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:31,482 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:31,484 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:31,485 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:38:35,338 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:35,340 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:35,341 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:35,341 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:36,519 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:36,520 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:36,521 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eda84cbd719747be98919044ae0a1068",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA73 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:38:44,917 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:38:44,919 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:38:44,920 - ERROR - SPA73 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:38:45,555 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:45,556 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:38:45,557 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:38:45,656 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:45,656 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:45,657 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:45,658 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:46,963 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:46,965 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:46,965 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:38:52,154 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:52,157 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:52,157 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:52,158 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:38:53,349 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:38:53,350 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:38:53,351 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccad1a62792d41ffa55b787d4fc4e923",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA72 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:38:59,940 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:38:59,941 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:38:59,941 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:38:59,942 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:01,186 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:01,187 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:01,188 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:39:06,558 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:06,560 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:06,561 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:06,562 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:07,725 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:07,726 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:07,727 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "890315c540dd4e0db33656871e3b644f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA72 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:39:12,953 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:39:12,954 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:39:12,955 - ERROR - SPA72 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:39:13,524 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:13,525 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:39:13,526 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:39:13,626 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:13,627 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:13,627 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:13,629 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:14,885 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:14,887 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:14,888 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:39:19,857 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:19,859 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:19,859 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:19,860 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:21,046 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:21,047 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:21,048 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c5544ab584d4e268cae5eefba4dd98a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA71 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:39:26,952 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:26,953 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:26,953 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:26,954 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:28,210 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:28,212 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:28,213 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:39:33,820 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:33,824 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:33,825 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:33,826 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:35,505 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:35,512 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:35,513 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a37f56508034476d906e0565c482953d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA71 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:39:41,029 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:39:41,032 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:39:41,033 - ERROR - SPA71 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:39:41,643 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:41,644 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:39:41,645 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:39:41,770 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:41,771 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:41,772 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:41,773 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:43,345 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:43,346 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:43,347 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:39:50,476 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:50,480 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:50,480 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:50,481 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:51,655 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:51,656 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:51,657 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "150aac9d56dc4f68a77e6a920bfb487c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA70 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:39:57,998 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:39:57,999 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:39:57,999 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:39:58,000 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:39:59,272 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:39:59,273 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:39:59,273 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:40:04,541 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:04,543 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:04,544 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:04,545 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:05,683 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:05,684 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:05,685 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc952f612284670b30cf6bafdf5fbb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA70 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:40:10,791 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:40:10,794 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:40:10,794 - ERROR - SPA70 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:40:11,704 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:11,705 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:40:11,705 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:40:11,805 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:11,806 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:11,806 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:11,807 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:13,191 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:13,192 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:13,193 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:40:25,718 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:25,720 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:25,721 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:25,722 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:26,832 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:26,834 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:26,873 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39eecf1e29a7486880dad5bf294f4e53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA69 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:40:35,068 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:35,070 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:35,071 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:35,071 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:36,660 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:36,663 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:36,664 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:40:41,706 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:41,708 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:41,709 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:41,710 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:42,967 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:42,970 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:42,971 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "289bc907a53746d8ad54bbd7559acdb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA69 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:40:48,167 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:40:48,168 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:40:48,169 - ERROR - SPA69 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:40:49,171 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:49,172 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:40:49,173 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:40:49,286 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:49,287 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:49,287 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:49,288 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:50,740 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:50,742 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:50,743 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:40:58,055 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:40:58,058 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:40:58,059 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:40:58,060 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:40:59,573 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:40:59,575 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:40:59,575 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "559baf8f39a349b0b66d1b335891d8a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA68 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:41:06,627 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:06,629 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:06,630 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:06,630 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:08,023 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:08,024 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:08,024 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:41:14,221 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:14,224 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:14,224 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:14,225 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:15,457 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:15,458 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:15,459 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3287cc8ea67c47c2a8b7a0993db23a9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA68 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:41:20,007 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:41:20,008 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:41:20,009 - ERROR - SPA68 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:41:20,652 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:20,653 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:41:20,654 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:41:20,750 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:20,751 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:20,752 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:20,752 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:22,206 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:22,207 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:22,208 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:41:27,899 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:27,903 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:27,904 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:27,904 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:29,124 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:29,127 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:29,128 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0df76cad82984542ba4fe8b7016a7d40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA67 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:41:34,365 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:34,368 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:34,368 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:34,369 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:35,775 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:35,776 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:35,777 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:41:40,710 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:40,712 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:40,713 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:40,714 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:41,881 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:41,882 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:41,882 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd1b338cdb754c32b4a4221e2ea859f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA67 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:41:47,163 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:41:47,164 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:41:47,165 - ERROR - SPA67 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:41:48,236 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:48,238 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:41:48,238 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:41:48,339 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:48,340 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:48,341 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:48,341 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:49,615 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:49,616 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:49,617 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:41:54,130 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:41:54,133 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:41:54,134 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:41:54,135 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:41:55,268 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:41:55,269 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:41:55,270 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e3ddc05081144c7839a3c53c106fffb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA66 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:42:02,018 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:02,019 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:02,020 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:02,021 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:03,320 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:03,321 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:03,322 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:42:07,334 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:07,338 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:07,339 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:07,339 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:08,595 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:08,597 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:08,598 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c588016f86ad43e09d110a5ebb2086d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA66 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:42:14,319 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:42:14,320 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:42:14,320 - ERROR - SPA66 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:42:14,831 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:14,832 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:42:14,833 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:42:14,935 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:14,936 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:14,936 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:14,937 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:16,173 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:16,175 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:16,176 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:42:19,538 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:19,539 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:19,540 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:19,541 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:20,664 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:20,665 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:20,666 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52509165d3584efd81f6978574edf601",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA65 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:42:25,986 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:25,987 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:25,988 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:25,989 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:27,229 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:27,230 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:27,231 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:42:30,265 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:30,266 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:30,267 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:30,268 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:31,418 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:31,420 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:31,420 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c93a4d4ac5b4b1684780507fb50b529",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA65 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:42:35,670 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:42:35,672 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:42:35,672 - ERROR - SPA65 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:42:36,159 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:36,160 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:42:36,161 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:42:36,270 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:36,271 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:36,272 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:36,272 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:37,596 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:37,597 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:37,598 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:42:40,814 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:40,819 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:40,820 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:40,821 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:42,037 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:42,038 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:42,038 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "162c2c73b01d4408bf64f881067ad6eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA64 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:42:47,293 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:47,294 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:47,294 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:47,295 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:48,611 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:48,614 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:48,615 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:42:51,763 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:51,764 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:51,765 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:51,766 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:52,916 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:52,918 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:52,918 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6e3214738e047a097448371e3b6e1be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA64 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:42:57,019 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:42:57,020 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:42:57,021 - ERROR - SPA64 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:42:57,953 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:57,954 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:42:57,955 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:42:58,053 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:42:58,054 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:42:58,054 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:42:58,055 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:42:59,382 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:42:59,383 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:42:59,384 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:43:02,303 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:02,307 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:02,308 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:02,308 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:03,457 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:03,458 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:03,459 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd1a025d3cbd4b6a9c15cbb795f8e468",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA63 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:43:10,098 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:10,099 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:10,100 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:10,101 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:11,367 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:11,370 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:11,371 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:43:13,837 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:13,839 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:13,839 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:13,839 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:14,921 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:14,922 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:14,922 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2959a11cfad42b38c64f179455b4591",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA63 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:43:22,484 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:43:22,485 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:43:22,485 - ERROR - SPA63 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:43:22,987 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:22,988 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:43:22,989 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:43:23,086 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:23,087 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:23,087 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:23,088 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:24,331 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:24,332 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:24,332 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:43:26,837 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:26,839 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:26,840 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:26,841 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:27,937 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:27,938 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:27,939 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf5035daa48e4473b3eb0a7f2c957d0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA62 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:43:31,477 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:31,479 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:31,480 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:31,481 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:32,703 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:32,704 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:32,705 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:43:34,766 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:34,767 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:34,768 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:34,769 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:35,854 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:35,855 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:35,856 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d22c1427af554b70a9b9e0ee87fd57fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA62 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:43:39,098 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:43:39,099 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:43:39,100 - ERROR - SPA62 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:43:39,554 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:39,555 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:43:39,556 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:43:39,649 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:39,650 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:39,651 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:39,651 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:40,877 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:40,878 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:40,878 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:43:43,094 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:43,095 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:43,096 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:43,096 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:44,207 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:44,208 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:44,209 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6b4ff85be234a228a2a56a0f19d1420",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA61 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:43:48,190 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:48,191 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:48,193 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:48,193 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:49,407 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:49,408 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:49,409 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:43:52,165 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:52,166 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:52,167 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:52,168 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:53,289 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:53,291 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:53,291 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45b047982a964345bb894060f2cd707f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA61 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:43:56,887 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:43:56,889 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:43:56,890 - ERROR - SPA61 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:43:57,260 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:57,260 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:43:57,261 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:43:57,357 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:43:57,358 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:43:57,359 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:43:57,360 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:43:58,687 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:43:58,688 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:43:58,689 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:44:00,713 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:00,715 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:00,716 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:00,717 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:01,821 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:01,822 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:01,823 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d25c2225f4004bceb7135a7d3852df59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA60 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:44:06,240 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:06,242 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:06,242 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:06,243 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:07,623 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:07,625 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:07,626 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:44:10,946 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:10,948 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:10,949 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:10,949 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:12,212 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:12,213 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:12,214 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1518106295164a9f937e975b82051f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA60 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:44:18,229 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:44:18,232 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:44:18,233 - ERROR - SPA60 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:44:18,824 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:18,825 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:44:18,826 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:44:18,923 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:18,924 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:18,924 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:18,925 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:20,377 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:20,379 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:20,380 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:44:23,766 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:23,767 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:23,768 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:23,769 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:24,887 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:24,889 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:24,890 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eff69227afa4439c814ac28b53c3e198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA59 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:44:30,593 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:30,594 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:30,595 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:30,595 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:32,035 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:32,036 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:32,037 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:44:36,948 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:36,951 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:36,952 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:36,953 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:38,084 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:38,087 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:38,088 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd96fe92ff2d4cd2a163bdbaf645d4f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA59 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:44:50,473 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:50,478 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:50,478 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:50,479 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:51,675 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:51,679 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:51,680 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "095749fd0b9747f192a378b1b06b605d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA58 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:44:57,374 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:44:57,376 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:44:57,377 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:44:57,378 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:44:58,822 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:44:58,824 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:44:58,825 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:45:03,530 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:03,534 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:03,535 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:03,535 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:04,718 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:04,720 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:04,721 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40c65ea0b9e64d6db1f92f63438c5b97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA58 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:45:09,619 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:45:09,620 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:45:09,620 - ERROR - SPA58 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:45:10,099 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:10,101 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:45:10,102 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:45:10,200 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:10,202 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:10,203 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:10,203 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:11,548 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:11,549 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:11,549 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:45:16,634 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:16,637 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:16,638 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:16,639 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:17,963 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:17,964 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:17,965 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e8beafb48bd49dd872fa86e560a8923",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA57 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:45:23,304 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:23,306 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:23,306 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:23,307 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:24,605 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:24,607 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:24,608 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:45:31,619 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:31,620 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:31,620 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:31,620 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:32,885 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:32,888 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:32,889 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ee870fbb59e45d8a328dc08ff0ac3ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA57 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:45:38,059 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:45:38,060 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:45:38,060 - ERROR - SPA57 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:45:38,573 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:38,574 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:45:38,575 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:45:38,672 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:38,672 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:38,673 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:38,674 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:39,972 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:39,973 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:39,974 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:45:44,986 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:44,990 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:44,991 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:44,991 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:46,178 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:46,179 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:46,180 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f751536687ea4721ba8a73f70bc4f1f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA56 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:45:52,482 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:45:52,484 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:45:52,484 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:45:52,484 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:45:53,755 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:45:53,756 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:45:53,757 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:46:00,509 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:00,511 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:00,512 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:00,512 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:01,684 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:01,687 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:01,688 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1964a9dbab8d4ad8b5ff92780a565153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA56 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:46:06,810 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:46:06,811 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:46:06,811 - ERROR - SPA56 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:46:07,641 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:07,642 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:46:07,643 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:46:07,745 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:07,746 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:07,747 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:07,747 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:09,097 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:09,099 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:09,100 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:46:14,036 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:14,038 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:14,039 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:14,039 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:15,305 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:15,308 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:15,310 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a65602de88774a45828e153a7928f062",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA55 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:46:22,578 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:22,579 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:22,579 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:22,580 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:23,902 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:23,903 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:23,904 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:46:27,907 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:27,911 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:27,912 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:27,913 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:29,111 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:29,113 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:29,113 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3f8eca34b074f949ec6524f66addea8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA55 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:46:35,330 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:46:35,331 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:46:35,332 - ERROR - SPA55 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:46:35,816 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:35,817 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:46:35,818 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:46:35,915 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:35,916 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:35,916 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:35,916 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:37,267 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:37,269 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:37,270 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:46:44,249 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:44,252 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:44,254 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:44,255 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:45,485 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:45,486 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:45,487 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7bb6b6c294847dba3b096e0ec8716a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA54 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:46:52,340 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:52,341 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:52,341 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:52,341 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:53,663 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:53,664 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:53,665 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:46:58,708 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:46:58,712 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:46:58,713 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:46:58,714 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:46:59,963 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:46:59,968 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:46:59,968 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "888ab42afde84916b45bf4a2cf7dc872",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA54 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:47:05,428 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:47:05,431 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:47:05,431 - ERROR - SPA54 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:47:05,972 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:05,973 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:47:05,974 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:47:06,079 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:06,080 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:06,081 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:06,082 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:07,638 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:07,639 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:07,640 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:47:12,130 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:12,134 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:12,135 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:12,136 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:13,285 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:13,286 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:13,287 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f23a45cab6114453a5b5a498d526b1c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA53 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:47:17,994 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:17,996 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:17,996 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:17,996 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:19,323 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:19,324 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:19,325 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:47:22,950 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:22,952 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:22,953 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:22,954 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:24,073 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:24,075 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:24,076 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f6be59bc00c4681899fa716045acc00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA53 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:47:28,203 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:47:28,204 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:47:28,204 - ERROR - SPA53 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:47:28,855 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:28,856 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:47:28,857 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:47:28,964 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:28,964 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:28,965 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:28,966 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:30,366 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:30,368 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:30,369 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:47:34,111 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:34,114 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:34,115 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:34,115 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:35,270 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:35,272 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:35,273 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a1d4c86e8f840a0b4bdc18eae76cab0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA52 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:47:39,531 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:39,533 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:39,533 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:39,533 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:40,830 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:40,833 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:40,834 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:47:43,818 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:43,820 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:43,821 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:43,822 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:45,003 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:45,004 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:45,005 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b59d9ee7e18c49d28bb92733cbf3eff9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA52 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:47:48,500 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:47:48,501 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:47:48,502 - ERROR - SPA52 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:47:49,729 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:49,730 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:47:49,731 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:47:49,831 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:49,831 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:49,832 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:49,832 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:51,136 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:51,137 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:51,138 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:47:54,399 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:47:54,402 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:47:54,402 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:47:54,403 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:47:55,527 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:47:55,529 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:47:55,530 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80f1acdb5dd94acd8f5df892c0d058cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA51 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:00,426 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:00,427 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:00,427 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:00,427 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:01,830 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:01,833 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:01,834 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:48:05,019 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:05,022 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:05,022 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:05,023 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:06,215 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:06,216 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:06,217 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ca5ac9f759c4c8eadafc6409156f3c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA51 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:10,177 - WARNING - [Tumor (IDC)] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:48:10,179 - WARNING - [Normal & Stroma] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\n",
            "2025-09-13 14:48:10,180 - ERROR - SPA51 è¯„ä¼°å¤±è´¥: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 418, in evaluate_breast_cancer_cohort\n",
            "    sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 308, in run_inference_and_eval_single\n",
            "    pseudo, score_df = create_silver_labels_scanpy(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_20982/1843103166.py\", line 124, in create_silver_labels_scanpy\n",
            "    raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
            "ValueError: marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\n",
            "2025-09-13 14:48:10,508 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:10,508 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:48:10,509 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:48:10,603 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:10,605 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:10,606 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:10,606 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:11,887 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:11,889 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:11,889 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:48:14,854 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:14,855 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:14,856 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:14,856 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:17,048 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:17,051 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:17,052 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b788d09a8a741f2b35046bdd7efe7ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA3 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:20,356 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:20,357 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:20,358 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:20,358 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:21,711 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:21,712 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:21,713 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:48:24,075 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:24,078 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:24,079 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:24,080 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:25,264 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:25,265 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:25,266 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fa378f94fc749e7a6b1a2a141e373a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA3 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:28,952 - INFO - [Silver labels] è¦†ç›–ç‡: 18.50% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:48:29,400 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:29,401 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:48:29,401 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:48:29,502 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:29,503 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:29,504 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:29,504 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:30,783 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:30,784 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:30,785 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:48:32,703 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:32,704 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:32,705 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:32,706 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:33,820 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:33,822 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:33,823 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a1649293e54b3b9891f2751994c328",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA2 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:37,259 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:37,259 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:37,260 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:37,260 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:38,590 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:38,591 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:38,592 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:48:40,274 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:40,275 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:40,276 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:40,277 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:41,365 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:41,366 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:41,367 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0ffc5115f454b77a34286fffd3eb15a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA2 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:47,054 - INFO - [Silver labels] è¦†ç›–ç‡: 19.12% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:48:47,447 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:47,448 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:48:47,449 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:48:47,546 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:47,547 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:47,548 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:47,548 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:48,835 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:48,836 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:48,837 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:48:51,178 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:51,180 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:51,181 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:51,181 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:52,280 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:52,281 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:52,282 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8af25e67adaa482e8e8f042ba8b9ac9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA1 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:48:56,873 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:48:56,883 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:48:56,885 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:48:56,885 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:48:58,194 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:48:58,195 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:48:58,196 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:49:00,084 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:00,087 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:00,088 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:00,089 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:01,171 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:01,172 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:01,173 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7491bfc8fd447818816a89ddda3c092",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA1 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:49:04,410 - INFO - [Silver labels] è¦†ç›–ç‡: 20.08% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:49:04,846 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:04,847 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:49:04,848 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:49:04,947 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:04,947 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:04,948 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:04,949 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:06,294 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:06,296 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:06,297 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:49:07,995 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:07,997 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:07,998 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:07,999 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:09,112 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:09,113 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:09,114 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32aede00ba7240aeb5f1ef51b5013bd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA0 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:49:12,529 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:12,530 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:12,531 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:12,531 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:13,774 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:13,776 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:13,777 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:49:15,745 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:15,747 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:15,748 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:15,749 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:16,849 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:16,850 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:16,851 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "271b9c5fe1294904aef2e8e6ecb98141",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SPA0 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:49:19,979 - INFO - [Silver labels] è¦†ç›–ç‡: 20.23% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:49:20,327 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:20,328 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:49:20,329 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:49:20,430 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:20,431 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:20,431 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:20,432 - INFO - Instantiating model architecture: CLIP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/public/home/jijh/micromamba/envs/spatial_clip/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82: UserWarning: Some cells have zero counts\n",
            "  return fn(*args_all, **kw)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:49:21,731 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:21,732 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:21,733 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:49:23,759 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:23,760 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:23,761 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:23,762 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:24,935 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:24,937 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:24,938 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b16ef697542b4cd6a3aa042f1a78a3aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI785 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:49:36,835 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:36,837 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:36,837 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:36,837 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:38,274 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:38,275 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:38,276 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:49:40,163 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:40,165 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:40,165 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:40,166 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:41,407 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:41,410 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:41,411 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2869854de3ec493f9608e98a1235de0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI785 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:49:51,571 - INFO - [Silver labels] è¦†ç›–ç‡: 19.74% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:49:51,948 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:51,949 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:49:51,950 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:49:52,059 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:52,060 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:52,061 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:52,062 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:49:53,450 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:49:53,453 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:49:53,454 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:49:58,882 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:49:58,886 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:49:58,887 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:49:58,888 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:50:00,024 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:50:00,026 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:50:00,027 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53aed32d7619477bbe245d31431e1169",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI784 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:50:13,163 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:50:13,164 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:50:13,165 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:50:13,165 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:50:14,494 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:50:14,496 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:50:14,497 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:50:19,330 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:50:19,334 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:50:19,335 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:50:19,336 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:50:20,518 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:50:20,519 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:50:20,520 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "303c8695d69641229a1393e176499572",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI784 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:50:32,073 - INFO - [Silver labels] è¦†ç›–ç‡: 19.19% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:50:32,545 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:50:32,547 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:50:32,549 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:50:32,655 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:50:32,656 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:50:32,656 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:50:32,657 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:50:34,091 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:50:34,094 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:50:34,095 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:50:39,002 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:50:39,004 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:50:39,005 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:50:39,006 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:50:40,146 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:50:40,147 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:50:40,148 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6049790d0de84f50b5d1fa2000b05858",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI783 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:51:00,362 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:00,363 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:51:00,363 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:51:00,364 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:51:01,773 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:51:01,775 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:51:01,776 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:51:05,834 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:05,836 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:51:05,837 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:51:05,838 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:51:07,016 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:51:07,019 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:51:07,020 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99c3943a239248ef9c22534509e4db1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI783 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:51:19,998 - INFO - [Silver labels] è¦†ç›–ç‡: 19.46% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:51:21,166 - INFO - Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:21,168 - INFO - Attempting to load config from built-in: ViT-B-32\n",
            "2025-09-13 14:51:21,169 - INFO - Using default SimpleTokenizer.\n",
            "2025-09-13 14:51:21,267 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:21,268 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:51:21,269 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:51:21,269 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:51:22,598 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:51:22,600 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:51:22,601 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:51:27,716 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:27,718 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:51:27,719 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:51:27,720 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:51:28,851 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:51:28,855 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:51:28,856 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e64f7d395a97472b8d162ff7b2ad6aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI776 æ¨ç†: OmiCLIP (Baseline):   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:51:47,539 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:47,541 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:51:47,542 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:51:47,542 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:51:48,847 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:51:48,848 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:51:48,849 - INFO - Model ViT-B-32 creation process complete.\n",
            "2025-09-13 14:51:54,262 - INFO - Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
            "2025-09-13 14:51:54,264 - INFO - Loaded built-in ViT-B-32 model config.\n",
            "2025-09-13 14:51:54,265 - INFO - No potential checkpoint path found from config source or pretrained arg.\n",
            "2025-09-13 14:51:54,266 - INFO - Instantiating model architecture: CLIP\n",
            "2025-09-13 14:51:55,583 - WARNING - No pretrained weights loaded for model 'ViT-B-32'. Model initialized randomly.\n",
            "2025-09-13 14:51:55,586 - INFO - Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
            "2025-09-13 14:51:55,587 - INFO - Model ViT-B-32 creation process complete.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0d1ee7e161046a197ec0a317dc5fbca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "NCBI776 æ¨ç†: Spatial CLIP (Ours):   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-13 14:52:14,979 - INFO - [Silver labels] è¦†ç›–ç‡: 19.59% (q=0.9, margin=0.3)\n",
            "2025-09-13 14:52:15,060 - INFO - å·²ä¿å­˜:\n",
            "- /cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline/cohort_breast_per_sample_Breast_Cancer_Binary.csv\n",
            "- /cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline/cohort_breast_grouped_Breast_Cancer_Binary.csv\n",
            "- /cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline/cohort_breast_global_Breast_Cancer_Binary.csv\n",
            "- /cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline/cohort_breast_mcnemar_per_sample_Breast_Cancer_Binary.csv\n",
            "- /cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline/cohort_breast_mcnemar_pooled_Breast_Cancer_Binary.csv\n",
            "2025-09-13 14:52:15,062 - WARNING - ä»¥ä¸‹æ ·æœ¬æœªèƒ½è¯„ä¼°ï¼ˆç¼º WSI æˆ–æŠ¥é”™ï¼‰ï¼š['SPA118', 'SPA117', 'SPA116', 'SPA115', 'SPA114', 'SPA113', 'SPA112', 'SPA111', 'SPA110', 'SPA109', 'SPA108', 'SPA107', 'SPA106', 'SPA105', 'SPA104', 'SPA103', 'SPA102', 'SPA101', 'SPA100', 'SPA99', 'SPA98', 'SPA97', 'SPA96', 'SPA95', 'SPA94', 'SPA93', 'SPA92', 'SPA91', 'SPA90', 'SPA89', 'SPA88', 'SPA87', 'SPA86', 'SPA85', 'SPA84', 'SPA83', 'SPA82', 'SPA81', 'SPA80', 'SPA79', 'SPA78', 'SPA77', 'SPA76', 'SPA75', 'SPA74', 'SPA73', 'SPA72', 'SPA71', 'SPA70', 'SPA69', 'SPA68', 'SPA67', 'SPA66', 'SPA65', 'SPA64', 'SPA63', 'SPA62', 'SPA61', 'SPA60', 'SPA59', 'SPA58', 'SPA57', 'SPA56', 'SPA55', 'SPA54', 'SPA53', 'SPA52', 'SPA51']\n",
            "=== æ¯æ ·æœ¬æ˜ç»†ï¼ˆå‰10è¡Œï¼‰===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_20982/1843103166.py:484: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  per_sample_df = pd.concat(all_rows, ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sample_id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "model",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "accuracy",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "f1_weighted",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "auroc_macro_ovr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "auprc_macro_ovr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "ece_15bin",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brier",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "coverage",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "n_eval_spots",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "n_total_spots",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "n_correct",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "organ",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "species",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "disease_state",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "oncotree_code",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "st_technology",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "preservation_method",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "nb_genes",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "data_publication_date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "license",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "tissue",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "subseries",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "inter_spot_dist",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "spot_diameter",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pixel_size_um_embedded",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pixel_size_um_estimated",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "fullres_px_width",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "fullres_px_height",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "b5084573-b284-4fba-aa8a-0b67ef322399",
              "rows": [
                [
                  "0",
                  "TENX99",
                  "OmiCLIP (Baseline)",
                  "0.6609249646059462",
                  "0.6609983590123487",
                  "0.7123062246255825",
                  "0.6953556756018513",
                  "0.15056378872904255",
                  "0.4906998877823017",
                  "0.18378143972246314",
                  "4238",
                  "23060",
                  "2801.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Replicate 1",
                  null,
                  null,
                  "1.0",
                  "0.2125",
                  "51351",
                  "107121"
                ],
                [
                  "1",
                  "TENX99",
                  "Spatial CLIP (Ours)",
                  "0.756488909863143",
                  "0.7488012096333273",
                  "0.8718828821235668",
                  "0.8691703288940472",
                  "0.25491057886949064",
                  "0.49787694929222054",
                  "0.18378143972246314",
                  "4238",
                  "23060",
                  "3206.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Replicate 1",
                  null,
                  null,
                  "1.0",
                  "0.2125",
                  "51351",
                  "107121"
                ],
                [
                  "2",
                  "TENX98",
                  "OmiCLIP (Baseline)",
                  "0.643265306122449",
                  "0.6364170476250509",
                  "0.7047707407079666",
                  "0.690384600067355",
                  "0.13010712879044667",
                  "0.4898748452011968",
                  "0.18795550441120062",
                  "4900",
                  "26070",
                  "3152.0000000000005",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Replicate 2",
                  null,
                  null,
                  "0.2125",
                  "0.2125",
                  "51458",
                  "111225"
                ],
                [
                  "3",
                  "TENX98",
                  "Spatial CLIP (Ours)",
                  "0.7553061224489795",
                  "0.7522318143840588",
                  "0.8559677524988538",
                  "0.8552661088981086",
                  "0.2539229966669666",
                  "0.4980175560084534",
                  "0.18795550441120062",
                  "4900",
                  "26070",
                  "3700.9999999999995",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Replicate 2",
                  null,
                  null,
                  "0.2125",
                  "0.2125",
                  "51458",
                  "111225"
                ],
                [
                  "4",
                  "TENX97",
                  "OmiCLIP (Baseline)",
                  "0.7728077945084145",
                  "0.769436919643642",
                  "0.8237379423429221",
                  "0.8071877885794865",
                  "0.2592927752816645",
                  "0.4830795199725079",
                  "0.1906289573659772",
                  "2258",
                  "11845",
                  "1745.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Tissue sample 1",
                  null,
                  null,
                  "0.2125",
                  "0.2125",
                  "48441",
                  "53833"
                ],
                [
                  "5",
                  "TENX97",
                  "Spatial CLIP (Ours)",
                  "0.6868910540301152",
                  "0.6857703879715688",
                  "0.8132909803429298",
                  "0.8254291793236879",
                  "0.1851970304209538",
                  "0.4976709316840435",
                  "0.1906289573659772",
                  "2258",
                  "11845",
                  "1551.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Tissue sample 1",
                  null,
                  null,
                  "0.2125",
                  "0.2125",
                  "48441",
                  "53833"
                ],
                [
                  "6",
                  "TENX96",
                  "OmiCLIP (Baseline)",
                  "0.8232789212207239",
                  "0.8228978839322489",
                  "0.8864456981664316",
                  "0.8741499953266518",
                  "0.30644388216619717",
                  "0.4748355217472603",
                  "0.19480160376054195",
                  "1409",
                  "7233",
                  "1160.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "ILC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Tissue sample 2",
                  null,
                  null,
                  "0.2125",
                  "0.2125",
                  "45749",
                  "41411"
                ],
                [
                  "7",
                  "TENX96",
                  "Spatial CLIP (Ours)",
                  "0.8112136266855926",
                  "0.8094784083872593",
                  "0.9184031835583317",
                  "0.9206269728710966",
                  "0.30957116109416194",
                  "0.49729768448915557",
                  "0.19480160376054195",
                  "1409",
                  "7233",
                  "1143.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "ILC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Tissue sample 2",
                  null,
                  null,
                  "0.2125",
                  "0.2125",
                  "45749",
                  "41411"
                ],
                [
                  "8",
                  "TENX95",
                  "OmiCLIP (Baseline)",
                  "0.7795698924731183",
                  "0.7795599749317729",
                  "0.8397905654011151",
                  "0.8279864367127808",
                  "0.26378610975853434",
                  "0.4791619978833833",
                  "0.1884339383706205",
                  "2232",
                  "11845",
                  "1740.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Tissue sample 1",
                  null,
                  null,
                  "1.0",
                  "0.2125",
                  "48376",
                  "53738"
                ],
                [
                  "9",
                  "TENX95",
                  "Spatial CLIP (Ours)",
                  "0.7110215053763441",
                  "0.7106799293374519",
                  "0.827793465511978",
                  "0.8363964222519856",
                  "0.20927640058661023",
                  "0.4974990032861982",
                  "0.1884339383706205",
                  "2232",
                  "11845",
                  "1587.0",
                  "Breast",
                  "Homo sapiens",
                  "Cancer",
                  "IDC",
                  "Xenium",
                  "FFPE",
                  "541",
                  "2023-01-22",
                  "Creative Commons Attribution",
                  "Breast",
                  "Tissue sample 1",
                  null,
                  null,
                  "1.0",
                  "0.2125",
                  "48376",
                  "53738"
                ]
              ],
              "shape": {
                "columns": 29,
                "rows": 10
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>auroc_macro_ovr</th>\n",
              "      <th>auprc_macro_ovr</th>\n",
              "      <th>ece_15bin</th>\n",
              "      <th>brier</th>\n",
              "      <th>coverage</th>\n",
              "      <th>n_eval_spots</th>\n",
              "      <th>...</th>\n",
              "      <th>data_publication_date</th>\n",
              "      <th>license</th>\n",
              "      <th>tissue</th>\n",
              "      <th>subseries</th>\n",
              "      <th>inter_spot_dist</th>\n",
              "      <th>spot_diameter</th>\n",
              "      <th>pixel_size_um_embedded</th>\n",
              "      <th>pixel_size_um_estimated</th>\n",
              "      <th>fullres_px_width</th>\n",
              "      <th>fullres_px_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TENX99</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>0.660925</td>\n",
              "      <td>0.660998</td>\n",
              "      <td>0.712306</td>\n",
              "      <td>0.695356</td>\n",
              "      <td>0.150564</td>\n",
              "      <td>0.490700</td>\n",
              "      <td>0.183781</td>\n",
              "      <td>4238</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Replicate 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>51351</td>\n",
              "      <td>107121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TENX99</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>0.756489</td>\n",
              "      <td>0.748801</td>\n",
              "      <td>0.871883</td>\n",
              "      <td>0.869170</td>\n",
              "      <td>0.254911</td>\n",
              "      <td>0.497877</td>\n",
              "      <td>0.183781</td>\n",
              "      <td>4238</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Replicate 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>51351</td>\n",
              "      <td>107121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TENX98</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>0.643265</td>\n",
              "      <td>0.636417</td>\n",
              "      <td>0.704771</td>\n",
              "      <td>0.690385</td>\n",
              "      <td>0.130107</td>\n",
              "      <td>0.489875</td>\n",
              "      <td>0.187956</td>\n",
              "      <td>4900</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Replicate 2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>51458</td>\n",
              "      <td>111225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TENX98</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>0.755306</td>\n",
              "      <td>0.752232</td>\n",
              "      <td>0.855968</td>\n",
              "      <td>0.855266</td>\n",
              "      <td>0.253923</td>\n",
              "      <td>0.498018</td>\n",
              "      <td>0.187956</td>\n",
              "      <td>4900</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Replicate 2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>51458</td>\n",
              "      <td>111225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TENX97</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>0.772808</td>\n",
              "      <td>0.769437</td>\n",
              "      <td>0.823738</td>\n",
              "      <td>0.807188</td>\n",
              "      <td>0.259293</td>\n",
              "      <td>0.483080</td>\n",
              "      <td>0.190629</td>\n",
              "      <td>2258</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Tissue sample 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>48441</td>\n",
              "      <td>53833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TENX97</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>0.686891</td>\n",
              "      <td>0.685770</td>\n",
              "      <td>0.813291</td>\n",
              "      <td>0.825429</td>\n",
              "      <td>0.185197</td>\n",
              "      <td>0.497671</td>\n",
              "      <td>0.190629</td>\n",
              "      <td>2258</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Tissue sample 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>48441</td>\n",
              "      <td>53833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TENX96</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>0.823279</td>\n",
              "      <td>0.822898</td>\n",
              "      <td>0.886446</td>\n",
              "      <td>0.874150</td>\n",
              "      <td>0.306444</td>\n",
              "      <td>0.474836</td>\n",
              "      <td>0.194802</td>\n",
              "      <td>1409</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Tissue sample 2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>45749</td>\n",
              "      <td>41411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TENX96</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>0.811214</td>\n",
              "      <td>0.809478</td>\n",
              "      <td>0.918403</td>\n",
              "      <td>0.920627</td>\n",
              "      <td>0.309571</td>\n",
              "      <td>0.497298</td>\n",
              "      <td>0.194802</td>\n",
              "      <td>1409</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Tissue sample 2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>45749</td>\n",
              "      <td>41411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TENX95</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>0.779570</td>\n",
              "      <td>0.779560</td>\n",
              "      <td>0.839791</td>\n",
              "      <td>0.827986</td>\n",
              "      <td>0.263786</td>\n",
              "      <td>0.479162</td>\n",
              "      <td>0.188434</td>\n",
              "      <td>2232</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Tissue sample 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>48376</td>\n",
              "      <td>53738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TENX95</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>0.711022</td>\n",
              "      <td>0.710680</td>\n",
              "      <td>0.827793</td>\n",
              "      <td>0.836396</td>\n",
              "      <td>0.209276</td>\n",
              "      <td>0.497499</td>\n",
              "      <td>0.188434</td>\n",
              "      <td>2232</td>\n",
              "      <td>...</td>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>Creative Commons Attribution</td>\n",
              "      <td>Breast</td>\n",
              "      <td>Tissue sample 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>48376</td>\n",
              "      <td>53738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  sample_id                model  accuracy  f1_weighted  auroc_macro_ovr  \\\n",
              "0    TENX99   OmiCLIP (Baseline)  0.660925     0.660998         0.712306   \n",
              "1    TENX99  Spatial CLIP (Ours)  0.756489     0.748801         0.871883   \n",
              "2    TENX98   OmiCLIP (Baseline)  0.643265     0.636417         0.704771   \n",
              "3    TENX98  Spatial CLIP (Ours)  0.755306     0.752232         0.855968   \n",
              "4    TENX97   OmiCLIP (Baseline)  0.772808     0.769437         0.823738   \n",
              "5    TENX97  Spatial CLIP (Ours)  0.686891     0.685770         0.813291   \n",
              "6    TENX96   OmiCLIP (Baseline)  0.823279     0.822898         0.886446   \n",
              "7    TENX96  Spatial CLIP (Ours)  0.811214     0.809478         0.918403   \n",
              "8    TENX95   OmiCLIP (Baseline)  0.779570     0.779560         0.839791   \n",
              "9    TENX95  Spatial CLIP (Ours)  0.711022     0.710680         0.827793   \n",
              "\n",
              "   auprc_macro_ovr  ece_15bin     brier  coverage  n_eval_spots  ...  \\\n",
              "0         0.695356   0.150564  0.490700  0.183781          4238  ...   \n",
              "1         0.869170   0.254911  0.497877  0.183781          4238  ...   \n",
              "2         0.690385   0.130107  0.489875  0.187956          4900  ...   \n",
              "3         0.855266   0.253923  0.498018  0.187956          4900  ...   \n",
              "4         0.807188   0.259293  0.483080  0.190629          2258  ...   \n",
              "5         0.825429   0.185197  0.497671  0.190629          2258  ...   \n",
              "6         0.874150   0.306444  0.474836  0.194802          1409  ...   \n",
              "7         0.920627   0.309571  0.497298  0.194802          1409  ...   \n",
              "8         0.827986   0.263786  0.479162  0.188434          2232  ...   \n",
              "9         0.836396   0.209276  0.497499  0.188434          2232  ...   \n",
              "\n",
              "   data_publication_date                       license  tissue  \\\n",
              "0             2023-01-22  Creative Commons Attribution  Breast   \n",
              "1             2023-01-22  Creative Commons Attribution  Breast   \n",
              "2             2023-01-22  Creative Commons Attribution  Breast   \n",
              "3             2023-01-22  Creative Commons Attribution  Breast   \n",
              "4             2023-01-22  Creative Commons Attribution  Breast   \n",
              "5             2023-01-22  Creative Commons Attribution  Breast   \n",
              "6             2023-01-22  Creative Commons Attribution  Breast   \n",
              "7             2023-01-22  Creative Commons Attribution  Breast   \n",
              "8             2023-01-22  Creative Commons Attribution  Breast   \n",
              "9             2023-01-22  Creative Commons Attribution  Breast   \n",
              "\n",
              "         subseries inter_spot_dist spot_diameter pixel_size_um_embedded  \\\n",
              "0      Replicate 1             NaN           NaN                 1.0000   \n",
              "1      Replicate 1             NaN           NaN                 1.0000   \n",
              "2      Replicate 2             NaN           NaN                 0.2125   \n",
              "3      Replicate 2             NaN           NaN                 0.2125   \n",
              "4  Tissue sample 1             NaN           NaN                 0.2125   \n",
              "5  Tissue sample 1             NaN           NaN                 0.2125   \n",
              "6  Tissue sample 2             NaN           NaN                 0.2125   \n",
              "7  Tissue sample 2             NaN           NaN                 0.2125   \n",
              "8  Tissue sample 1             NaN           NaN                 1.0000   \n",
              "9  Tissue sample 1             NaN           NaN                 1.0000   \n",
              "\n",
              "  pixel_size_um_estimated  fullres_px_width fullres_px_height  \n",
              "0                  0.2125             51351            107121  \n",
              "1                  0.2125             51351            107121  \n",
              "2                  0.2125             51458            111225  \n",
              "3                  0.2125             51458            111225  \n",
              "4                  0.2125             48441             53833  \n",
              "5                  0.2125             48441             53833  \n",
              "6                  0.2125             45749             41411  \n",
              "7                  0.2125             45749             41411  \n",
              "8                  0.2125             48376             53738  \n",
              "9                  0.2125             48376             53738  \n",
              "\n",
              "[10 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== åˆ†ç»„æ±‡æ€»ï¼ˆå¹³å°/è‚¿ç˜¤ç±»å‹/ä¿å­˜æ–¹å¼ï¼‰===\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "group_by",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "st_technology",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "model",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "n_samples",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "global_n_eval_spots",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "global_accuracy_weighted",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_accuracy",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_f1_weighted",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_auroc_macro_ovr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_auprc_macro_ovr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_ece_15bin",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_brier",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "oncotree_code",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "preservation_method",
                  "rawType": "object",
                  "type": "unknown"
                }
              ],
              "ref": "d361238d-b672-4936-8372-394d46610c99",
              "rows": [
                [
                  "0",
                  "st_technology",
                  "Spatial Transcriptomics",
                  "OmiCLIP (Baseline)",
                  "40",
                  "2192",
                  "0.6587591240875912",
                  "0.6372811574037447",
                  "0.6275785687883648",
                  "0.6361442575395108",
                  "0.6530659576285929",
                  "0.14332822187551647",
                  "0.47968063068992295",
                  null,
                  null
                ],
                [
                  "1",
                  "st_technology",
                  "Visium",
                  "OmiCLIP (Baseline)",
                  "8",
                  "4970",
                  "0.6843058350100604",
                  "0.6893432249834316",
                  "0.6845179337928542",
                  "0.7841929147348733",
                  "0.7650256330251246",
                  "0.1751794846345898",
                  "0.48434636893886607",
                  null,
                  null
                ],
                [
                  "2",
                  "st_technology",
                  "Xenium",
                  "OmiCLIP (Baseline)",
                  "9",
                  "19132",
                  "0.7131507422120008",
                  "0.7314972171661864",
                  "0.7177197670444306",
                  "0.8138660105791123",
                  "0.8019677513530374",
                  "0.22723178013505388",
                  "0.4827627743051969",
                  null,
                  null
                ],
                [
                  "3",
                  "st_technology",
                  "Spatial Transcriptomics",
                  "Spatial CLIP (Ours)",
                  "40",
                  "2192",
                  "0.771441605839416",
                  "0.7476872283765866",
                  "0.7126624574407914",
                  "0.8529252475233804",
                  "0.8389534252454702",
                  "0.23494267101577856",
                  "0.4840061993037789",
                  null,
                  null
                ],
                [
                  "4",
                  "st_technology",
                  "Visium",
                  "Spatial CLIP (Ours)",
                  "8",
                  "4970",
                  "0.7955734406438632",
                  "0.7997737174403409",
                  "0.7936643889635667",
                  "0.8684346015896973",
                  "0.843212476532399",
                  "0.29773004553434645",
                  "0.4966481983730431",
                  null,
                  null
                ],
                [
                  "5",
                  "st_technology",
                  "Xenium",
                  "Spatial CLIP (Ours)",
                  "9",
                  "19132",
                  "0.7404348735103492",
                  "0.7351388505518127",
                  "0.720870127992493",
                  "0.8675128841347987",
                  "0.8696610735646266",
                  "0.23316877134174327",
                  "0.4972395437816251",
                  null,
                  null
                ],
                [
                  "6",
                  "oncotree_code",
                  null,
                  "OmiCLIP (Baseline)",
                  "53",
                  "21816",
                  "0.6895856252291895",
                  "0.6531173790107846",
                  "0.6424972249251284",
                  "0.676208948121266",
                  "0.6842751049552546",
                  "0.1558913730582267",
                  "0.4807362750934917",
                  "IDC",
                  null
                ],
                [
                  "7",
                  "oncotree_code",
                  null,
                  "OmiCLIP (Baseline)",
                  "4",
                  "4478",
                  "0.7693166592228674",
                  "0.7435614907353364",
                  "0.7466028010613727",
                  "0.8112745387065231",
                  "0.7984931422233901",
                  "0.22935200030671135",
                  "0.4819596419748896",
                  "ILC",
                  null
                ],
                [
                  "8",
                  "oncotree_code",
                  null,
                  "Spatial CLIP (Ours)",
                  "53",
                  "21816",
                  "0.7535753575357536",
                  "0.7535393122528542",
                  "0.723808019339131",
                  "0.8586178052354867",
                  "0.8450230550436009",
                  "0.24338256419794202",
                  "0.4871024577332135",
                  "IDC",
                  null
                ],
                [
                  "9",
                  "oncotree_code",
                  null,
                  "Spatial CLIP (Ours)",
                  "4",
                  "4478",
                  "0.7527914247431889",
                  "0.7460862450378074",
                  "0.7454548840746688",
                  "0.8427628877743245",
                  "0.836141141712197",
                  "0.2446975611226691",
                  "0.498039798327453",
                  "ILC",
                  null
                ],
                [
                  "10",
                  "preservation_method",
                  null,
                  "OmiCLIP (Baseline)",
                  "10",
                  "19636",
                  "0.7104298227744958",
                  "0.7190617811638536",
                  "0.7006207554562666",
                  "0.8115452951347057",
                  "0.8010931706254224",
                  "0.21342325415074864",
                  "0.48312319582405355",
                  null,
                  "FFPE"
                ],
                [
                  "11",
                  "preservation_method",
                  null,
                  "OmiCLIP (Baseline)",
                  "43",
                  "6457",
                  "0.6848381601362862",
                  "0.6529771918818079",
                  "0.6467405862207631",
                  "0.6573384124163733",
                  "0.6685027665327133",
                  "0.15751517716966512",
                  "0.47906169870236187",
                  null,
                  "Fresh Frozen"
                ],
                [
                  "12",
                  "preservation_method",
                  null,
                  "Spatial CLIP (Ours)",
                  "10",
                  "19636",
                  "0.7451619474434712",
                  "0.754085282956949",
                  "0.7412089634887431",
                  "0.8803773679561386",
                  "0.8823215240283726",
                  "0.25208654252230234",
                  "0.4970848450055362",
                  null,
                  "FFPE"
                ],
                [
                  "13",
                  "preservation_method",
                  null,
                  "Spatial CLIP (Ours)",
                  "43",
                  "6457",
                  "0.7819420783645656",
                  "0.7626963773646308",
                  "0.7329351797476732",
                  "0.8516540487582743",
                  "0.8331073716762791",
                  "0.2507187842605862",
                  "0.48478651359134484",
                  null,
                  "Fresh Frozen"
                ]
              ],
              "shape": {
                "columns": 14,
                "rows": 14
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group_by</th>\n",
              "      <th>st_technology</th>\n",
              "      <th>model</th>\n",
              "      <th>n_samples</th>\n",
              "      <th>global_n_eval_spots</th>\n",
              "      <th>global_accuracy_weighted</th>\n",
              "      <th>macro_accuracy</th>\n",
              "      <th>macro_f1_weighted</th>\n",
              "      <th>macro_auroc_macro_ovr</th>\n",
              "      <th>macro_auprc_macro_ovr</th>\n",
              "      <th>macro_ece_15bin</th>\n",
              "      <th>macro_brier</th>\n",
              "      <th>oncotree_code</th>\n",
              "      <th>preservation_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>st_technology</td>\n",
              "      <td>Spatial Transcriptomics</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>40</td>\n",
              "      <td>2192</td>\n",
              "      <td>0.658759</td>\n",
              "      <td>0.637281</td>\n",
              "      <td>0.627579</td>\n",
              "      <td>0.636144</td>\n",
              "      <td>0.653066</td>\n",
              "      <td>0.143328</td>\n",
              "      <td>0.479681</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>st_technology</td>\n",
              "      <td>Visium</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>8</td>\n",
              "      <td>4970</td>\n",
              "      <td>0.684306</td>\n",
              "      <td>0.689343</td>\n",
              "      <td>0.684518</td>\n",
              "      <td>0.784193</td>\n",
              "      <td>0.765026</td>\n",
              "      <td>0.175179</td>\n",
              "      <td>0.484346</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>st_technology</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>9</td>\n",
              "      <td>19132</td>\n",
              "      <td>0.713151</td>\n",
              "      <td>0.731497</td>\n",
              "      <td>0.717720</td>\n",
              "      <td>0.813866</td>\n",
              "      <td>0.801968</td>\n",
              "      <td>0.227232</td>\n",
              "      <td>0.482763</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>st_technology</td>\n",
              "      <td>Spatial Transcriptomics</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>40</td>\n",
              "      <td>2192</td>\n",
              "      <td>0.771442</td>\n",
              "      <td>0.747687</td>\n",
              "      <td>0.712662</td>\n",
              "      <td>0.852925</td>\n",
              "      <td>0.838953</td>\n",
              "      <td>0.234943</td>\n",
              "      <td>0.484006</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>st_technology</td>\n",
              "      <td>Visium</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>8</td>\n",
              "      <td>4970</td>\n",
              "      <td>0.795573</td>\n",
              "      <td>0.799774</td>\n",
              "      <td>0.793664</td>\n",
              "      <td>0.868435</td>\n",
              "      <td>0.843212</td>\n",
              "      <td>0.297730</td>\n",
              "      <td>0.496648</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>st_technology</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>9</td>\n",
              "      <td>19132</td>\n",
              "      <td>0.740435</td>\n",
              "      <td>0.735139</td>\n",
              "      <td>0.720870</td>\n",
              "      <td>0.867513</td>\n",
              "      <td>0.869661</td>\n",
              "      <td>0.233169</td>\n",
              "      <td>0.497240</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>oncotree_code</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>53</td>\n",
              "      <td>21816</td>\n",
              "      <td>0.689586</td>\n",
              "      <td>0.653117</td>\n",
              "      <td>0.642497</td>\n",
              "      <td>0.676209</td>\n",
              "      <td>0.684275</td>\n",
              "      <td>0.155891</td>\n",
              "      <td>0.480736</td>\n",
              "      <td>IDC</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>oncotree_code</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>4</td>\n",
              "      <td>4478</td>\n",
              "      <td>0.769317</td>\n",
              "      <td>0.743561</td>\n",
              "      <td>0.746603</td>\n",
              "      <td>0.811275</td>\n",
              "      <td>0.798493</td>\n",
              "      <td>0.229352</td>\n",
              "      <td>0.481960</td>\n",
              "      <td>ILC</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>oncotree_code</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>53</td>\n",
              "      <td>21816</td>\n",
              "      <td>0.753575</td>\n",
              "      <td>0.753539</td>\n",
              "      <td>0.723808</td>\n",
              "      <td>0.858618</td>\n",
              "      <td>0.845023</td>\n",
              "      <td>0.243383</td>\n",
              "      <td>0.487102</td>\n",
              "      <td>IDC</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>oncotree_code</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>4</td>\n",
              "      <td>4478</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.746086</td>\n",
              "      <td>0.745455</td>\n",
              "      <td>0.842763</td>\n",
              "      <td>0.836141</td>\n",
              "      <td>0.244698</td>\n",
              "      <td>0.498040</td>\n",
              "      <td>ILC</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>preservation_method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>10</td>\n",
              "      <td>19636</td>\n",
              "      <td>0.710430</td>\n",
              "      <td>0.719062</td>\n",
              "      <td>0.700621</td>\n",
              "      <td>0.811545</td>\n",
              "      <td>0.801093</td>\n",
              "      <td>0.213423</td>\n",
              "      <td>0.483123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>preservation_method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>43</td>\n",
              "      <td>6457</td>\n",
              "      <td>0.684838</td>\n",
              "      <td>0.652977</td>\n",
              "      <td>0.646741</td>\n",
              "      <td>0.657338</td>\n",
              "      <td>0.668503</td>\n",
              "      <td>0.157515</td>\n",
              "      <td>0.479062</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fresh Frozen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>preservation_method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>10</td>\n",
              "      <td>19636</td>\n",
              "      <td>0.745162</td>\n",
              "      <td>0.754085</td>\n",
              "      <td>0.741209</td>\n",
              "      <td>0.880377</td>\n",
              "      <td>0.882322</td>\n",
              "      <td>0.252087</td>\n",
              "      <td>0.497085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>preservation_method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>43</td>\n",
              "      <td>6457</td>\n",
              "      <td>0.781942</td>\n",
              "      <td>0.762696</td>\n",
              "      <td>0.732935</td>\n",
              "      <td>0.851654</td>\n",
              "      <td>0.833107</td>\n",
              "      <td>0.250719</td>\n",
              "      <td>0.484787</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fresh Frozen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               group_by            st_technology                model  \\\n",
              "0         st_technology  Spatial Transcriptomics   OmiCLIP (Baseline)   \n",
              "1         st_technology                   Visium   OmiCLIP (Baseline)   \n",
              "2         st_technology                   Xenium   OmiCLIP (Baseline)   \n",
              "3         st_technology  Spatial Transcriptomics  Spatial CLIP (Ours)   \n",
              "4         st_technology                   Visium  Spatial CLIP (Ours)   \n",
              "5         st_technology                   Xenium  Spatial CLIP (Ours)   \n",
              "6         oncotree_code                      NaN   OmiCLIP (Baseline)   \n",
              "7         oncotree_code                      NaN   OmiCLIP (Baseline)   \n",
              "8         oncotree_code                      NaN  Spatial CLIP (Ours)   \n",
              "9         oncotree_code                      NaN  Spatial CLIP (Ours)   \n",
              "10  preservation_method                      NaN   OmiCLIP (Baseline)   \n",
              "11  preservation_method                      NaN   OmiCLIP (Baseline)   \n",
              "12  preservation_method                      NaN  Spatial CLIP (Ours)   \n",
              "13  preservation_method                      NaN  Spatial CLIP (Ours)   \n",
              "\n",
              "    n_samples  global_n_eval_spots  global_accuracy_weighted  macro_accuracy  \\\n",
              "0          40                 2192                  0.658759        0.637281   \n",
              "1           8                 4970                  0.684306        0.689343   \n",
              "2           9                19132                  0.713151        0.731497   \n",
              "3          40                 2192                  0.771442        0.747687   \n",
              "4           8                 4970                  0.795573        0.799774   \n",
              "5           9                19132                  0.740435        0.735139   \n",
              "6          53                21816                  0.689586        0.653117   \n",
              "7           4                 4478                  0.769317        0.743561   \n",
              "8          53                21816                  0.753575        0.753539   \n",
              "9           4                 4478                  0.752791        0.746086   \n",
              "10         10                19636                  0.710430        0.719062   \n",
              "11         43                 6457                  0.684838        0.652977   \n",
              "12         10                19636                  0.745162        0.754085   \n",
              "13         43                 6457                  0.781942        0.762696   \n",
              "\n",
              "    macro_f1_weighted  macro_auroc_macro_ovr  macro_auprc_macro_ovr  \\\n",
              "0            0.627579               0.636144               0.653066   \n",
              "1            0.684518               0.784193               0.765026   \n",
              "2            0.717720               0.813866               0.801968   \n",
              "3            0.712662               0.852925               0.838953   \n",
              "4            0.793664               0.868435               0.843212   \n",
              "5            0.720870               0.867513               0.869661   \n",
              "6            0.642497               0.676209               0.684275   \n",
              "7            0.746603               0.811275               0.798493   \n",
              "8            0.723808               0.858618               0.845023   \n",
              "9            0.745455               0.842763               0.836141   \n",
              "10           0.700621               0.811545               0.801093   \n",
              "11           0.646741               0.657338               0.668503   \n",
              "12           0.741209               0.880377               0.882322   \n",
              "13           0.732935               0.851654               0.833107   \n",
              "\n",
              "    macro_ece_15bin  macro_brier oncotree_code preservation_method  \n",
              "0          0.143328     0.479681           NaN                 NaN  \n",
              "1          0.175179     0.484346           NaN                 NaN  \n",
              "2          0.227232     0.482763           NaN                 NaN  \n",
              "3          0.234943     0.484006           NaN                 NaN  \n",
              "4          0.297730     0.496648           NaN                 NaN  \n",
              "5          0.233169     0.497240           NaN                 NaN  \n",
              "6          0.155891     0.480736           IDC                 NaN  \n",
              "7          0.229352     0.481960           ILC                 NaN  \n",
              "8          0.243383     0.487102           IDC                 NaN  \n",
              "9          0.244698     0.498040           ILC                 NaN  \n",
              "10         0.213423     0.483123           NaN                FFPE  \n",
              "11         0.157515     0.479062           NaN        Fresh Frozen  \n",
              "12         0.252087     0.497085           NaN                FFPE  \n",
              "13         0.250719     0.484787           NaN        Fresh Frozen  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== å…¨å±€æ±‡æ€» ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "model",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "global_n_eval_spots",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "global_accuracy_weighted",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_accuracy",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_f1_weighted",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_auroc_macro_ovr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_auprc_macro_ovr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_ece_15bin",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "macro_brier",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "n_samples",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "60360f2e-1dae-4dee-9e0f-c9ee38da04f8",
              "rows": [
                [
                  "0",
                  "OmiCLIP (Baseline)",
                  "26294",
                  "0.7031642199741386",
                  "0.659464334219525",
                  "0.6498028793908298",
                  "0.6858564903059271",
                  "0.6922904058161764",
                  "0.16104650479496252",
                  "0.4808221254009582",
                  "57"
                ],
                [
                  "1",
                  "Spatial CLIP (Ours)",
                  "26294",
                  "0.7534418498516772",
                  "0.7530162899921492",
                  "0.7253270975661864",
                  "0.8574853111311179",
                  "0.8443997628799935",
                  "0.24347484468388778",
                  "0.48786999040649337",
                  "57"
                ]
              ],
              "shape": {
                "columns": 10,
                "rows": 2
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>global_n_eval_spots</th>\n",
              "      <th>global_accuracy_weighted</th>\n",
              "      <th>macro_accuracy</th>\n",
              "      <th>macro_f1_weighted</th>\n",
              "      <th>macro_auroc_macro_ovr</th>\n",
              "      <th>macro_auprc_macro_ovr</th>\n",
              "      <th>macro_ece_15bin</th>\n",
              "      <th>macro_brier</th>\n",
              "      <th>n_samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>26294</td>\n",
              "      <td>0.703164</td>\n",
              "      <td>0.659464</td>\n",
              "      <td>0.649803</td>\n",
              "      <td>0.685856</td>\n",
              "      <td>0.69229</td>\n",
              "      <td>0.161047</td>\n",
              "      <td>0.480822</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>26294</td>\n",
              "      <td>0.753442</td>\n",
              "      <td>0.753016</td>\n",
              "      <td>0.725327</td>\n",
              "      <td>0.857485</td>\n",
              "      <td>0.84440</td>\n",
              "      <td>0.243475</td>\n",
              "      <td>0.487870</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  global_n_eval_spots  global_accuracy_weighted  \\\n",
              "0   OmiCLIP (Baseline)                26294                  0.703164   \n",
              "1  Spatial CLIP (Ours)                26294                  0.753442   \n",
              "\n",
              "   macro_accuracy  macro_f1_weighted  macro_auroc_macro_ovr  \\\n",
              "0        0.659464           0.649803               0.685856   \n",
              "1        0.753016           0.725327               0.857485   \n",
              "\n",
              "   macro_auprc_macro_ovr  macro_ece_15bin  macro_brier  n_samples  \n",
              "0                0.69229         0.161047     0.480822         57  \n",
              "1                0.84440         0.243475     0.487870         57  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== McNemarï¼ˆæ¯æ ·æœ¬ï¼‰===\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sample_id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "model_A",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "model_B",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "a_both_correct",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "b_A_wrong_B_right",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "c_A_right_B_wrong",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "d_both_wrong",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "n_discordant",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "p_value",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "st_technology",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "oncotree_code",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "preservation_method",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "4f0f0840-048f-4dcc-a309-4589671cae87",
              "rows": [
                [
                  "0",
                  "TENX99",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "2315",
                  "891",
                  "486",
                  "546",
                  "1377",
                  "1.3272217117255187e-27",
                  "Xenium",
                  "IDC",
                  "FFPE"
                ],
                [
                  "1",
                  "TENX98",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "2430",
                  "1271",
                  "722",
                  "477",
                  "1993",
                  "1.231589769804324e-34",
                  "Xenium",
                  "IDC",
                  "FFPE"
                ],
                [
                  "2",
                  "TENX97",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "1229",
                  "322",
                  "516",
                  "191",
                  "838",
                  "2.6095287781133884e-11",
                  "Xenium",
                  "IDC",
                  "FFPE"
                ],
                [
                  "3",
                  "TENX96",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "995",
                  "148",
                  "165",
                  "101",
                  "313",
                  "0.3657974007355351",
                  "Xenium",
                  "ILC",
                  "FFPE"
                ],
                [
                  "4",
                  "TENX95",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "1256",
                  "331",
                  "484",
                  "161",
                  "815",
                  "1.013270522787346e-07",
                  "Xenium",
                  "IDC",
                  "FFPE"
                ],
                [
                  "5",
                  "TENX94",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "1045",
                  "206",
                  "321",
                  "143",
                  "527",
                  "6.837684492119023e-07",
                  "Xenium",
                  "ILC",
                  "FFPE"
                ],
                [
                  "6",
                  "TENX68",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "258",
                  "17",
                  "6",
                  "6",
                  "23",
                  "0.03468966484069824",
                  "Visium",
                  "IDC",
                  "Fresh Frozen"
                ],
                [
                  "7",
                  "TENX53",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "304",
                  "203",
                  "91",
                  "52",
                  "294",
                  "9.566242581260698e-11",
                  "Visium",
                  "IDC",
                  "Fresh Frozen"
                ],
                [
                  "8",
                  "TENX39",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "293",
                  "173",
                  "13",
                  "25",
                  "186",
                  "2.078011853428552e-31",
                  "Visium",
                  "IDC",
                  "FFPE"
                ],
                [
                  "9",
                  "TENX24",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "390",
                  "125",
                  "114",
                  "89",
                  "239",
                  "0.5177314704874408",
                  "Visium",
                  "ILC",
                  "Fresh Frozen"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 10
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>model_A</th>\n",
              "      <th>model_B</th>\n",
              "      <th>a_both_correct</th>\n",
              "      <th>b_A_wrong_B_right</th>\n",
              "      <th>c_A_right_B_wrong</th>\n",
              "      <th>d_both_wrong</th>\n",
              "      <th>n_discordant</th>\n",
              "      <th>p_value</th>\n",
              "      <th>st_technology</th>\n",
              "      <th>oncotree_code</th>\n",
              "      <th>preservation_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TENX99</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>2315</td>\n",
              "      <td>891</td>\n",
              "      <td>486</td>\n",
              "      <td>546</td>\n",
              "      <td>1377</td>\n",
              "      <td>1.327222e-27</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TENX98</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>2430</td>\n",
              "      <td>1271</td>\n",
              "      <td>722</td>\n",
              "      <td>477</td>\n",
              "      <td>1993</td>\n",
              "      <td>1.231590e-34</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TENX97</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>1229</td>\n",
              "      <td>322</td>\n",
              "      <td>516</td>\n",
              "      <td>191</td>\n",
              "      <td>838</td>\n",
              "      <td>2.609529e-11</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TENX96</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>995</td>\n",
              "      <td>148</td>\n",
              "      <td>165</td>\n",
              "      <td>101</td>\n",
              "      <td>313</td>\n",
              "      <td>3.657974e-01</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>ILC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TENX95</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>1256</td>\n",
              "      <td>331</td>\n",
              "      <td>484</td>\n",
              "      <td>161</td>\n",
              "      <td>815</td>\n",
              "      <td>1.013271e-07</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TENX94</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>1045</td>\n",
              "      <td>206</td>\n",
              "      <td>321</td>\n",
              "      <td>143</td>\n",
              "      <td>527</td>\n",
              "      <td>6.837684e-07</td>\n",
              "      <td>Xenium</td>\n",
              "      <td>ILC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TENX68</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>258</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>3.468966e-02</td>\n",
              "      <td>Visium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>Fresh Frozen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TENX53</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>304</td>\n",
              "      <td>203</td>\n",
              "      <td>91</td>\n",
              "      <td>52</td>\n",
              "      <td>294</td>\n",
              "      <td>9.566243e-11</td>\n",
              "      <td>Visium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>Fresh Frozen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TENX39</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>293</td>\n",
              "      <td>173</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>186</td>\n",
              "      <td>2.078012e-31</td>\n",
              "      <td>Visium</td>\n",
              "      <td>IDC</td>\n",
              "      <td>FFPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TENX24</td>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>390</td>\n",
              "      <td>125</td>\n",
              "      <td>114</td>\n",
              "      <td>89</td>\n",
              "      <td>239</td>\n",
              "      <td>5.177315e-01</td>\n",
              "      <td>Visium</td>\n",
              "      <td>ILC</td>\n",
              "      <td>Fresh Frozen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sample_id             model_A              model_B  a_both_correct  \\\n",
              "0    TENX99  OmiCLIP (Baseline)  Spatial CLIP (Ours)            2315   \n",
              "1    TENX98  OmiCLIP (Baseline)  Spatial CLIP (Ours)            2430   \n",
              "2    TENX97  OmiCLIP (Baseline)  Spatial CLIP (Ours)            1229   \n",
              "3    TENX96  OmiCLIP (Baseline)  Spatial CLIP (Ours)             995   \n",
              "4    TENX95  OmiCLIP (Baseline)  Spatial CLIP (Ours)            1256   \n",
              "5    TENX94  OmiCLIP (Baseline)  Spatial CLIP (Ours)            1045   \n",
              "6    TENX68  OmiCLIP (Baseline)  Spatial CLIP (Ours)             258   \n",
              "7    TENX53  OmiCLIP (Baseline)  Spatial CLIP (Ours)             304   \n",
              "8    TENX39  OmiCLIP (Baseline)  Spatial CLIP (Ours)             293   \n",
              "9    TENX24  OmiCLIP (Baseline)  Spatial CLIP (Ours)             390   \n",
              "\n",
              "   b_A_wrong_B_right  c_A_right_B_wrong  d_both_wrong  n_discordant  \\\n",
              "0                891                486           546          1377   \n",
              "1               1271                722           477          1993   \n",
              "2                322                516           191           838   \n",
              "3                148                165           101           313   \n",
              "4                331                484           161           815   \n",
              "5                206                321           143           527   \n",
              "6                 17                  6             6            23   \n",
              "7                203                 91            52           294   \n",
              "8                173                 13            25           186   \n",
              "9                125                114            89           239   \n",
              "\n",
              "        p_value st_technology oncotree_code preservation_method  \n",
              "0  1.327222e-27        Xenium           IDC                FFPE  \n",
              "1  1.231590e-34        Xenium           IDC                FFPE  \n",
              "2  2.609529e-11        Xenium           IDC                FFPE  \n",
              "3  3.657974e-01        Xenium           ILC                FFPE  \n",
              "4  1.013271e-07        Xenium           IDC                FFPE  \n",
              "5  6.837684e-07        Xenium           ILC                FFPE  \n",
              "6  3.468966e-02        Visium           IDC        Fresh Frozen  \n",
              "7  9.566243e-11        Visium           IDC        Fresh Frozen  \n",
              "8  2.078012e-31        Visium           IDC                FFPE  \n",
              "9  5.177315e-01        Visium           ILC        Fresh Frozen  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== McNemarï¼ˆå…¨é˜Ÿåˆ— pooledï¼‰===\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "model_A",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "model_B",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "a_both_correct",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "b_A_wrong_B_right",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "c_A_right_B_wrong",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "d_both_wrong",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "n_discordant",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "p_value",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "ed2d6f98-d29c-4826-968b-e6bb36c3048c",
              "rows": [
                [
                  "0",
                  "OmiCLIP (Baseline)",
                  "Spatial CLIP (Ours)",
                  "14687",
                  "5124",
                  "3802",
                  "2681",
                  "8926",
                  "2.0030497195747256e-44"
                ]
              ],
              "shape": {
                "columns": 8,
                "rows": 1
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_A</th>\n",
              "      <th>model_B</th>\n",
              "      <th>a_both_correct</th>\n",
              "      <th>b_A_wrong_B_right</th>\n",
              "      <th>c_A_right_B_wrong</th>\n",
              "      <th>d_both_wrong</th>\n",
              "      <th>n_discordant</th>\n",
              "      <th>p_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OmiCLIP (Baseline)</td>\n",
              "      <td>Spatial CLIP (Ours)</td>\n",
              "      <td>14687</td>\n",
              "      <td>5124</td>\n",
              "      <td>3802</td>\n",
              "      <td>2681</td>\n",
              "      <td>8926</td>\n",
              "      <td>2.003050e-44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              model_A              model_B  a_both_correct  b_A_wrong_B_right  \\\n",
              "0  OmiCLIP (Baseline)  Spatial CLIP (Ours)           14687               5124   \n",
              "\n",
              "   c_A_right_B_wrong  d_both_wrong  n_discordant       p_value  \n",
              "0               3802          2681          8926  2.003050e-44  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # ç©ºé—´CLIPè¯„ä¼°ï¼šäººç±»ä¹³è…ºç™Œæ•´é˜Ÿåˆ—ï¼ˆå« AUROC/AUPRC/ECE/Brier & McNemarï¼‰\n",
        "# - ä¼ªæ ‡ç­¾ï¼šscanpy.tl.score_genes å¤šåŸºå› æ‰“åˆ† + åˆ†ä½é˜ˆå€¼ + ç½®ä¿¡è¾¹é™… + Unknown\n",
        "# - æŒ‡æ ‡ï¼šAccuracy/F1ï¼ˆå·²æœ‰ï¼‰+ AUROCï¼ˆmacro-OVRï¼‰/AUPRCï¼ˆmacro-OVRï¼‰/ECEï¼ˆmax prob, 15 binsï¼‰/Brierï¼ˆmulticlassï¼‰\n",
        "# - é…å¯¹æ£€éªŒï¼šMcNemarï¼ˆå¯¹å„æ¨¡å‹å¯¹åœ¨â€œæ˜¯å¦é¢„æµ‹æ­£ç¡®â€ä¸Šçš„å·®å¼‚è¿›è¡Œé…å¯¹ç»Ÿè®¡ï¼‰ï¼Œæä¾›æ¯æ ·æœ¬ä¸å…¨é˜Ÿåˆ—ï¼ˆpooledï¼‰på€¼\n",
        "\n",
        "# =========================\n",
        "# 1) å¯¼å…¥ä¸åŸºç¡€é…ç½®\n",
        "# =========================\n",
        "DRYRUN = False\n",
        "\n",
        "import os, sys, logging, glob\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple, List, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_auc_score, average_precision_score\n",
        ")\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from IPython.display import display\n",
        "\n",
        "# ç»Ÿè®¡åŒ…ï¼ˆMcNemarï¼‰\n",
        "try:\n",
        "    from statsmodels.stats.contingency_tables import mcnemar as sm_mcnemar\n",
        "    _HAS_STATSMODELS = True\n",
        "except Exception:\n",
        "    _HAS_STATSMODELS = False\n",
        "from scipy.stats import binomtest  # ä½œä¸ºæ—  statsmodels æ—¶çš„ç²¾ç¡®äºŒé¡¹æ£€éªŒæ›¿ä»£\n",
        "\n",
        "# é¡¹ç›®è·¯å¾„ä¸æœ¬åœ°åº“\n",
        "PROJECT_ROOT = Path(\"/home1/jijh/diffusion_project/git_repo/yuanspace\")\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "    print(f\"å·²å°† '{PROJECT_ROOT}' æ·»åŠ åˆ° sys.path\")\n",
        "\n",
        "import open_clip\n",
        "from src.spaglam_preproc.utils.hest_loading import HESTDataset, HESTSample  # å¤ç”¨ä½ çš„å®ç°\n",
        "\n",
        "# æ—¥å¿—\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# =========================\n",
        "# 2) è·¯å¾„ä¸æ¨¡å‹é…ç½®\n",
        "# =========================\n",
        "HEST_DATA_DIR = Path(\"/cwStorage/nodecw_group/jijh/hest_1k\")\n",
        "OUTPUT_DIR    = Path(\"/cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline\")\n",
        "\n",
        "BASELINE_MODEL_CKPT = Path(\"/cwStorage/nodecw_group/jijh/trained_models/omiclip_base_model/omiclip_epoch_50.pt\")\n",
        "SPATIAL_MODEL_CKPT  = Path(\"/cwStorage/nodecw_group/jijh/trained_models/spatial_clip_base_model/multi_positice_loss50.pt\")\n",
        "MODEL_NAME = \"ViT-B-32\"\n",
        "\n",
        "BATCH_SIZE  = 512\n",
        "NUM_WORKERS = 16\n",
        "DEVICE      = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODELS_TO_TEST = {\n",
        "    \"OmiCLIP (Baseline)\": {\"path\": BASELINE_MODEL_CKPT, \"model_name\": MODEL_NAME},\n",
        "    \"Spatial CLIP (Ours)\": {\"path\": SPATIAL_MODEL_CKPT, \"model_name\": MODEL_NAME},\n",
        "}\n",
        "\n",
        "if not DRYRUN:\n",
        "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "for name, cfg in MODELS_TO_TEST.items():\n",
        "    assert cfg[\"path\"].exists(), f\"[{name}] ckpt ä¸å­˜åœ¨: {cfg['path']}\"\n",
        "assert HEST_DATA_DIR.exists(), f\"HEST æ•°æ®ç›®å½•ä¸å­˜åœ¨: {HEST_DATA_DIR}\"\n",
        "\n",
        "# =========================\n",
        "# 3) WSI Patch Dataset\n",
        "# =========================\n",
        "class WSISpotDataset(Dataset):\n",
        "    \"\"\"æŒ‰ spot åæ ‡ä» WSI è¯»å– 224x224 patch\"\"\"\n",
        "    def __init__(self, wsi, coords, transform):\n",
        "        self.wsi = wsi\n",
        "        self.coords = coords\n",
        "        self.transform = transform\n",
        "        self.patch_size = (224, 224)\n",
        "        self.patch_radius = self.patch_size[0] // 2\n",
        "    def __len__(self): return len(self.coords)\n",
        "    def __getitem__(self, idx):\n",
        "        c = self.coords[idx]\n",
        "        top_left = (int(c[0] - self.patch_radius), int(c[1] - self.patch_radius))\n",
        "        tile = self.wsi.read_region(top_left, 0, self.patch_size).convert(\"RGB\")\n",
        "        if self.transform: tile = self.transform(tile)\n",
        "        return tile\n",
        "\n",
        "# =========================\n",
        "# 4) ä¼ªæ ‡ç­¾ï¼ˆé“¶æ ‡å‡†ï¼‰ï¼šscore_genes + åˆ†ä½é˜ˆå€¼ + ç½®ä¿¡è¾¹é™… + Unknown\n",
        "# =========================\n",
        "def ensure_log1p_layer(adata: sc.AnnData, layer_name: str = \"log1p\") -> None:\n",
        "    if layer_name in adata.layers: \n",
        "        return\n",
        "    sc.pp.normalize_total(adata, target_sum=1e4)  # CP10k\n",
        "    sc.pp.log1p(adata)\n",
        "    adata.layers[layer_name] = adata.X.copy()\n",
        "\n",
        "def create_silver_labels_scanpy(\n",
        "    adata: sc.AnnData,\n",
        "    marker_panels: Dict[str, List[str]],\n",
        "    layer: str = \"log1p\",\n",
        "    ctrl_size: int = 50,\n",
        "    q: float = 0.90,\n",
        "    margin_min: float = 0.30\n",
        ") -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"è¿”å› (labels, score_df)ï¼›labels å« Unknownã€‚\"\"\"\n",
        "    panels = {lbl: [g for g in genes if g in adata.var_names]\n",
        "              for lbl, genes in marker_panels.items()}\n",
        "    score_cols = []\n",
        "    for lbl, genes in panels.items():\n",
        "        if not genes:\n",
        "            logging.warning(f\"[{lbl}] æ— å¯ç”¨æ ‡è®°åŸºå› ï¼Œè·³è¿‡ã€‚\")\n",
        "            continue\n",
        "        col = f\"score__{lbl}\"\n",
        "        sc.tl.score_genes(adata, gene_list=genes, score_name=col,\n",
        "                          ctrl_size=ctrl_size, use_raw=False, layer=layer)\n",
        "        score_cols.append(col)\n",
        "    if not score_cols:\n",
        "        raise ValueError(\"marker_panels ä¸­åŸºå› å‡æœªå‘½ä¸­ adata.var_namesã€‚\")\n",
        "\n",
        "    S = adata.obs[score_cols].copy()\n",
        "    S.columns = [c.replace(\"score__\", \"\") for c in S.columns]\n",
        "\n",
        "    winner = S.idxmax(axis=1)\n",
        "    top1   = S.max(axis=1)\n",
        "    top2   = S.apply(lambda r: r.nlargest(2).iloc[-1] if (r.notna().sum() >= 2) else np.nan, axis=1)\n",
        "    margin = top1 - top2\n",
        "\n",
        "    per_label_thresh = {lbl: S[lbl].quantile(q) for lbl in S.columns}\n",
        "    keep = pd.Series(False, index=S.index)\n",
        "    for idx, lbl in winner.items():\n",
        "        thr = per_label_thresh.get(lbl, np.inf)\n",
        "        keep.at[idx] = (S.at[idx, lbl] >= thr) and (margin.at[idx] >= margin_min)\n",
        "\n",
        "    labels = winner.copy()\n",
        "    labels.loc[~keep] = \"Unknown\"\n",
        "    labels = labels.astype(\"category\")\n",
        "\n",
        "    coverage = (labels != \"Unknown\").mean()\n",
        "    logging.info(f\"[Silver labels] è¦†ç›–ç‡: {coverage:.2%} (q={q}, margin={margin_min})\")\n",
        "    return labels, S\n",
        "\n",
        "# =========================\n",
        "# 5) è¯„ä¼°å·¥å…·å‡½æ•°ï¼šAUROC/AUPRC/ECE/Brier & McNemar\n",
        "# =========================\n",
        "def one_hot(y_idx: np.ndarray, n_class: int) -> np.ndarray:\n",
        "    Y = np.zeros((len(y_idx), n_class), dtype=float)\n",
        "    Y[np.arange(len(y_idx)), y_idx] = 1.0\n",
        "    return Y\n",
        "\n",
        "def macro_ovr_auroc(y_idx: np.ndarray, P: np.ndarray) -> float:\n",
        "    \"\"\"å¤šç±» macro-OVR AUROCï¼›äºŒåˆ†ç±»ä¹Ÿé€‚ç”¨ã€‚\"\"\"\n",
        "    C = P.shape[1]\n",
        "    Y = one_hot(y_idx, C)\n",
        "    try:\n",
        "        return roc_auc_score(Y, P, average='macro', multi_class='ovr')\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def macro_ovr_auprc(y_idx: np.ndarray, P: np.ndarray) -> float:\n",
        "    \"\"\"å¤šç±» macro-OVR AUPRCï¼›é€ç±» AP å†å¹³å‡ã€‚\"\"\"\n",
        "    C = P.shape[1]\n",
        "    ap = []\n",
        "    for k in range(C):\n",
        "        yk = (y_idx == k).astype(int)\n",
        "        try:\n",
        "            ap.append(average_precision_score(yk, P[:, k]))\n",
        "        except Exception:\n",
        "            ap.append(np.nan)\n",
        "    return float(np.nanmean(ap)) if len(ap) else np.nan\n",
        "\n",
        "def multiclass_brier(y_idx: np.ndarray, P: np.ndarray) -> float:\n",
        "    Y = one_hot(y_idx, P.shape[1])\n",
        "    return float(np.mean(np.sum((P - Y) ** 2, axis=1)))\n",
        "\n",
        "def ece_maxprob(y_idx: np.ndarray, P: np.ndarray, n_bins: int = 15) -> float:\n",
        "    \"\"\"ECEï¼šç”¨ max prob & æ˜¯å¦é¢„æµ‹æ­£ç¡®ï¼ˆå¤šç±»ç‰ˆæœ¬çš„å¸¸ç”¨å®ç°ï¼‰\"\"\"\n",
        "    conf = P.max(axis=1)\n",
        "    pred = P.argmax(axis=1)\n",
        "    corr = (pred == y_idx).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    N = len(conf)\n",
        "    for i in range(n_bins):\n",
        "        lo, hi = bins[i], bins[i+1]\n",
        "        m = (conf >= lo) & (conf < hi) if i < n_bins - 1 else (conf >= lo) & (conf <= hi)\n",
        "        if m.sum() == 0: \n",
        "            continue\n",
        "        acc_bin = corr[m].mean()\n",
        "        conf_bin = conf[m].mean()\n",
        "        ece += np.abs(acc_bin - conf_bin) * (m.sum() / N)\n",
        "    return float(ece)\n",
        "\n",
        "def mcnemar_pvalue_from_correct(correctA: np.ndarray, correctB: np.ndarray) -> Tuple[int, int, int, int, float]:\n",
        "    \"\"\"åŸºäºâ€œæ˜¯å¦é¢„æµ‹æ­£ç¡®â€çš„2x2è¡¨åšMcNemarï¼šè¿”å› a,b,c,d,p\"\"\"\n",
        "    a = int(np.sum( (correctA == 1) & (correctB == 1) ))\n",
        "    b = int(np.sum( (correctA == 0) & (correctB == 1) ))  # Aé”™Bå¯¹\n",
        "    c = int(np.sum( (correctA == 1) & (correctB == 0) ))  # Aå¯¹Bé”™\n",
        "    d = int(np.sum( (correctA == 0) & (correctB == 0) ))\n",
        "    if b + c == 0:\n",
        "        pval = 1.0  # å®Œå…¨ä¸€è‡´ï¼Œæ— å·®å¼‚\n",
        "    else:\n",
        "        if _HAS_STATSMODELS:\n",
        "            exact = (b + c) <= 100\n",
        "            res = sm_mcnemar([[a, b], [c, d]], exact=exact, correction=not exact)\n",
        "            pval = float(res.pvalue)\n",
        "        else:\n",
        "            # ç²¾ç¡®äºŒé¡¹æ›¿ä»£ï¼šH0 ä¸‹ b~Binom(b+c,0.5)ï¼ŒåŒä¾§\n",
        "            pval = float(binomtest(k=min(b, c), n=b+c, p=0.5, alternative='two-sided').pvalue)\n",
        "    return a, b, c, d, pval\n",
        "\n",
        "# =========================\n",
        "# 6) å•æ ·æœ¬ï¼šæ¨ç† + è¯„ä¼°ï¼ˆæ–°å¢ï¼šAUROC/AUPRC/ECE/Brierï¼›è¿”å›McNemaræ‰€éœ€æ­£ç¡®æ€§å‘é‡ï¼‰\n",
        "# =========================\n",
        "def load_clip_model(checkpoint_path: Path, model_name: str, device: str) -> torch.nn.Module:\n",
        "    model, _, _ = open_clip.create_model_and_transforms(model_name, pretrained=None)\n",
        "    ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "    state_dict = ckpt.get('state_dict', ckpt)\n",
        "    if all(k.startswith('module.') for k in state_dict.keys()):\n",
        "        state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
        "    try:\n",
        "        model.load_state_dict(state_dict)\n",
        "    except RuntimeError as e:\n",
        "        logging.warning(f\"ä¸¥æ ¼åŠ è½½å¤±è´¥: {e}ï¼Œé‡‡ç”¨éä¸¥æ ¼ã€‚\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    model.to(device); model.eval()\n",
        "    return model\n",
        "\n",
        "def run_inference_and_eval_single(\n",
        "    sample_id: str,\n",
        "    text_queries: Dict[str, str],\n",
        "    marker_panels: Dict[str, List[str]],\n",
        "    experiment_name: str,\n",
        "    q: float = 0.90,\n",
        "    margin_min: float = 0.30,\n",
        "    models_to_test: Dict[str, Dict[str, Any]] = MODELS_TO_TEST,\n",
        "    device: str = DEVICE,\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "    num_workers: int = NUM_WORKERS,\n",
        ") -> Tuple[HESTSample, pd.DataFrame, Dict[str, np.ndarray], List[str]]:\n",
        "    \"\"\"\n",
        "    è¿”å›ï¼š\n",
        "      - sample: HESTSample\n",
        "      - metrics_df_per_model: æ¯æ¨¡å‹è¯„ä¼°ï¼ˆå« Accuracy/F1/AUROC/AUPRC/ECE/Brierï¼‰\n",
        "      - correct_flags: {model_name: bool array of correctness on evaluated spots}\n",
        "      - eval_labels: å‚ä¸è¯„ä¼°çš„æ ‡ç­¾é¡ºåºï¼ˆä¸æ¦‚ç‡åˆ—ä¸€è‡´ï¼‰\n",
        "    \"\"\"\n",
        "    # åŠ è½½æ ·æœ¬\n",
        "    ds = HESTDataset(str(HEST_DATA_DIR))\n",
        "    samples = ds.get_samples(sample_ids=[sample_id])\n",
        "    if len(samples) == 0:\n",
        "        raise FileNotFoundError(f\"{sample_id} æœªåœ¨å…ƒæ•°æ®ä¸­æ‰¾åˆ°ã€‚\")\n",
        "    sample = samples[0]\n",
        "    sample.load_st_data(lazy=False)\n",
        "    sample.load_wsi()\n",
        "\n",
        "    if sample.wsi is None:\n",
        "        logging.warning(f\"{sample_id}: ç¼ºå°‘ WSIï¼Œè·³è¿‡ã€‚\")\n",
        "        return sample, pd.DataFrame(), {}, []\n",
        "\n",
        "    ensure_log1p_layer(sample.adata, layer_name=\"log1p\")\n",
        "\n",
        "    tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "    query_labels = list(text_queries.keys())\n",
        "    label_to_col = {lbl: i for i, lbl in enumerate(query_labels)}\n",
        "\n",
        "    # æ¨ç†ï¼šé€æ¨¡å‹ï¼Œä¿å­˜å…¨ä½“spotçš„ç±»åˆ«æ¦‚ç‡\n",
        "    model_probs = {}  # {model_name: np.ndarray (n_spots x n_classes)}\n",
        "    for model_name, cfg in models_to_test.items():\n",
        "        model = load_clip_model(cfg['path'], cfg['model_name'], device)\n",
        "        _, _, image_pre = open_clip.create_model_and_transforms(cfg['model_name'])\n",
        "        loader = DataLoader(\n",
        "            WSISpotDataset(wsi=sample.wsi, coords=sample.adata.obsm['spatial'], transform=image_pre),\n",
        "            batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
        "            pin_memory=True, persistent_workers=False\n",
        "        )\n",
        "        with torch.inference_mode():\n",
        "            tok = tokenizer(list(text_queries.values())).to(device)\n",
        "            txt_feat = model.encode_text(tok, normalize=True)\n",
        "            all_emb = []\n",
        "            for batch in tqdm(loader, desc=f\"{sample_id} æ¨ç†: {model_name}\", leave=False):\n",
        "                img_feat = model.encode_image(batch.to(device), normalize=True)\n",
        "                all_emb.append(img_feat.cpu())\n",
        "        spot_emb = torch.cat(all_emb, dim=0)\n",
        "        sim = spot_emb.to(device) @ txt_feat.T\n",
        "        prob = torch.softmax(sim, dim=1).cpu().numpy()\n",
        "        model_probs[model_name] = prob\n",
        "\n",
        "        # ä¿å­˜ä¸»ç»“æœåˆ—ï¼ˆä¸ä¹‹å‰ä¿æŒå…¼å®¹ï¼‰\n",
        "        conf = prob.max(axis=1)\n",
        "        pred_idx = prob.argmax(axis=1)\n",
        "        safe = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        anno_col = f\"anno_{experiment_name}_{safe}\"\n",
        "        conf_col = f\"conf_{experiment_name}_{safe}\"\n",
        "        sample.adata.obs[anno_col] = pd.Categorical([query_labels[i] for i in pred_idx],\n",
        "                                                    categories=query_labels)\n",
        "        sample.adata.obs[conf_col] = conf\n",
        "\n",
        "        del model, txt_feat, spot_emb\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ä¼ªæ ‡ç­¾ï¼ˆé“¶æ ‡å‡†ï¼‰\n",
        "    pseudo, score_df = create_silver_labels_scanpy(\n",
        "        sample.adata, marker_panels=marker_panels, layer=\"log1p\", q=q, margin_min=margin_min\n",
        "    )\n",
        "    kept_idx = pseudo.index[pseudo.values != \"Unknown\"]\n",
        "    n_eval   = len(kept_idx); n_total = sample.adata.n_obs\n",
        "    if n_eval == 0:\n",
        "        logging.warning(f\"{sample_id}: ä¼ªæ ‡ç­¾è¦†ç›–ç‡ä¸º 0ï¼Œè·³è¿‡å®šé‡è¯„ä¼°ã€‚\")\n",
        "        return sample, pd.DataFrame(), {}, []\n",
        "\n",
        "    # å¯¹åº”åˆ°æ•°ç»„ä¸‹æ ‡ï¼ˆDataLoader é¡ºåºå³ obs é¡ºåºï¼‰\n",
        "    pos = sample.adata.obs_names.get_indexer(kept_idx)\n",
        "    assert np.all(pos >= 0)\n",
        "\n",
        "    # ä»…å¯¹ pseudo å‡ºç°çš„ç±»åšè¯„ä¼°ï¼Œä¿æŒåˆ—é¡ºåºç¨³å®š\n",
        "    eval_labels = sorted(list(set(pseudo[kept_idx].unique())))  # ä¸å« Unknown\n",
        "    eval_cols = [label_to_col[lbl] for lbl in eval_labels]\n",
        "\n",
        "    # é€æ¨¡å‹è¯„ä¼°\n",
        "    rows = []\n",
        "    correct_flags = {}\n",
        "    y_true_idx = np.array([eval_labels.index(lbl) for lbl in pseudo.loc[kept_idx].tolist()], dtype=int)\n",
        "\n",
        "    for model_name, prob_all in model_probs.items():\n",
        "        # é€‰å–è¯„ä¼°åˆ—å¹¶åœ¨è¯„ä¼°åˆ—ä¸Šå½’ä¸€åŒ–ï¼ˆé˜²æ­¢æœ‰â€œå…¶ä»–ç±»â€æ—¶æ¦‚ç‡ä¸æ»¡1ï¼‰\n",
        "        P = prob_all[pos][:, eval_cols]\n",
        "        P = P / np.maximum(P.sum(axis=1, keepdims=True), 1e-12)\n",
        "\n",
        "        # é¢„æµ‹/æ­£ç¡®æ€§\n",
        "        pred_idx = P.argmax(axis=1)\n",
        "        correct = (pred_idx == y_true_idx).astype(int)\n",
        "        correct_flags[model_name] = correct.copy()\n",
        "\n",
        "        # æŒ‡æ ‡\n",
        "        acc = float(correct.mean())\n",
        "        f1w = float(f1_score(y_true_idx, pred_idx, average='weighted', zero_division=0))\n",
        "        auroc = macro_ovr_auroc(y_true_idx, P)\n",
        "        auprc = macro_ovr_auprc(y_true_idx, P)\n",
        "        ece   = ece_maxprob(y_true_idx, P, n_bins=15)\n",
        "        brier = multiclass_brier(y_true_idx, P)\n",
        "\n",
        "        rows.append({\n",
        "            \"sample_id\": sample.sample_id,\n",
        "            \"model\": model_name,\n",
        "            \"accuracy\": acc,\n",
        "            \"f1_weighted\": f1w,\n",
        "            \"auroc_macro_ovr\": auroc,\n",
        "            \"auprc_macro_ovr\": auprc,\n",
        "            \"ece_15bin\": ece,\n",
        "            \"brier\": brier,\n",
        "            \"coverage\": n_eval / n_total,\n",
        "            \"n_eval_spots\": n_eval,\n",
        "            \"n_total_spots\": n_total,\n",
        "            \"n_correct\": acc * n_eval\n",
        "        })\n",
        "\n",
        "    metrics_df = pd.DataFrame(rows)\n",
        "    return sample, metrics_df, correct_flags, eval_labels\n",
        "\n",
        "# =========================\n",
        "# 7) é€‰æ‹©é˜Ÿåˆ—ï¼šäººç±» + ä¹³è…ºï¼ˆBreastï¼‰\n",
        "# =========================\n",
        "def get_breast_cancer_sample_ids(hest_data_dir: Path) -> List[str]:\n",
        "    ds = HESTDataset(str(hest_data_dir))\n",
        "    df = ds.meta_df.copy()\n",
        "    organ_mask   = (df['organ'] == 'Breast')\n",
        "    species_mask = (df['species'] == 'Homo sapiens')\n",
        "    cancer_mask  = (df['disease_state'].fillna('') == 'Cancer')\n",
        "    brca_mask    = (df['oncotree_code'].fillna('') == 'BRCA')\n",
        "    mask = species_mask & (organ_mask | brca_mask) & (cancer_mask | brca_mask)\n",
        "    cohort = df.loc[mask, 'id'].dropna().unique().tolist()\n",
        "    logging.info(f\"[Cohort] äººç±»ä¹³è…ºç™Œæ ·æœ¬æ•°é‡: {len(cohort)} -> {cohort}\")\n",
        "    return cohort\n",
        "\n",
        "# =========================\n",
        "# 8) é˜Ÿåˆ—è¯„ä¼°ï¼ˆå« McNemarï¼šæ¯æ ·æœ¬ & å…¨é˜Ÿåˆ— pooledï¼‰\n",
        "# =========================\n",
        "from itertools import combinations\n",
        "\n",
        "def evaluate_breast_cancer_cohort(\n",
        "    text_queries: Dict[str, str],\n",
        "    marker_panels: Dict[str, List[str]],\n",
        "    experiment_name: str = \"Breast_Cancer_Binary\",\n",
        "    q: float = 0.90, margin_min: float = 0.30,\n",
        "    models_to_test: Dict[str, Dict[str, Any]] = MODELS_TO_TEST,\n",
        "    device: str = DEVICE\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    è¿”å›ï¼š\n",
        "      - per_sample_df: æ¯æ ·æœ¬ x æ¯æ¨¡å‹ æŒ‡æ ‡ + å…ƒæ•°æ®\n",
        "      - per_group_df : æŒ‰æ¨¡å‹ & (st_technology/oncotree_code/preservation_method) åˆ†ç»„åŠ æƒæ±‡æ€»\n",
        "      - global_df    : å…¨å±€ï¼ˆæŒ‰ spot åŠ æƒï¼‰ä¸æ ·æœ¬å®å¹³å‡\n",
        "      - mcnemar_per_sample_df: æ¯æ ·æœ¬çš„æ¨¡å‹å¯¹ McNemar æ£€éªŒç»“æœ\n",
        "      - mcnemar_pooled_df    : å…¨é˜Ÿåˆ— pooled çš„æ¨¡å‹å¯¹ McNemar æ£€éªŒç»“æœ\n",
        "    \"\"\"\n",
        "    sample_ids = get_breast_cancer_sample_ids(HEST_DATA_DIR)\n",
        "    if len(sample_ids) == 0:\n",
        "        logging.warning(\"æœªæ‰¾åˆ°äººç±»ä¹³è…ºç™Œæ ·æœ¬ã€‚\")\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    ds = HESTDataset(str(HEST_DATA_DIR))\n",
        "    all_rows = []\n",
        "    mcnemar_rows = []\n",
        "    pooled_bc = {}  # {(A,B): {'b':sum, 'c':sum, 'a':sum, 'd':sum}}\n",
        "    failed   = []\n",
        "\n",
        "    model_names = list(models_to_test.keys())\n",
        "    model_pairs = list(combinations(model_names, 2))\n",
        "\n",
        "    for sid in sample_ids:\n",
        "        try:\n",
        "            sample, df_metrics, correct_flags, eval_labels = run_inference_and_eval_single(\n",
        "                sid, text_queries, marker_panels, experiment_name,\n",
        "                q=q, margin_min=margin_min, models_to_test=models_to_test, device=device\n",
        "            )\n",
        "            if df_metrics.empty or not correct_flags:\n",
        "                failed.append(sid)\n",
        "                continue\n",
        "\n",
        "            # è¿½åŠ å…ƒæ•°æ®\n",
        "            meta = sample.metadata_dict if isinstance(sample.metadata_dict, dict) else {}\n",
        "            md = {\n",
        "                'sample_id'            : sample.sample_id,\n",
        "                'organ'                : meta.get('organ'),\n",
        "                'species'              : meta.get('species'),\n",
        "                'disease_state'        : meta.get('disease_state'),\n",
        "                'oncotree_code'        : meta.get('oncotree_code'),\n",
        "                'st_technology'        : meta.get('st_technology'),\n",
        "                'preservation_method'  : meta.get('preservation_method'),\n",
        "                'nb_genes'             : meta.get('nb_genes'),\n",
        "                'data_publication_date': meta.get('data_publication_date'),\n",
        "                'license'              : meta.get('license'),\n",
        "                'tissue'               : meta.get('tissue'),\n",
        "                'subseries'            : meta.get('subseries'),\n",
        "                'inter_spot_dist'      : meta.get('inter_spot_dist'),\n",
        "                'spot_diameter'        : meta.get('spot_diameter'),\n",
        "                'pixel_size_um_embedded': meta.get('pixel_size_um_embedded'),\n",
        "                'pixel_size_um_estimated': meta.get('pixel_size_um_estimated'),\n",
        "                'fullres_px_width'     : meta.get('fullres_px_width'),\n",
        "                'fullres_px_height'    : meta.get('fullres_px_height'),\n",
        "            }\n",
        "            df_metrics = df_metrics.merge(pd.DataFrame([md]), on='sample_id', how='left')\n",
        "            all_rows.append(df_metrics)\n",
        "\n",
        "            # ---- McNemarï¼šæ¯æ ·æœ¬ + ç´¯ç§¯åˆ° pooled ----\n",
        "            for A, B in model_pairs:\n",
        "                if A not in correct_flags or B not in correct_flags:\n",
        "                    continue\n",
        "                a, b, c, d, pval = mcnemar_pvalue_from_correct(\n",
        "                    correct_flags[A].astype(int), correct_flags[B].astype(int)\n",
        "                )\n",
        "                mcnemar_rows.append({\n",
        "                    \"sample_id\": sample.sample_id,\n",
        "                    \"model_A\": A, \"model_B\": B,\n",
        "                    \"a_both_correct\": a, \"b_A_wrong_B_right\": b, \"c_A_right_B_wrong\": c, \"d_both_wrong\": d,\n",
        "                    \"n_discordant\": b + c,\n",
        "                    \"p_value\": pval,\n",
        "                    \"st_technology\": meta.get('st_technology'),\n",
        "                    \"oncotree_code\": meta.get('oncotree_code'),\n",
        "                    \"preservation_method\": meta.get('preservation_method')\n",
        "                })\n",
        "                key = (A, B)\n",
        "                if key not in pooled_bc:\n",
        "                    pooled_bc[key] = {'a':0,'b':0,'c':0,'d':0}\n",
        "                pooled_bc[key]['a'] += a\n",
        "                pooled_bc[key]['b'] += b\n",
        "                pooled_bc[key]['c'] += c\n",
        "                pooled_bc[key]['d'] += d\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"{sid} è¯„ä¼°å¤±è´¥: {e}\")\n",
        "            failed.append(sid)\n",
        "\n",
        "    if len(all_rows) == 0:\n",
        "        logging.warning(\"é˜Ÿåˆ—è¯„ä¼°æœªå¾—åˆ°ä»»ä½•æŒ‡æ ‡ã€‚\")\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    per_sample_df = pd.concat(all_rows, ignore_index=True)\n",
        "    mcnemar_per_sample_df = pd.DataFrame(mcnemar_rows)\n",
        "\n",
        "    # -------- å…¨å±€æ±‡æ€»ï¼ˆæŒ‰ spot åŠ æƒï¼‰ä¸æ ·æœ¬å®å¹³å‡ --------\n",
        "    def _global_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        out = []\n",
        "        for model, g in df.groupby('model'):\n",
        "            n_eval = g['n_eval_spots'].sum()\n",
        "            n_corr = g['n_correct'].sum()\n",
        "            row = {\n",
        "                \"model\": model,\n",
        "                \"global_n_eval_spots\": int(n_eval),\n",
        "                \"global_accuracy_weighted\": (n_corr / n_eval) if n_eval > 0 else np.nan,\n",
        "                \"macro_accuracy\": g['accuracy'].mean(),\n",
        "                \"macro_f1_weighted\": g['f1_weighted'].mean(),\n",
        "                \"macro_auroc_macro_ovr\": g['auroc_macro_ovr'].mean(),\n",
        "                \"macro_auprc_macro_ovr\": g['auprc_macro_ovr'].mean(),\n",
        "                \"macro_ece_15bin\": g['ece_15bin'].mean(),\n",
        "                \"macro_brier\": g['brier'].mean(),\n",
        "                \"n_samples\": g['sample_id'].nunique()\n",
        "            }\n",
        "            out.append(row)\n",
        "        return pd.DataFrame(out)\n",
        "\n",
        "    global_df = _global_summary(per_sample_df)\n",
        "\n",
        "    # -------- åˆ†ç»„æ±‡æ€»ï¼ˆå¹³å°/è‚¿ç˜¤ç±»å‹/ä¿å­˜æ–¹å¼ï¼‰æŒ‰ spot åŠ æƒ --------\n",
        "    def _grouped_summary(df: pd.DataFrame, by: str) -> pd.DataFrame:\n",
        "        rows = []\n",
        "        for (model, grp), gdf in df.groupby(['model', by]):\n",
        "            n_eval = gdf['n_eval_spots'].sum()\n",
        "            n_corr = gdf['n_correct'].sum()\n",
        "            rows.append({\n",
        "                \"group_by\": by,\n",
        "                by: grp,\n",
        "                \"model\": model,\n",
        "                \"n_samples\": gdf['sample_id'].nunique(),\n",
        "                \"global_n_eval_spots\": int(n_eval),\n",
        "                \"global_accuracy_weighted\": (n_corr / n_eval) if n_eval > 0 else np.nan,\n",
        "                \"macro_accuracy\": gdf['accuracy'].mean(),\n",
        "                \"macro_f1_weighted\": gdf['f1_weighted'].mean(),\n",
        "                \"macro_auroc_macro_ovr\": gdf['auroc_macro_ovr'].mean(),\n",
        "                \"macro_auprc_macro_ovr\": gdf['auprc_macro_ovr'].mean(),\n",
        "                \"macro_ece_15bin\": gdf['ece_15bin'].mean(),\n",
        "                \"macro_brier\": gdf['brier'].mean(),\n",
        "            })\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    group_keys = ['st_technology', 'oncotree_code', 'preservation_method']\n",
        "    grouped_frames = [_grouped_summary(per_sample_df, k) for k in group_keys]\n",
        "    per_group_df = pd.concat(grouped_frames, ignore_index=True)\n",
        "\n",
        "    # -------- pooled McNemarï¼ˆå…¨é˜Ÿåˆ—ï¼‰--------\n",
        "    pooled_rows = []\n",
        "    for (A, B), abcd in pooled_bc.items():\n",
        "        a, b, c, d = abcd['a'], abcd['b'], abcd['c'], abcd['d']\n",
        "        if b + c == 0:\n",
        "            pval = 1.0\n",
        "        else:\n",
        "            if _HAS_STATSMODELS:\n",
        "                exact = (b + c) <= 1000\n",
        "                res = sm_mcnemar([[a,b],[c,d]], exact=exact, correction=not exact)\n",
        "                pval = float(res.pvalue)\n",
        "            else:\n",
        "                pval = float(binomtest(k=min(b,c), n=b+c, p=0.5, alternative='two-sided').pvalue)\n",
        "        pooled_rows.append({\n",
        "            \"model_A\": A, \"model_B\": B,\n",
        "            \"a_both_correct\": a, \"b_A_wrong_B_right\": b, \"c_A_right_B_wrong\": c, \"d_both_wrong\": d,\n",
        "            \"n_discordant\": b + c,\n",
        "            \"p_value\": pval\n",
        "        })\n",
        "    mcnemar_pooled_df = pd.DataFrame(pooled_rows)\n",
        "\n",
        "    # -------- ä¿å­˜ç»“æœ --------\n",
        "    if not DRYRUN:\n",
        "        per_sample_path = OUTPUT_DIR / f\"cohort_breast_per_sample_{experiment_name}.csv\"\n",
        "        per_group_path  = OUTPUT_DIR / f\"cohort_breast_grouped_{experiment_name}.csv\"\n",
        "        global_path     = OUTPUT_DIR / f\"cohort_breast_global_{experiment_name}.csv\"\n",
        "        mcnemar_s_path  = OUTPUT_DIR / f\"cohort_breast_mcnemar_per_sample_{experiment_name}.csv\"\n",
        "        mcnemar_p_path  = OUTPUT_DIR / f\"cohort_breast_mcnemar_pooled_{experiment_name}.csv\"\n",
        "        per_sample_df.to_csv(per_sample_path, index=False)\n",
        "        per_group_df.to_csv(per_group_path, index=False)\n",
        "        global_df.to_csv(global_path, index=False)\n",
        "        mcnemar_per_sample_df.to_csv(mcnemar_s_path, index=False)\n",
        "        mcnemar_pooled_df.to_csv(mcnemar_p_path, index=False)\n",
        "        logging.info(f\"å·²ä¿å­˜:\\n- {per_sample_path}\\n- {per_group_path}\\n- {global_path}\\n- {mcnemar_s_path}\\n- {mcnemar_p_path}\")\n",
        "\n",
        "    if failed:\n",
        "        logging.warning(f\"ä»¥ä¸‹æ ·æœ¬æœªèƒ½è¯„ä¼°ï¼ˆç¼º WSI æˆ–æŠ¥é”™ï¼‰ï¼š{failed}\")\n",
        "\n",
        "    return per_sample_df, per_group_df, global_df, mcnemar_per_sample_df, mcnemar_pooled_df\n",
        "\n",
        "# =========================\n",
        "# 9) ä¹³è…ºäºŒåˆ†ç±»ï¼šæ–‡æœ¬æŸ¥è¯¢ & ç»å…¸æ ‡è®°ï¼ˆä¸è®­ç»ƒ Top-50 æ–‡æœ¬æç¤ºè§£è€¦ï¼‰\n",
        "# =========================\n",
        "breast_cancer_binary_queries = {\n",
        "    \"Tumor (IDC)\": (\n",
        "        \"KRT8 KRT18 KRT19 EPCAM MUC1 CLDN3 CLDN4 CLDN7 CDH1 KRT7 \"\n",
        "        \"ERBB2 GRB7 ERBB3 ESR1 PGR FOXA1 GATA3 AGR2 TFF1 TFF3 \"\n",
        "        \"TRPS1 SCGB2A2 BCL2 AR MKI67 TOP2A MYC CCND1 EGFR BIRC5 \"\n",
        "        \"UBE2C CCNA2 CCNB1 CDC20 PLK1 AURKA AURKB CENPF NUSAP1 KIF11 \"\n",
        "        \"KIF2C PTTG1 PRC1 ANLN MCM2 MCM4 MCM6 MCM7 TK1 PCNA\"\n",
        "    ),\n",
        "    \"Normal & Stroma\": (\n",
        "        \"COL1A1 COL1A2 COL3A1 COL5A1 COL5A2 COL6A1 COL6A2 COL6A3 FN1 VIM \"\n",
        "        \"LUM DCN BGN THY1 FAP PDGFRB RGS5 CSPG4 ACTA2 TAGLN \"\n",
        "        \"MYH11 CNN1 DES VWF PECAM1 CLDN5 KDR FLT1 ENG CD34 \"\n",
        "        \"MCAM PDPN PROX1 LYVE1 PTPRC LST1 LYZ CSF1R CD68 C1QB \"\n",
        "        \"ITGAM ITGAX HLA-DRA HLA-DPB1 CD3D CD4 CD8A TRAC MS4A1 CD79A\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "marker_panels = {\n",
        "    \"Tumor (IDC)\": [\"EPCAM\",\"KRT8\",\"KRT18\",\"KRT19\",\"KRT7\",\"MUC1\",\"CLDN3\",\"CLDN4\",\"CLDN7\",\"ERBB2\"],\n",
        "    \"Normal & Stroma\": [\"COL1A1\",\"COL1A2\",\"COL3A1\",\"DCN\",\"LUM\",\"BGN\",\"THY1\",\"PDGFRB\",\"TAGLN\",\"ACTA2\",\"VWF\",\"PECAM1\"],\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# 10) è¿è¡Œæ•´é˜Ÿåˆ—è¯„ä¼°\n",
        "# =========================\n",
        "if not DRYRUN:\n",
        "    per_sample_df, per_group_df, global_df, mcnemar_per_sample_df, mcnemar_pooled_df = evaluate_breast_cancer_cohort(\n",
        "        text_queries=breast_cancer_binary_queries,\n",
        "        marker_panels=marker_panels,\n",
        "        experiment_name=\"Breast_Cancer_Binary\",\n",
        "        q=0.90, margin_min=0.30,\n",
        "        models_to_test=MODELS_TO_TEST,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    print(\"=== æ¯æ ·æœ¬æ˜ç»†ï¼ˆå‰10è¡Œï¼‰===\")\n",
        "    display(per_sample_df.head(10))\n",
        "    print(\"=== åˆ†ç»„æ±‡æ€»ï¼ˆå¹³å°/è‚¿ç˜¤ç±»å‹/ä¿å­˜æ–¹å¼ï¼‰===\")\n",
        "    display(per_group_df)\n",
        "    print(\"=== å…¨å±€æ±‡æ€» ===\")\n",
        "    display(global_df)\n",
        "    print(\"=== McNemarï¼ˆæ¯æ ·æœ¬ï¼‰===\")\n",
        "    display(mcnemar_per_sample_df.head(10))\n",
        "    print(\"=== McNemarï¼ˆå…¨é˜Ÿåˆ— pooledï¼‰===\")\n",
        "    display(mcnemar_pooled_df)\n",
        "else:\n",
        "    logging.warning(\"DRYRUN=Trueï¼Œè·³è¿‡é˜Ÿåˆ—è¯„ä¼°ã€‚\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "2b06f808",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # å¯è§†åŒ–ï¼šæ•´é˜Ÿåˆ—ç©ºé—´CLIPè¯„ä¼°ç»“æœ\n",
        "\n",
        "# ========= ç”¨æˆ·å¯è°ƒå‚æ•° =========\n",
        "EXPERIMENT_NAME = \"Breast_Cancer_Binary\"\n",
        "TOP_K_GROUPS = 12      # åˆ†ç»„å¯è§†åŒ–åªå–å‰Kä¸ªæ ·æœ¬æ•°æœ€å¤šçš„ç»„\n",
        "SHOW_VIOLIN = False    # True: å°æç´å›¾ï¼›False: ç®±çº¿å›¾\n",
        "DOT_ALPHA = 0.25       # ç®±/æç´å åŠ æ•£ç‚¹é€æ˜åº¦\n",
        "SEED = 7               # éšæœºç§å­(ç”¨äºæŠ–åŠ¨)\n",
        "# =================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# ===== è·¯å¾„ï¼Œä¸è®­ç»ƒ/è¯„ä¼°ä»£ç ä¿æŒä¸€è‡´ =====\n",
        "OUTPUT_DIR = Path(\"/cwStorage/nodecw_group/jijh/trained_models/all_comparisons/multipositive_vs_basline\")\n",
        "FIG_DIR = OUTPUT_DIR / \"figs\" / EXPERIMENT_NAME\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ====== è¯»å…¥ç»“æœ ======\n",
        "def load_results(output_dir: Path, experiment_name: str):\n",
        "    def _try_read(name):\n",
        "        p = output_dir / f\"cohort_breast_{name}_{experiment_name}.csv\"\n",
        "        if p.exists():\n",
        "            return pd.read_csv(p)\n",
        "        return None\n",
        "    per_sample = _try_read(\"per_sample\")\n",
        "    per_group  = _try_read(\"grouped\")\n",
        "    global_df  = _try_read(\"global\")\n",
        "    mcnemar_s  = _try_read(\"mcnemar_per_sample\")\n",
        "    mcnemar_p  = _try_read(\"mcnemar_pooled\")\n",
        "    return per_sample, per_group, global_df, mcnemar_s, mcnemar_p\n",
        "\n",
        "per_sample_df, per_group_df, global_df, mcnemar_per_sample_df, mcnemar_pooled_df = load_results(OUTPUT_DIR, EXPERIMENT_NAME)\n",
        "\n",
        "# ç®€å•æ ¡éªŒ\n",
        "print(\"Loaded:\")\n",
        "print(\" - per_sample_df:\", None if per_sample_df is None else per_sample_df.shape)\n",
        "print(\" - per_group_df :\", None if per_group_df  is None else per_group_df.shape)\n",
        "print(\" - global_df    :\", None if global_df     is None else global_df.shape)\n",
        "print(\" - mcnemar_sample:\", None if mcnemar_per_sample_df is None else mcnemar_per_sample_df.shape)\n",
        "print(\" - mcnemar_pooled:\", None if mcnemar_pooled_df     is None else mcnemar_pooled_df.shape)\n",
        "\n",
        "# ====== é€šç”¨å·¥å…· ======\n",
        "def _savefig(fig, name: str, dpi=180, tight=True):\n",
        "    out = FIG_DIR / f\"{name}.png\"\n",
        "    if tight:\n",
        "        fig.savefig(out, dpi=dpi, bbox_inches=\"tight\")\n",
        "    else:\n",
        "        fig.savefig(out, dpi=dpi)\n",
        "    print(f\"Saved: {out}\")\n",
        "\n",
        "def _maybe_cols(df: pd.DataFrame, cols: list):\n",
        "    return [c for c in cols if (df is not None and c in df.columns)]\n",
        "\n",
        "def _jitter(n, scale=0.08, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    return rng.normal(0, scale, n)\n",
        "\n",
        "# ====== 1) å…¨å±€æ±‡æ€»æŸ±çŠ¶å›¾ ======\n",
        "def plot_global_bars(global_df: pd.DataFrame):\n",
        "    if global_df is None or global_df.empty:\n",
        "        print(\"[Global] æ— æ•°æ®ã€‚\")\n",
        "        return\n",
        "    metrics = _maybe_cols(global_df, [\n",
        "        \"global_accuracy_weighted\",\n",
        "        \"macro_accuracy\",\n",
        "        \"macro_f1_weighted\",\n",
        "        \"macro_auroc_macro_ovr\",\n",
        "        \"macro_auprc_macro_ovr\",\n",
        "        \"macro_ece_15bin\",\n",
        "        \"macro_brier\",\n",
        "    ])\n",
        "    if not metrics:\n",
        "        print(\"[Global] æœªæ‰¾åˆ°å¯ç»˜åˆ¶çš„æŒ‡æ ‡åˆ—ã€‚\")\n",
        "        return\n",
        "\n",
        "    for m in metrics:\n",
        "        fig, ax = plt.subplots(figsize=(7,4.5))\n",
        "        x = np.arange(len(global_df))\n",
        "        ax.bar(x, global_df[m].values)\n",
        "        ax.set_xticks(x); ax.set_xticklabels(global_df[\"model\"].astype(str), rotation=20, ha='right')\n",
        "        ax.set_ylabel(m)\n",
        "        ax.set_title(f\"Global Summary â€” {m}\")\n",
        "        for i, v in enumerate(global_df[m].values):\n",
        "            ax.text(i, v, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        _savefig(fig, f\"global_bar_{m}\")\n",
        "\n",
        "plot_global_bars(global_df)\n",
        "\n",
        "# ====== 2) æ¯æ ·æœ¬åˆ†å¸ƒï¼ˆç®±/æç´ï¼‰ ======\n",
        "def plot_per_sample_distribution(per_sample_df: pd.DataFrame, metric: str, show_violin: bool = SHOW_VIOLIN):\n",
        "    if per_sample_df is None or per_sample_df.empty or metric not in per_sample_df.columns:\n",
        "        print(f\"[Per-sample] åˆ— {metric} ä¸å­˜åœ¨æˆ–æ— æ•°æ®ã€‚\")\n",
        "        return\n",
        "    order = per_sample_df.groupby(\"model\")[metric].median().sort_values(ascending=False).index.tolist()\n",
        "    models = order\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    data = [per_sample_df.loc[per_sample_df[\"model\"]==m, metric].dropna().values for m in models]\n",
        "\n",
        "    # ç®±/æç´\n",
        "    if show_violin:\n",
        "        parts = ax.violinplot(data, showmeans=False, showmedians=True, showextrema=False)\n",
        "    else:\n",
        "        bp = ax.boxplot(data, showfliers=False, notch=False)\n",
        "\n",
        "    # å åŠ æ•£ç‚¹\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i, m in enumerate(models, start=1):\n",
        "        y = per_sample_df.loc[per_sample_df[\"model\"]==m, metric].dropna().values\n",
        "        x = np.full_like(y, i, dtype=float) + _jitter(len(y))\n",
        "        xs.append(x); ys.append(y)\n",
        "    ax.plot(np.concatenate(xs), np.concatenate(ys), 'o', alpha=DOT_ALPHA, markersize=3)\n",
        "\n",
        "    ax.set_xticks(range(1, len(models)+1)); ax.set_xticklabels(models, rotation=20, ha='right')\n",
        "    ax.set_ylabel(metric); ax.set_title(f\"Per-Sample Distribution â€” {metric}\")\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, f\"per_sample_{metric}_{'violin' if show_violin else 'box'}\")\n",
        "\n",
        "for m in [\"accuracy\",\"f1_weighted\",\"auroc_macro_ovr\",\"auprc_macro_ovr\",\"ece_15bin\",\"brier\"]:\n",
        "    plot_per_sample_distribution(per_sample_df, m, show_violin=SHOW_VIOLIN)\n",
        "\n",
        "# ====== 3) è¦†ç›–ç‡ vs å‡†ç¡®ç‡ æ•£ç‚¹ ======\n",
        "def plot_coverage_scatter(per_sample_df: pd.DataFrame):\n",
        "    if per_sample_df is None or per_sample_df.empty or (\"coverage\" not in per_sample_df.columns):\n",
        "        print(\"[Coverage] æ—  coverage åˆ—ã€‚\")\n",
        "        return\n",
        "    fig, ax = plt.subplots(figsize=(6.5,5))\n",
        "    models = per_sample_df[\"model\"].unique().tolist()\n",
        "    for i, m in enumerate(models):\n",
        "        d = per_sample_df.loc[per_sample_df[\"model\"]==m]\n",
        "        ax.plot(d[\"coverage\"], d[\"accuracy\"], 'o', alpha=0.6, label=m)\n",
        "    ax.set_xlabel(\"Coverage (fraction of spots with silver labels)\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.set_title(\"Coverage vs. Accuracy (per sample)\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, \"coverage_vs_accuracy\")\n",
        "\n",
        "plot_coverage_scatter(per_sample_df)\n",
        "\n",
        "# ====== 4) åˆ†ç»„æ¯”è¾ƒï¼ˆå¹³å°/è‚¿ç˜¤ç±»å‹/ä¿å­˜æ–¹å¼ï¼‰ ======\n",
        "def pick_top_groups(per_group_df: pd.DataFrame, by: str, top_k: int = TOP_K_GROUPS):\n",
        "    if per_group_df is None or per_group_df.empty: return []\n",
        "    sub = per_group_df[per_group_df[\"group_by\"]==by].copy()\n",
        "    if sub.empty: return []\n",
        "    # æŒ‰è¯¥ç»„ä¸‹çš„æ ·æœ¬æ•°æ’åºï¼ˆä¸åŒæ¨¡å‹ä¼šé‡å¤ï¼Œå–æ€»è®¡ï¼‰\n",
        "    size = sub.groupby(by)[\"n_samples\"].sum().sort_values(ascending=False)\n",
        "    return size.head(top_k).index.tolist()\n",
        "\n",
        "def plot_group_bars(per_group_df: pd.DataFrame, by: str, metric: str, top_k: int = TOP_K_GROUPS):\n",
        "    if per_group_df is None or per_group_df.empty: \n",
        "        print(f\"[Group] æ— åˆ†ç»„æ•°æ®ã€‚\")\n",
        "        return\n",
        "    if metric not in per_group_df.columns:\n",
        "        print(f\"[Group] æŒ‡æ ‡ {metric} ç¼ºå¤±ã€‚\")\n",
        "        return\n",
        "    sub = per_group_df[per_group_df[\"group_by\"]==by].copy()\n",
        "    if sub.empty:\n",
        "        print(f\"[Group] æ—  {by} ç»´åº¦çš„æ•°æ®ã€‚\")\n",
        "        return\n",
        "    groups = pick_top_groups(per_group_df, by, top_k)\n",
        "    if not groups:\n",
        "        print(f\"[Group] æœªæ‰¾åˆ° {by} çš„å‰ {top_k} ç»„ã€‚\")\n",
        "        return\n",
        "    sub = sub[sub[by].isin(groups)]\n",
        "    # æŒ‰ç»„å†…æ¨¡å‹ç”»åˆ†ç»„æŸ±å›¾\n",
        "    models = sub[\"model\"].unique().tolist()\n",
        "    g_order = groups\n",
        "    width = 0.8 / max(len(models),1)\n",
        "    fig, ax = plt.subplots(figsize=(min(12, 1.2*len(g_order)+3), 5))\n",
        "    x = np.arange(len(g_order))\n",
        "    for j, m in enumerate(models):\n",
        "        y = [sub.loc[(sub[by]==g) & (sub[\"model\"]==m), metric].mean() for g in g_order]\n",
        "        ax.bar(x + j*width, y, width, label=m)\n",
        "    ax.set_xticks(x + width*(len(models)-1)/2)\n",
        "    ax.set_xticklabels([str(g) for g in g_order], rotation=20, ha='right')\n",
        "    ax.set_ylabel(metric); ax.set_title(f\"{by}: top-{len(g_order)} groups â€” {metric}\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, f\"group_{by}_{metric}_bar_top{len(g_order)}\")\n",
        "\n",
        "for by in [\"st_technology\",\"oncotree_code\",\"preservation_method\"]:\n",
        "    for metric in [\"global_accuracy_weighted\",\"macro_accuracy\",\"macro_f1_weighted\",\"macro_auroc_macro_ovr\",\"macro_auprc_macro_ovr\"]:\n",
        "        if per_group_df is not None and metric in per_group_df.columns:\n",
        "            plot_group_bars(per_group_df, by, metric, TOP_K_GROUPS)\n",
        "\n",
        "# ====== 5) åˆ†ç»„çƒ­å›¾ï¼ˆç»„ Ã— æ¨¡å‹ï¼‰ ======\n",
        "def plot_group_heatmap(per_group_df: pd.DataFrame, by: str, metric: str, top_k: int = TOP_K_GROUPS):\n",
        "    if per_group_df is None or per_group_df.empty or metric not in per_group_df.columns:\n",
        "        print(f\"[Heatmap] æ— æ³•ç»˜åˆ¶ {by}-{metric}\")\n",
        "        return\n",
        "    sub = per_group_df[per_group_df[\"group_by\"]==by].copy()\n",
        "    if sub.empty:\n",
        "        print(f\"[Heatmap] æ—  {by} æ•°æ®ã€‚\"); return\n",
        "    groups = pick_top_groups(per_group_df, by, top_k)\n",
        "    if not groups:\n",
        "        print(f\"[Heatmap] æœªæ‰¾åˆ° {by} çš„å‰ {top_k} ç»„ã€‚\"); return\n",
        "    sub = sub[sub[by].isin(groups)]\n",
        "    pivot = sub.pivot_table(index=by, columns=\"model\", values=metric, aggfunc='mean')\n",
        "    # çº¯ matplotlib çƒ­å›¾\n",
        "    fig, ax = plt.subplots(figsize=(min(12, 0.6*pivot.shape[1]+4), min(10, 0.4*pivot.shape[0]+3)))\n",
        "    im = ax.imshow(pivot.values, aspect='auto')\n",
        "    ax.set_xticks(np.arange(pivot.shape[1])); ax.set_xticklabels(list(pivot.columns), rotation=20, ha='right')\n",
        "    ax.set_yticks(np.arange(pivot.shape[0])); ax.set_yticklabels(list(pivot.index))\n",
        "    ax.set_title(f\"Heatmap â€” {by} Ã— model ({metric})\")\n",
        "    cbar = fig.colorbar(im, ax=ax); cbar.set_label(metric)\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, f\"heatmap_{by}_{metric}_top{len(groups)}\")\n",
        "\n",
        "for by in [\"st_technology\",\"oncotree_code\",\"preservation_method\"]:\n",
        "    for metric in [\"global_accuracy_weighted\",\"macro_accuracy\",\"macro_f1_weighted\",\"macro_auroc_macro_ovr\",\"macro_auprc_macro_ovr\"]:\n",
        "        plot_group_heatmap(per_group_df, by, metric, TOP_K_GROUPS)\n",
        "\n",
        "# ====== 6) McNemar å¯è§†åŒ– ======\n",
        "def plot_mcnemar_pooled(mcnemar_pooled_df: pd.DataFrame):\n",
        "    if mcnemar_pooled_df is None or mcnemar_pooled_df.empty:\n",
        "        print(\"[McNemar pooled] æ— æ•°æ®ã€‚\"); return\n",
        "    df = mcnemar_pooled_df.copy()\n",
        "    df[\"pair\"] = df[\"model_A\"].astype(str) + \" vs \" + df[\"model_B\"].astype(str)\n",
        "    df[\"neglog10_p\"] = -np.log10(df[\"p_value\"].clip(lower=1e-300))\n",
        "    # âˆ’log10(p) æŸ±çŠ¶å›¾ + æ˜¾è‘—æ€§é˜ˆå€¼çº¿\n",
        "    fig, ax = plt.subplots(figsize=(max(6, 1.2*len(df)), 4.8))\n",
        "    x = np.arange(len(df))\n",
        "    ax.bar(x, df[\"neglog10_p\"].values)\n",
        "    ax.axhline(-np.log10(0.05), linestyle='--')\n",
        "    ax.set_xticks(x); ax.set_xticklabels(df[\"pair\"], rotation=20, ha='right')\n",
        "    ax.set_ylabel(\"-log10(p)\"); ax.set_title(\"Pooled McNemar: significance\")\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, \"mcnemar_pooled_neglog10p\")\n",
        "\n",
        "    # ä¸ä¸€è‡´è®¡æ•° (b vs c)\n",
        "    fig, ax = plt.subplots(figsize=(max(6, 1.2*len(df)), 4.8))\n",
        "    w = 0.4\n",
        "    ax.bar(x - w/2, df[\"b_A_wrong_B_right\"].values, width=w, label=\"A wrong, B right (b)\")\n",
        "    ax.bar(x + w/2, df[\"c_A_right_B_wrong\"].values, width=w, label=\"A right, B wrong (c)\")\n",
        "    ax.set_xticks(x); ax.set_xticklabels(df[\"pair\"], rotation=20, ha='right')\n",
        "    ax.set_ylabel(\"count\"); ax.set_title(\"Pooled McNemar: discordant counts\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, \"mcnemar_pooled_discordant_counts\")\n",
        "\n",
        "plot_mcnemar_pooled(mcnemar_pooled_df)\n",
        "\n",
        "def plot_mcnemar_top_per_sample(mcnemar_per_sample_df: pd.DataFrame, topN: int = 20):\n",
        "    if mcnemar_per_sample_df is None or mcnemar_per_sample_df.empty:\n",
        "        print(\"[McNemar per-sample] æ— æ•°æ®ã€‚\"); return\n",
        "    df = mcnemar_per_sample_df.copy()\n",
        "    df = df.sort_values(\"p_value\", ascending=True).head(topN).copy()\n",
        "    df[\"pair\"] = df[\"model_A\"].astype(str) + \" vs \" + df[\"model_B\"].astype(str)\n",
        "    df[\"label\"] = df[\"sample_id\"].astype(str) + \" | \" + df[\"pair\"]\n",
        "    df[\"neglog10_p\"] = -np.log10(df[\"p_value\"].clip(lower=1e-300))\n",
        "    fig, ax = plt.subplots(figsize=(8, max(5, 0.35*len(df))))\n",
        "    y = np.arange(len(df))\n",
        "    ax.barh(y, df[\"neglog10_p\"].values)\n",
        "    ax.set_yticks(y); ax.set_yticklabels(df[\"label\"])\n",
        "    ax.axvline(-np.log10(0.05), linestyle='--')\n",
        "    ax.set_xlabel(\"-log10(p)\"); ax.set_title(f\"Top-{topN} most significant McNemar pairs (per-sample)\")\n",
        "    plt.tight_layout()\n",
        "    _savefig(fig, f\"mcnemar_per_sample_top{topN}\")\n",
        "\n",
        "plot_mcnemar_top_per_sample(mcnemar_per_sample_df, topN=20)\n",
        "\n",
        "# ====== 7) â€œæœ€ä½³/æœ€å·®â€æ ·æœ¬æ’è¡Œæ¦œï¼ˆæŒ‰å‡†ç¡®ç‡ï¼‰ ======\n",
        "def topk_samples(per_sample_df: pd.DataFrame, metric=\"accuracy\", k=10, largest=True):\n",
        "    if per_sample_df is None or per_sample_df.empty or metric not in per_sample_df.columns:\n",
        "        print(\"[TopK] æ— æ•°æ®æˆ–åˆ—ç¼ºå¤±ã€‚\"); return\n",
        "    df = per_sample_df[[\"sample_id\",\"model\",metric,\"coverage\",\"st_technology\",\"oncotree_code\",\"preservation_method\"]].copy()\n",
        "    df = df.sort_values(metric, ascending=not largest).groupby(\"model\").head(k)\n",
        "    print(f\"Top-{k} samples by {metric} ({'largest' if largest else 'smallest'})\")\n",
        "    display(df)\n",
        "\n",
        "topk_samples(per_sample_df, \"accuracy\", k=10, largest=True)   # æœ€ä½³\n",
        "topk_samples(per_sample_df, \"accuracy\", k=10, largest=False)  # æœ€å·®\n",
        "\n",
        "print(\"\\nâœ… å¯è§†åŒ–å·²å®Œæˆã€‚æ‰€æœ‰å›¾ç‰‡ä¿å­˜åœ¨ï¼š\", FIG_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53705725",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (spatial_clip)",
      "language": "python",
      "name": "spatial_clip"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
